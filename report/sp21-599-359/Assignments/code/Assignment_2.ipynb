{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E599 Assignment 2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KScAHZqbQ_Sr"
      },
      "source": [
        "# MNIST Classification "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXNb7rQOQ2bW"
      },
      "source": [
        "\n",
        "In this lesson we discuss in how to create a simple IPython Notebook to solve\n",
        "an image classification problem. MNIST contains a set of pictures\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLpLVkFLRK-1"
      },
      "source": [
        "## Import Libraries \n",
        "\n",
        "Note: https://python-future.org/quickstart.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqorYeyBkCyi"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmlJQqK42Cs2"
      },
      "source": [
        "## Warm Up Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YajEPjlyRkrr"
      },
      "source": [
        "## Pre-process data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yOjQ9cjRrwQ"
      },
      "source": [
        "### Load data \n",
        "\n",
        "First we load the data from the inbuilt mnist dataset from Keras\n",
        "Here we have to split the data set into training and testing data. \n",
        "The training data or testing data has two components. \n",
        "Training features and training labels. \n",
        "For instance every sample in the dataset has a corresponding label. \n",
        "In Mnist the training sample contains image data represented in terms of \n",
        "an array. The training labels are from 0-9. \n",
        "\n",
        "Here we say x_train for training data features and y_train as the training labels. Same goes for testing data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN7h9FQ-kIzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d21d1f-4cea-425b-a2bc-336183ded28d"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJJxAbKxR7kZ"
      },
      "source": [
        "### Identify Number of Classes\n",
        "\n",
        "As this is a number classification problem. We need to know how many classes are there. \n",
        "So we'll count the number of unique labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laqnfrEBSFxZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8568bc8d-a037-4895-d1d3-f3ce0596b32d"
      },
      "source": [
        "num_labels = len(np.unique(y_train))\n",
        "print(num_labels)\n",
        "num_features = len(np.unique(x_train))\n",
        "print(num_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugx6012YSXtA"
      },
      "source": [
        "### Convert Labels To One-Hot Vector\n",
        "\n",
        "Read more on one-hot vector. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpSBHnBEScZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2099474-5de4-4e6f-f635-5aefd39ab512"
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_train\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyAfgPaJU753"
      },
      "source": [
        "## Image Reshaping\n",
        "\n",
        "The training model is designed by considering the data as a vector.\n",
        "This is a model dependent modification. Here we assume the image is\n",
        "a squared shape image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vxzUIK8Sedn"
      },
      "source": [
        "image_size = x_train.shape[1]\n",
        "input_size = image_size * image_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZnBo49lVWDM"
      },
      "source": [
        "## Resize and Normalize\n",
        "\n",
        "The next step is to continue the reshaping to a fit into a vector\n",
        "and normalize the data. Image values are from 0 - 255, so an \n",
        "easy way to normalize is to divide by the maximum value. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9qUX7mwSf-u"
      },
      "source": [
        "x_train = np.reshape(x_train, [-1, input_size])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = np.reshape(x_test, [-1, input_size])\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn89L_-zVxUB"
      },
      "source": [
        "## Create a Keras Model\n",
        "\n",
        "Keras is a neural network library. The summary function provides tabular summary on the model you created. And the plot_model function provides a grpah on the network you created. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3o_k-adkOy4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "447302ed-0fa4-41c4-fc49-f4f069d3f643"
      },
      "source": [
        "# Create Model\n",
        "# network parameters\n",
        "batch_size = 4\n",
        "hidden_units = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(hidden_units, input_dim=input_size))\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "plot_model(model, to_file='mlp-mnist.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwl6dlU3aStZ"
      },
      "source": [
        "## Compile and Train\n",
        "\n",
        "A keras model need to be compiled before it can be used to train\n",
        "the model. In the compile function, you can provide the optimization\n",
        "that you want to add, metrics you expect and the type of loss function\n",
        "you need to use. \n",
        "\n",
        "Here we use adam optimizer, a famous optimizer used in neural networks. \n",
        "\n",
        "The loss funtion we have used is the categorical_crossentropy. \n",
        "\n",
        "Once the model is compiled, then the fit function is called upon passing the number of epochs, traing data and batch size. \n",
        "\n",
        "The batch size determines the number of elements used per minibatch in optimizing the function. \n",
        "\n",
        "**Note: Change the number of epochs, batch size and see what happens.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUMyJyEmsM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f0d3d1-617b-4226-ad76-77cd3f6099c9"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define different epochs and batch sizes for assessment\n",
        "epoch_list = [5,10,20,50]\n",
        "batch_size_list = [4,16,32,64,128]\n",
        "\n",
        "# Loop 1: display results of training model for different epochs but fixed batch size  \n",
        "for i in epoch_list:\n",
        "  print(\"\\nTraining for\", i,\"epochs at batch size\", batch_size,\":\")\n",
        "  model.fit(x_train, y_train, epochs=i, batch_size=batch_size)\n",
        "  loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "  print(\"Test accuracy at\",i,\"epochs and batch size\",batch_size,\": %.2f%%\" % (100.0 * acc))\n",
        "\n",
        "# Loop 2: display results of training model for fixed epochs but different batch sizes \n",
        "for j in batch_size_list:\n",
        "  print(\"\\nTraining for 5 epochs at batch size\", j,\":\")\n",
        "  model.fit(x_train, y_train, epochs=5, batch_size=j) \n",
        "  loss, acc = model.evaluate(x_test, y_test, batch_size=j)\n",
        "  print(\"Test accuracy after 5 epochs and batch size\",j,\": %.2f%%\" % (100.0 * acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training for 5 epochs at batch size 4 :\n",
            "Epoch 1/5\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.4416 - accuracy: 0.8717\n",
            "Epoch 2/5\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.3176 - accuracy: 0.9111\n",
            "Epoch 3/5\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2990 - accuracy: 0.9164\n",
            "Epoch 4/5\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2975 - accuracy: 0.9167\n",
            "Epoch 5/5\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2971 - accuracy: 0.9163\n",
            "2500/2500 [==============================] - 2s 747us/step - loss: 0.2974 - accuracy: 0.9194\n",
            "Test accuracy at 5 epochs and batch size 4 : 91.94%\n",
            "\n",
            "Training for 10 epochs at batch size 4 :\n",
            "Epoch 1/10\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2870 - accuracy: 0.9202\n",
            "Epoch 2/10\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2838 - accuracy: 0.9201\n",
            "Epoch 3/10\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2820 - accuracy: 0.9207\n",
            "Epoch 4/10\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2794 - accuracy: 0.9205\n",
            "Epoch 5/10\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2771 - accuracy: 0.9227\n",
            "Epoch 6/10\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2750 - accuracy: 0.9229\n",
            "Epoch 7/10\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2733 - accuracy: 0.9233\n",
            "Epoch 8/10\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2731 - accuracy: 0.9241\n",
            "Epoch 9/10\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2708 - accuracy: 0.9245\n",
            "Epoch 10/10\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2694 - accuracy: 0.9247\n",
            "2500/2500 [==============================] - 2s 859us/step - loss: 0.2900 - accuracy: 0.9222\n",
            "Test accuracy at 10 epochs and batch size 4 : 92.22%\n",
            "\n",
            "Training for 20 epochs at batch size 4 :\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2691 - accuracy: 0.9253\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2687 - accuracy: 0.9239\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2685 - accuracy: 0.9248\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2656 - accuracy: 0.9260\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2661 - accuracy: 0.9244\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2651 - accuracy: 0.9263\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2658 - accuracy: 0.9245\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2634 - accuracy: 0.9261\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2632 - accuracy: 0.9264\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2634 - accuracy: 0.9259\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2630 - accuracy: 0.9273\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2629 - accuracy: 0.9269\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2609 - accuracy: 0.9279\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2620 - accuracy: 0.9268\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2615 - accuracy: 0.9274\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2604 - accuracy: 0.9271\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2600 - accuracy: 0.9278\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2611 - accuracy: 0.9265\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2593 - accuracy: 0.9269\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2586 - accuracy: 0.9277\n",
            "2500/2500 [==============================] - 2s 832us/step - loss: 0.3150 - accuracy: 0.9121\n",
            "Test accuracy at 20 epochs and batch size 4 : 91.21%\n",
            "\n",
            "Training for 50 epochs at batch size 4 :\n",
            "Epoch 1/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2582 - accuracy: 0.9276\n",
            "Epoch 2/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2585 - accuracy: 0.9276\n",
            "Epoch 3/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2583 - accuracy: 0.9272\n",
            "Epoch 4/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2583 - accuracy: 0.9267\n",
            "Epoch 5/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2577 - accuracy: 0.9279\n",
            "Epoch 6/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2575 - accuracy: 0.9275\n",
            "Epoch 7/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2582 - accuracy: 0.9288\n",
            "Epoch 8/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2580 - accuracy: 0.9276\n",
            "Epoch 9/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2564 - accuracy: 0.9277\n",
            "Epoch 10/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2568 - accuracy: 0.9275\n",
            "Epoch 11/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2569 - accuracy: 0.9288\n",
            "Epoch 12/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2566 - accuracy: 0.9279\n",
            "Epoch 13/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2558 - accuracy: 0.9282\n",
            "Epoch 14/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2555 - accuracy: 0.9284\n",
            "Epoch 15/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2565 - accuracy: 0.9272\n",
            "Epoch 16/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2558 - accuracy: 0.9280\n",
            "Epoch 17/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2555 - accuracy: 0.9275\n",
            "Epoch 18/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2546 - accuracy: 0.9286\n",
            "Epoch 19/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2548 - accuracy: 0.9283\n",
            "Epoch 20/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2543 - accuracy: 0.9286\n",
            "Epoch 21/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2550 - accuracy: 0.9278\n",
            "Epoch 22/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2552 - accuracy: 0.9285\n",
            "Epoch 23/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2545 - accuracy: 0.9283\n",
            "Epoch 24/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2541 - accuracy: 0.9292\n",
            "Epoch 25/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2544 - accuracy: 0.9291\n",
            "Epoch 26/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2540 - accuracy: 0.9282\n",
            "Epoch 27/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2541 - accuracy: 0.9284\n",
            "Epoch 28/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2531 - accuracy: 0.9290\n",
            "Epoch 29/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2549 - accuracy: 0.9287\n",
            "Epoch 30/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2537 - accuracy: 0.9288\n",
            "Epoch 31/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2531 - accuracy: 0.9296\n",
            "Epoch 32/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2544 - accuracy: 0.9283\n",
            "Epoch 33/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2531 - accuracy: 0.9291\n",
            "Epoch 34/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2528 - accuracy: 0.9294\n",
            "Epoch 35/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2533 - accuracy: 0.9293\n",
            "Epoch 36/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2528 - accuracy: 0.9288\n",
            "Epoch 37/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2532 - accuracy: 0.9287\n",
            "Epoch 38/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2522 - accuracy: 0.9287\n",
            "Epoch 39/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2532 - accuracy: 0.9297\n",
            "Epoch 40/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2516 - accuracy: 0.9290\n",
            "Epoch 41/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2531 - accuracy: 0.9285\n",
            "Epoch 42/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2516 - accuracy: 0.9285\n",
            "Epoch 43/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2519 - accuracy: 0.9304\n",
            "Epoch 44/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2532 - accuracy: 0.9295\n",
            "Epoch 45/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2522 - accuracy: 0.9284\n",
            "Epoch 46/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2522 - accuracy: 0.9295\n",
            "Epoch 47/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2526 - accuracy: 0.9294\n",
            "Epoch 48/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2518 - accuracy: 0.9291\n",
            "Epoch 49/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2513 - accuracy: 0.9290\n",
            "Epoch 50/50\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2510 - accuracy: 0.9297\n",
            "2500/2500 [==============================] - 2s 775us/step - loss: 0.3213 - accuracy: 0.9197\n",
            "Test accuracy at 50 epochs and batch size 4 : 91.97%\n",
            "\n",
            "Training for 5 epochs at batch size 4 :\n",
            "Epoch 1/5\n",
            "15000/15000 [==============================] - 17s 1ms/step - loss: 0.2517 - accuracy: 0.9298\n",
            "Epoch 2/5\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2521 - accuracy: 0.9291\n",
            "Epoch 3/5\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2499 - accuracy: 0.9297\n",
            "Epoch 4/5\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2525 - accuracy: 0.9284\n",
            "Epoch 5/5\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2517 - accuracy: 0.9289\n",
            "2500/2500 [==============================] - 2s 899us/step - loss: 0.3183 - accuracy: 0.9196\n",
            "Test accuracy after 5 epochs and batch size 4 : 91.96%\n",
            "\n",
            "Training for 5 epochs at batch size 16 :\n",
            "Epoch 1/5\n",
            "3750/3750 [==============================] - 7s 2ms/step - loss: 0.2307 - accuracy: 0.9359\n",
            "Epoch 2/5\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2317 - accuracy: 0.9351\n",
            "Epoch 3/5\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2320 - accuracy: 0.9348\n",
            "Epoch 4/5\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2319 - accuracy: 0.9346\n",
            "Epoch 5/5\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2322 - accuracy: 0.9345\n",
            "625/625 [==============================] - 1s 1ms/step - loss: 0.3033 - accuracy: 0.9216\n",
            "Test accuracy after 5 epochs and batch size 16 : 92.16%\n",
            "\n",
            "Training for 5 epochs at batch size 32 :\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2246 - accuracy: 0.9379\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2258 - accuracy: 0.9377\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2257 - accuracy: 0.9374\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2269 - accuracy: 0.9368\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2256 - accuracy: 0.9376\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3053 - accuracy: 0.9238\n",
            "Test accuracy after 5 epochs and batch size 32 : 92.38%\n",
            "\n",
            "Training for 5 epochs at batch size 64 :\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2206 - accuracy: 0.9393\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2211 - accuracy: 0.9388\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2215 - accuracy: 0.9384\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2218 - accuracy: 0.9382\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2217 - accuracy: 0.9380\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.9257\n",
            "Test accuracy after 5 epochs and batch size 64 : 92.57%\n",
            "\n",
            "Training for 5 epochs at batch size 128 :\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2177 - accuracy: 0.9400\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2176 - accuracy: 0.9401\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9395\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2185 - accuracy: 0.9391\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2184 - accuracy: 0.9400\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.9249\n",
            "Test accuracy after 5 epochs and batch size 128 : 92.49%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDAY7JYmbmOq"
      },
      "source": [
        "## Testing \n",
        "\n",
        "Now we can test the trained model. Use the evaluate function by passing\n",
        "test data and batch size and the accuracy and the loss value can be retrieved.\n",
        "\n",
        "**MNIST_V1.0|Exercise: Try to observe the network behavior by changing the number of epochs, batch size and record the best accuracy that you can gain. Here you can record what happens when you change these values. Describe your observations in 50-100 words.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sfTk_pcjXHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b2f90a-8523-4e48-8733-3dc2c23cc57d"
      },
      "source": [
        "# Assess for best accuracy gained by varying epochs and batch sizes\n",
        "best_accuracy = 0\n",
        "# Loop through different epochs and batch sizes\n",
        "for i in epoch_list:\n",
        "  for j in batch_size_list:\n",
        "    print(\"Assessing accuracy at\",i,\"epochs of training and batch size:\",j)\n",
        "    model.fit(x_train, y_train, epochs=i, batch_size=j)\n",
        "    loss, acc = model.evaluate(x_test, y_test, batch_size=j)\n",
        "    #Assess and record for best accuracy\n",
        "    if acc > best_accuracy:\n",
        "      best_accuracy = acc\n",
        "      optimum_batch_size = j\n",
        "      optimum_epochs = i\n",
        "      loss_at_optimum = loss\n",
        "    print(\"Intermediate best accuracy is currently: %.2f%%\" % (100.0 * best_accuracy),\"after\",optimum_epochs,\"epochs\",\"at batch size of\",optimum_batch_size,\"\\n\") \n",
        "print(\"\\nFinal result: Best accuracy is %.2f%%\" % (100.0 * best_accuracy),\"after\",optimum_epochs,\"epochs\",\"at batch size of\",optimum_batch_size,\"\\n\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Assessing accuracy at 5 epochs of training and batch size: 4\n",
            "Epoch 1/5\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2518 - accuracy: 0.9281\n",
            "Epoch 2/5\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2486 - accuracy: 0.9301\n",
            "Epoch 3/5\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2487 - accuracy: 0.9293\n",
            "Epoch 4/5\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2490 - accuracy: 0.9304\n",
            "Epoch 5/5\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2479 - accuracy: 0.9307\n",
            "2500/2500 [==============================] - 2s 817us/step - loss: 0.3239 - accuracy: 0.9182\n",
            "Intermediate best accuracy is currently: 91.82% after 5 epochs at batch size of 4 \n",
            "\n",
            "Assessing accuracy at 5 epochs of training and batch size: 16\n",
            "Epoch 1/5\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2295 - accuracy: 0.9369\n",
            "Epoch 2/5\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2306 - accuracy: 0.9362\n",
            "Epoch 3/5\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2300 - accuracy: 0.9359\n",
            "Epoch 4/5\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2303 - accuracy: 0.9362\n",
            "Epoch 5/5\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2303 - accuracy: 0.9349\n",
            "625/625 [==============================] - 1s 1ms/step - loss: 0.3052 - accuracy: 0.9244\n",
            "Intermediate best accuracy is currently: 92.44% after 5 epochs at batch size of 16 \n",
            "\n",
            "Assessing accuracy at 5 epochs of training and batch size: 32\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2230 - accuracy: 0.9380\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2241 - accuracy: 0.9382\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2246 - accuracy: 0.9363\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2246 - accuracy: 0.9372\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2242 - accuracy: 0.9373\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3038 - accuracy: 0.9229\n",
            "Intermediate best accuracy is currently: 92.44% after 5 epochs at batch size of 16 \n",
            "\n",
            "Assessing accuracy at 5 epochs of training and batch size: 64\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2190 - accuracy: 0.9399\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2197 - accuracy: 0.9391\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2202 - accuracy: 0.9384\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2204 - accuracy: 0.9390\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2204 - accuracy: 0.9385\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 0.3017 - accuracy: 0.9260\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 5 epochs of training and batch size: 128\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2160 - accuracy: 0.9409\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2164 - accuracy: 0.9400\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2167 - accuracy: 0.9395\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2169 - accuracy: 0.9396\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2171 - accuracy: 0.9398\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.9251\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 10 epochs of training and batch size: 4\n",
            "Epoch 1/10\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2503 - accuracy: 0.9294\n",
            "Epoch 2/10\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2484 - accuracy: 0.9295\n",
            "Epoch 3/10\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2473 - accuracy: 0.9305\n",
            "Epoch 4/10\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2481 - accuracy: 0.9305\n",
            "Epoch 5/10\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2481 - accuracy: 0.9300\n",
            "Epoch 6/10\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2481 - accuracy: 0.9304\n",
            "Epoch 7/10\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2487 - accuracy: 0.9295\n",
            "Epoch 8/10\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2488 - accuracy: 0.9299\n",
            "Epoch 9/10\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2480 - accuracy: 0.9310\n",
            "Epoch 10/10\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2486 - accuracy: 0.9307\n",
            "2500/2500 [==============================] - 2s 801us/step - loss: 0.3306 - accuracy: 0.9157\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 10 epochs of training and batch size: 16\n",
            "Epoch 1/10\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2281 - accuracy: 0.9365\n",
            "Epoch 2/10\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2294 - accuracy: 0.9358\n",
            "Epoch 3/10\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2300 - accuracy: 0.9360\n",
            "Epoch 4/10\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2294 - accuracy: 0.9361\n",
            "Epoch 5/10\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2289 - accuracy: 0.9359\n",
            "Epoch 6/10\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2285 - accuracy: 0.9360\n",
            "Epoch 7/10\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2293 - accuracy: 0.9362\n",
            "Epoch 8/10\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2284 - accuracy: 0.9355\n",
            "Epoch 9/10\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2292 - accuracy: 0.9363\n",
            "Epoch 10/10\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2291 - accuracy: 0.9362\n",
            "625/625 [==============================] - 1s 1ms/step - loss: 0.3140 - accuracy: 0.9212\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 10 epochs of training and batch size: 32\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2212 - accuracy: 0.9387\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2224 - accuracy: 0.9384\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2234 - accuracy: 0.9372\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2232 - accuracy: 0.9363\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2231 - accuracy: 0.9373\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2228 - accuracy: 0.9379\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2232 - accuracy: 0.9377\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2227 - accuracy: 0.9380\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2230 - accuracy: 0.9377\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2226 - accuracy: 0.9382\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.9198\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 10 epochs of training and batch size: 64\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2179 - accuracy: 0.9396\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2181 - accuracy: 0.9391\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2180 - accuracy: 0.9390\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2185 - accuracy: 0.9392\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2186 - accuracy: 0.9391\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2188 - accuracy: 0.9387\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2179 - accuracy: 0.9388\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2185 - accuracy: 0.9386\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2187 - accuracy: 0.9390\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2186 - accuracy: 0.9391\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 0.3062 - accuracy: 0.9246\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 10 epochs of training and batch size: 128\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2147 - accuracy: 0.9405\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2147 - accuracy: 0.9406\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2149 - accuracy: 0.9401\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2153 - accuracy: 0.9399\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2151 - accuracy: 0.9400\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2153 - accuracy: 0.9404\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9401\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.9403\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9402\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2153 - accuracy: 0.9398\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.9234\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 20 epochs of training and batch size: 4\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2488 - accuracy: 0.9293\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2463 - accuracy: 0.9304\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2466 - accuracy: 0.9305\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2454 - accuracy: 0.9297\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2466 - accuracy: 0.9307\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2464 - accuracy: 0.9299\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2466 - accuracy: 0.9299\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2479 - accuracy: 0.9291\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2461 - accuracy: 0.9302\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2479 - accuracy: 0.9293\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2463 - accuracy: 0.9298\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2484 - accuracy: 0.9304\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2465 - accuracy: 0.9300\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2469 - accuracy: 0.9304\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2473 - accuracy: 0.9309\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2482 - accuracy: 0.9307\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2472 - accuracy: 0.9305\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2457 - accuracy: 0.9313\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2476 - accuracy: 0.9295\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2465 - accuracy: 0.9305\n",
            "2500/2500 [==============================] - 2s 819us/step - loss: 0.3218 - accuracy: 0.9197\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 20 epochs of training and batch size: 16\n",
            "Epoch 1/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2260 - accuracy: 0.9370\n",
            "Epoch 2/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2289 - accuracy: 0.9356\n",
            "Epoch 3/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2283 - accuracy: 0.9350\n",
            "Epoch 4/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2279 - accuracy: 0.9362\n",
            "Epoch 5/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2277 - accuracy: 0.9357\n",
            "Epoch 6/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2276 - accuracy: 0.9366\n",
            "Epoch 7/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2277 - accuracy: 0.9358\n",
            "Epoch 8/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2273 - accuracy: 0.9367\n",
            "Epoch 9/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2283 - accuracy: 0.9355\n",
            "Epoch 10/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2273 - accuracy: 0.9369\n",
            "Epoch 11/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2266 - accuracy: 0.9364\n",
            "Epoch 12/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2273 - accuracy: 0.9360\n",
            "Epoch 13/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2268 - accuracy: 0.9364\n",
            "Epoch 14/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2268 - accuracy: 0.9360\n",
            "Epoch 15/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2266 - accuracy: 0.9362\n",
            "Epoch 16/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2270 - accuracy: 0.9370\n",
            "Epoch 17/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2264 - accuracy: 0.9364\n",
            "Epoch 18/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2269 - accuracy: 0.9356\n",
            "Epoch 19/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2261 - accuracy: 0.9363\n",
            "Epoch 20/20\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2264 - accuracy: 0.9362\n",
            "625/625 [==============================] - 1s 1ms/step - loss: 0.3116 - accuracy: 0.9209\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 20 epochs of training and batch size: 32\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2191 - accuracy: 0.9385\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2210 - accuracy: 0.9376\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2211 - accuracy: 0.9377\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2212 - accuracy: 0.9377\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2213 - accuracy: 0.9386\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2210 - accuracy: 0.9383\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2211 - accuracy: 0.9381\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2209 - accuracy: 0.9380\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2208 - accuracy: 0.9378\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2213 - accuracy: 0.9379\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2209 - accuracy: 0.9379\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2209 - accuracy: 0.9383\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2208 - accuracy: 0.9380\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2210 - accuracy: 0.9373\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2208 - accuracy: 0.9380\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2202 - accuracy: 0.9383\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2207 - accuracy: 0.9378\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2208 - accuracy: 0.9375\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2205 - accuracy: 0.9381\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2205 - accuracy: 0.9386\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.9239\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 20 epochs of training and batch size: 64\n",
            "Epoch 1/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2155 - accuracy: 0.9397\n",
            "Epoch 2/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2160 - accuracy: 0.9401\n",
            "Epoch 3/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2165 - accuracy: 0.9397\n",
            "Epoch 4/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2165 - accuracy: 0.9396\n",
            "Epoch 5/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2168 - accuracy: 0.9399\n",
            "Epoch 6/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2168 - accuracy: 0.9398\n",
            "Epoch 7/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2164 - accuracy: 0.9395\n",
            "Epoch 8/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2167 - accuracy: 0.9395\n",
            "Epoch 9/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2171 - accuracy: 0.9392\n",
            "Epoch 10/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2168 - accuracy: 0.9393\n",
            "Epoch 11/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2169 - accuracy: 0.9387\n",
            "Epoch 12/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2167 - accuracy: 0.9397\n",
            "Epoch 13/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2166 - accuracy: 0.9389\n",
            "Epoch 14/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2170 - accuracy: 0.9402\n",
            "Epoch 15/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2163 - accuracy: 0.9392\n",
            "Epoch 16/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2167 - accuracy: 0.9392\n",
            "Epoch 17/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2166 - accuracy: 0.9394\n",
            "Epoch 18/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2168 - accuracy: 0.9401\n",
            "Epoch 19/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2165 - accuracy: 0.9391\n",
            "Epoch 20/20\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2162 - accuracy: 0.9388\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 0.3171 - accuracy: 0.9230\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 20 epochs of training and batch size: 128\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.9413\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.9411\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2128 - accuracy: 0.9409\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2129 - accuracy: 0.9409\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2131 - accuracy: 0.9407\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2135 - accuracy: 0.9413\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9404\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.9406\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2133 - accuracy: 0.9408\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2136 - accuracy: 0.9405\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.9408\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9400\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9402\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2137 - accuracy: 0.9397\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2133 - accuracy: 0.9402\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2136 - accuracy: 0.9405\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2137 - accuracy: 0.9402\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.9407\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.9403\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.9407\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.9233\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 50 epochs of training and batch size: 4\n",
            "Epoch 1/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2455 - accuracy: 0.9299\n",
            "Epoch 2/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2423 - accuracy: 0.9301\n",
            "Epoch 3/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2434 - accuracy: 0.9308\n",
            "Epoch 4/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2445 - accuracy: 0.9306\n",
            "Epoch 5/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2444 - accuracy: 0.9300\n",
            "Epoch 6/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2446 - accuracy: 0.9309\n",
            "Epoch 7/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2442 - accuracy: 0.9307\n",
            "Epoch 8/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2440 - accuracy: 0.9305\n",
            "Epoch 9/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2454 - accuracy: 0.9294\n",
            "Epoch 10/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2448 - accuracy: 0.9299\n",
            "Epoch 11/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2447 - accuracy: 0.9303\n",
            "Epoch 12/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2444 - accuracy: 0.9317\n",
            "Epoch 13/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2450 - accuracy: 0.9312\n",
            "Epoch 14/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2454 - accuracy: 0.9305\n",
            "Epoch 15/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2460 - accuracy: 0.9311\n",
            "Epoch 16/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2445 - accuracy: 0.9306\n",
            "Epoch 17/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2459 - accuracy: 0.9300\n",
            "Epoch 18/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2457 - accuracy: 0.9307\n",
            "Epoch 19/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2442 - accuracy: 0.9316\n",
            "Epoch 20/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2452 - accuracy: 0.9305\n",
            "Epoch 21/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2443 - accuracy: 0.9312\n",
            "Epoch 22/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2449 - accuracy: 0.9305\n",
            "Epoch 23/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2457 - accuracy: 0.9304\n",
            "Epoch 24/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2443 - accuracy: 0.9308\n",
            "Epoch 25/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2462 - accuracy: 0.9290\n",
            "Epoch 26/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2441 - accuracy: 0.9311\n",
            "Epoch 27/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2451 - accuracy: 0.9304\n",
            "Epoch 28/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2448 - accuracy: 0.9312\n",
            "Epoch 29/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2455 - accuracy: 0.9309\n",
            "Epoch 30/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2451 - accuracy: 0.9309\n",
            "Epoch 31/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2458 - accuracy: 0.9301\n",
            "Epoch 32/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2452 - accuracy: 0.9297\n",
            "Epoch 33/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2452 - accuracy: 0.9303\n",
            "Epoch 34/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2457 - accuracy: 0.9292\n",
            "Epoch 35/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2453 - accuracy: 0.9301\n",
            "Epoch 36/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2465 - accuracy: 0.9302\n",
            "Epoch 37/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2447 - accuracy: 0.9306\n",
            "Epoch 38/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2461 - accuracy: 0.9314\n",
            "Epoch 39/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2453 - accuracy: 0.9312\n",
            "Epoch 40/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2459 - accuracy: 0.9298\n",
            "Epoch 41/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2462 - accuracy: 0.9298\n",
            "Epoch 42/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2453 - accuracy: 0.9310\n",
            "Epoch 43/50\n",
            "15000/15000 [==============================] - 20s 1ms/step - loss: 0.2468 - accuracy: 0.9301\n",
            "Epoch 44/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2452 - accuracy: 0.9310\n",
            "Epoch 45/50\n",
            "15000/15000 [==============================] - 19s 1ms/step - loss: 0.2455 - accuracy: 0.9298\n",
            "Epoch 46/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2461 - accuracy: 0.9307\n",
            "Epoch 47/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2447 - accuracy: 0.9309\n",
            "Epoch 48/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2448 - accuracy: 0.9301\n",
            "Epoch 49/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2456 - accuracy: 0.9311\n",
            "Epoch 50/50\n",
            "15000/15000 [==============================] - 18s 1ms/step - loss: 0.2448 - accuracy: 0.9303\n",
            "2500/2500 [==============================] - 2s 823us/step - loss: 0.3354 - accuracy: 0.9197\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 50 epochs of training and batch size: 16\n",
            "Epoch 1/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2245 - accuracy: 0.9366\n",
            "Epoch 2/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2266 - accuracy: 0.9358\n",
            "Epoch 3/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2262 - accuracy: 0.9361\n",
            "Epoch 4/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2260 - accuracy: 0.9359\n",
            "Epoch 5/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2268 - accuracy: 0.9365\n",
            "Epoch 6/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2265 - accuracy: 0.9370\n",
            "Epoch 7/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2260 - accuracy: 0.9366\n",
            "Epoch 8/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2259 - accuracy: 0.9370\n",
            "Epoch 9/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2266 - accuracy: 0.9358\n",
            "Epoch 10/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2259 - accuracy: 0.9365\n",
            "Epoch 11/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2253 - accuracy: 0.9368\n",
            "Epoch 12/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2256 - accuracy: 0.9364\n",
            "Epoch 13/50\n",
            "3750/3750 [==============================] - 7s 2ms/step - loss: 0.2254 - accuracy: 0.9374\n",
            "Epoch 14/50\n",
            "3750/3750 [==============================] - 7s 2ms/step - loss: 0.2250 - accuracy: 0.9376\n",
            "Epoch 15/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2258 - accuracy: 0.9355\n",
            "Epoch 16/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2258 - accuracy: 0.9359\n",
            "Epoch 17/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2247 - accuracy: 0.9360\n",
            "Epoch 18/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2254 - accuracy: 0.9358\n",
            "Epoch 19/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2250 - accuracy: 0.9363\n",
            "Epoch 20/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2249 - accuracy: 0.9376\n",
            "Epoch 21/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2250 - accuracy: 0.9373\n",
            "Epoch 22/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2249 - accuracy: 0.9371\n",
            "Epoch 23/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2249 - accuracy: 0.9363\n",
            "Epoch 24/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2248 - accuracy: 0.9362\n",
            "Epoch 25/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2250 - accuracy: 0.9367\n",
            "Epoch 26/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2248 - accuracy: 0.9364\n",
            "Epoch 27/50\n",
            "3750/3750 [==============================] - 7s 2ms/step - loss: 0.2248 - accuracy: 0.9366\n",
            "Epoch 28/50\n",
            "3750/3750 [==============================] - 7s 2ms/step - loss: 0.2252 - accuracy: 0.9359\n",
            "Epoch 29/50\n",
            "3750/3750 [==============================] - 7s 2ms/step - loss: 0.2252 - accuracy: 0.9360\n",
            "Epoch 30/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2250 - accuracy: 0.9366\n",
            "Epoch 31/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2248 - accuracy: 0.9366\n",
            "Epoch 32/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2255 - accuracy: 0.9361\n",
            "Epoch 33/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2248 - accuracy: 0.9359\n",
            "Epoch 34/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2246 - accuracy: 0.9360\n",
            "Epoch 35/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2246 - accuracy: 0.9367\n",
            "Epoch 36/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2247 - accuracy: 0.9371\n",
            "Epoch 37/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2243 - accuracy: 0.9366\n",
            "Epoch 38/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2245 - accuracy: 0.9374\n",
            "Epoch 39/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2246 - accuracy: 0.9363\n",
            "Epoch 40/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2243 - accuracy: 0.9365\n",
            "Epoch 41/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2242 - accuracy: 0.9368\n",
            "Epoch 42/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2248 - accuracy: 0.9369\n",
            "Epoch 43/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2247 - accuracy: 0.9365\n",
            "Epoch 44/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2246 - accuracy: 0.9369\n",
            "Epoch 45/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2244 - accuracy: 0.9369\n",
            "Epoch 46/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2243 - accuracy: 0.9367\n",
            "Epoch 47/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2243 - accuracy: 0.9365\n",
            "Epoch 48/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2246 - accuracy: 0.9366\n",
            "Epoch 49/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2243 - accuracy: 0.9366\n",
            "Epoch 50/50\n",
            "3750/3750 [==============================] - 6s 2ms/step - loss: 0.2248 - accuracy: 0.9371\n",
            "625/625 [==============================] - 1s 1ms/step - loss: 0.3297 - accuracy: 0.9210\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 50 epochs of training and batch size: 32\n",
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2172 - accuracy: 0.9393\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2193 - accuracy: 0.9382\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2184 - accuracy: 0.9388\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2190 - accuracy: 0.9384\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2190 - accuracy: 0.9381\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2187 - accuracy: 0.9393\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2197 - accuracy: 0.9383\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2192 - accuracy: 0.9379\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2190 - accuracy: 0.9385\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2190 - accuracy: 0.9383\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2189 - accuracy: 0.9386\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2189 - accuracy: 0.9384\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2187 - accuracy: 0.9388\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2190 - accuracy: 0.9389\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2189 - accuracy: 0.9383\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2186 - accuracy: 0.9386\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2189 - accuracy: 0.9384\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2191 - accuracy: 0.9386\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2186 - accuracy: 0.9386\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2187 - accuracy: 0.9387\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2187 - accuracy: 0.9386\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2182 - accuracy: 0.9379\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2185 - accuracy: 0.9385\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2188 - accuracy: 0.9382\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2184 - accuracy: 0.9388\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2188 - accuracy: 0.9378\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2185 - accuracy: 0.9386\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2183 - accuracy: 0.9386\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2182 - accuracy: 0.9387\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2186 - accuracy: 0.9385\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2183 - accuracy: 0.9382\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2184 - accuracy: 0.9394\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2183 - accuracy: 0.9390\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2181 - accuracy: 0.9374\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2181 - accuracy: 0.9390\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2181 - accuracy: 0.9391\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2178 - accuracy: 0.9390\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2180 - accuracy: 0.9389\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2186 - accuracy: 0.9389\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2188 - accuracy: 0.9385\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2192 - accuracy: 0.9381\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2179 - accuracy: 0.9391\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2180 - accuracy: 0.9384\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2179 - accuracy: 0.9387\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2184 - accuracy: 0.9390\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2181 - accuracy: 0.9383\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2182 - accuracy: 0.9391\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2184 - accuracy: 0.9384\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2178 - accuracy: 0.9386\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2189 - accuracy: 0.9387\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.9206\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 50 epochs of training and batch size: 64\n",
            "Epoch 1/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2132 - accuracy: 0.9402\n",
            "Epoch 2/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2134 - accuracy: 0.9403\n",
            "Epoch 3/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2140 - accuracy: 0.9403\n",
            "Epoch 4/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2145 - accuracy: 0.9402\n",
            "Epoch 5/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2144 - accuracy: 0.9400\n",
            "Epoch 6/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2148 - accuracy: 0.9395\n",
            "Epoch 7/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2143 - accuracy: 0.9396\n",
            "Epoch 8/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2145 - accuracy: 0.9395\n",
            "Epoch 9/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2145 - accuracy: 0.9399\n",
            "Epoch 10/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2147 - accuracy: 0.9404\n",
            "Epoch 11/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2141 - accuracy: 0.9398\n",
            "Epoch 12/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2147 - accuracy: 0.9398\n",
            "Epoch 13/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2141 - accuracy: 0.9396\n",
            "Epoch 14/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2146 - accuracy: 0.9400\n",
            "Epoch 15/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2142 - accuracy: 0.9401\n",
            "Epoch 16/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2143 - accuracy: 0.9396\n",
            "Epoch 17/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2142 - accuracy: 0.9396\n",
            "Epoch 18/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2144 - accuracy: 0.9403\n",
            "Epoch 19/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2141 - accuracy: 0.9403\n",
            "Epoch 20/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2142 - accuracy: 0.9397\n",
            "Epoch 21/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2146 - accuracy: 0.9398\n",
            "Epoch 22/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2140 - accuracy: 0.9401\n",
            "Epoch 23/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2141 - accuracy: 0.9398\n",
            "Epoch 24/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2144 - accuracy: 0.9398\n",
            "Epoch 25/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2141 - accuracy: 0.9400\n",
            "Epoch 26/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2143 - accuracy: 0.9392\n",
            "Epoch 27/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2146 - accuracy: 0.9396\n",
            "Epoch 28/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2136 - accuracy: 0.9399\n",
            "Epoch 29/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2144 - accuracy: 0.9401\n",
            "Epoch 30/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2139 - accuracy: 0.9396\n",
            "Epoch 31/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2143 - accuracy: 0.9400\n",
            "Epoch 32/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2145 - accuracy: 0.9396\n",
            "Epoch 33/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2141 - accuracy: 0.9398\n",
            "Epoch 34/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2143 - accuracy: 0.9393\n",
            "Epoch 35/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2140 - accuracy: 0.9398\n",
            "Epoch 36/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2144 - accuracy: 0.9397\n",
            "Epoch 37/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2141 - accuracy: 0.9398\n",
            "Epoch 38/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2140 - accuracy: 0.9397\n",
            "Epoch 39/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2139 - accuracy: 0.9399\n",
            "Epoch 40/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2144 - accuracy: 0.9397\n",
            "Epoch 41/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2143 - accuracy: 0.9399\n",
            "Epoch 42/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2137 - accuracy: 0.9402\n",
            "Epoch 43/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2142 - accuracy: 0.9394\n",
            "Epoch 44/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2139 - accuracy: 0.9402\n",
            "Epoch 45/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2142 - accuracy: 0.9401\n",
            "Epoch 46/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2137 - accuracy: 0.9395\n",
            "Epoch 47/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2139 - accuracy: 0.9396\n",
            "Epoch 48/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2139 - accuracy: 0.9400\n",
            "Epoch 49/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2139 - accuracy: 0.9397\n",
            "Epoch 50/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2140 - accuracy: 0.9401\n",
            "157/157 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.9197\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "Assessing accuracy at 50 epochs of training and batch size: 128\n",
            "Epoch 1/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2104 - accuracy: 0.9411\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2103 - accuracy: 0.9415\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2106 - accuracy: 0.9409\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2107 - accuracy: 0.9413\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9411\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2111 - accuracy: 0.9416\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2117 - accuracy: 0.9407\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2114 - accuracy: 0.9404\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2110 - accuracy: 0.9412\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2111 - accuracy: 0.9412\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9408\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2111 - accuracy: 0.9413\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2114 - accuracy: 0.9409\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2111 - accuracy: 0.9406\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2111 - accuracy: 0.9408\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2114 - accuracy: 0.9412\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9412\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9408\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2114 - accuracy: 0.9409\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2114 - accuracy: 0.9406\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2113 - accuracy: 0.9403\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9414\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9409\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2111 - accuracy: 0.9414\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9416\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2108 - accuracy: 0.9406\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9408\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9414\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9410\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9408\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2111 - accuracy: 0.9418\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2111 - accuracy: 0.9413\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2109 - accuracy: 0.9412\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2110 - accuracy: 0.9408\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9412\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2111 - accuracy: 0.9409\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2109 - accuracy: 0.9403\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9416\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9415\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2109 - accuracy: 0.9412\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2112 - accuracy: 0.9413\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2109 - accuracy: 0.9413\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2109 - accuracy: 0.9409\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9409\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2115 - accuracy: 0.9409\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9406\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2110 - accuracy: 0.9408\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2111 - accuracy: 0.9408\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2111 - accuracy: 0.9405\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2109 - accuracy: 0.9410\n",
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.9219\n",
            "Intermediate best accuracy is currently: 92.60% after 5 epochs at batch size of 64 \n",
            "\n",
            "\n",
            "Final result: Best accuracy is 92.60% after 5 epochs at batch size of 64 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2fDpqnfcEmC"
      },
      "source": [
        "## Final Note\n",
        "\n",
        "This programme can be defined as a hello world programme in deep\n",
        "learning. Objective of this exercise is not to teach you the depths of\n",
        "deep learning. But to teach you basic concepts that may need to design a\n",
        "simple network to solve a problem. Before running the whole code, read\n",
        "all the instructions before a code section. \n",
        "\n",
        "## Homework\n",
        "\n",
        "**Solve Exercise MNIST_V1.0.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocPstTerfs0S"
      },
      "source": [
        "# Observations \n",
        "\n",
        "Increasing epochs for training the neural network resulted in a general decrease in loss and increase in accuracy *of the model fit function*. Propagating more cycles of training through the network optimized weights in the model, yielding reductions in loss and gains in accuracy on training data. A similar trend was observed with increasing the batch sizes used. \n",
        "\n",
        "Best accuracy of the model on test data was on a batch size of about 64 at 5 or 10 epochs. This could be because variance in the test data was more in line with the less optimized model at lower epochs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UufRkOsSRaUR"
      },
      "source": [
        "\n",
        "### Reference: \n",
        "\n",
        "[Orignal Source to Source Code](https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras)\n"
      ]
    }
  ]
}