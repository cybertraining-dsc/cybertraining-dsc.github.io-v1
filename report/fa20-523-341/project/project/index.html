<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.79.1"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Cybertraining</title><meta property="og:title" content><meta property="og:description" content="Music Mood Classification   Status: final, Type: Project
Kunaal Shah, fa20-523-341, Edit
Abstract Music analysis on an individual level is incredibly subjective. A particular song can leave polarizing impressions on the emotions of its listener. One person may find a sense of calm in a piece, while another feels energy. In this study we examine the audio and lyrical features of popular songs in order to find relationships in a song&rsquo;s lyrics, audio features, and its valence."><meta property="og:type" content="article"><meta property="og:url" content="/report/fa20-523-341/project/project/"><meta property="og:site_name" content="Cybertraining"><meta itemprop=name content><meta itemprop=description content="Music Mood Classification   Status: final, Type: Project
Kunaal Shah, fa20-523-341, Edit
Abstract Music analysis on an individual level is incredibly subjective. A particular song can leave polarizing impressions on the emotions of its listener. One person may find a sense of calm in a piece, while another feels energy. In this study we examine the audio and lyrical features of popular songs in order to find relationships in a song&rsquo;s lyrics, audio features, and its valence."><meta itemprop=wordCount content="3692"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Music Mood Classification   Status: final, Type: Project
Kunaal Shah, fa20-523-341, Edit
Abstract Music analysis on an individual level is incredibly subjective. A particular song can leave polarizing impressions on the emotions of its listener. One person may find a sense of calm in a piece, while another feels energy. In this study we examine the audio and lyrical features of popular songs in order to find relationships in a song&rsquo;s lyrics, audio features, and its valence."><link rel=preload href=/scss/main.min.541f105c34f11dd207a9775a00ff9f1f41884f48abc84ab786959ab04f5fa8a0.css as=style><link href=/scss/main.min.541f105c34f11dd207a9775a00ff9f1f41884f48abc84ab786959ab04f5fa8a0.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script></head><body class=td-page><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zM197.0804 232.033c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><rect x="198.8952" y="225.1043" style="fill:#5b7fc0" width="122.6266" height="13.8671"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zM197.0804 177.6188c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><rect x="198.8952" y="170.69" style="fill:#d95140" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zM197.5309 286.4723c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><rect x="199.3456" y="279.5436" style="fill:#56a55c" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zM197.0804 340.5784c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><rect x="198.8952" y="333.6497" style="fill:#f1bc42" width="122.6266" height="13.8671"/></g></g></svg></span><span class="text-uppercase font-weight-bold">Cybertraining</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/about/><span>About</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/courses/><span>Courses</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/modules/><span>Modules</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/tutorial/><span>Tutorials</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/report/><span class=active>Reports</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/report/2021/><span>Reports 2021</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog/><span>Blog</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/contrib/><span>Contributing</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><br><ul><li><a href=/courses/ai-first/>AI-First</a></li><ul><li><a href=/modules/ai-first/2021/course_lectures/>Lectures</a></li><li><a href=/modules/ai-first/2021/introduction/>Introduction</a></li><li><a href=/courses/ai-first>Other Material</a></li><li><a href=/report/2021.html>Reports</a></li></ul></ul><hr><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-docs-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="collapse td-sidebar-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/report/ class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section"><div style=border:1px;border-style:solid;border-color:#d1d1d1;padding:0>Reports</div></a></li><ul><li class="collapse show" id=report><a class="td-sidebar-link td-sidebar-link__page" id=m-report2021 href=/report/2021/>Reports 2021</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapicloudmeshopenapireadme href=/report/cloudmesh-openapi/cloudmesh/openapi/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapicloudmeshopenapiscikitlearnreadme href=/report/cloudmesh-openapi/cloudmesh/openapi/scikitlearn/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapideprecatedopenapireadme href=/report/cloudmesh-openapi/deprecated/openapi/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapideprecatedpaperresultsinstallcloud_lscpu href=/report/cloudmesh-openapi/deprecated/paper/results/install/cloud_lscpu/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapidockerubuntu1910todo href=/report/cloudmesh-openapi/docker/ubuntu19.10/todo/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapidockerubuntu2004-sklearntodo href=/report/cloudmesh-openapi/docker/ubuntu20.04-sklearn/todo/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapidockerubuntu2004todo href=/report/cloudmesh-openapi/docker/ubuntu20.04/todo/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapiproject_review href=/report/cloudmesh-openapi/project_review/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapireadme-adam href=/report/cloudmesh-openapi/readme-adam/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapireadme-eigenfaces-test href=/report/cloudmesh-openapi/readme-eigenfaces-test/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapireadme-scikitlearn href=/report/cloudmesh-openapi/readme-scikitlearn/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapireadme-security href=/report/cloudmesh-openapi/readme-security/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapireadme href=/report/cloudmesh-openapi/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsadd-floatreadme href=/report/cloudmesh-openapi/tests/add-float/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsadd-jsonreadme href=/report/cloudmesh-openapi/tests/add-json/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsgenerator-natural-langgooglecloudvmset href=/report/cloudmesh-openapi/tests/generator-natural-lang/googlecloudvmset/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsgregorreadme href=/report/cloudmesh-openapi/tests/gregor/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsimage-analysisreadme href=/report/cloudmesh-openapi/tests/image-analysis/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsreadme href=/report/cloudmesh-openapi/tests/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsserver-cpureadme href=/report/cloudmesh-openapi/tests/server-cpu/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapiteststest_mlperfreadme-source href=/report/cloudmesh-openapi/tests/test_mlperf/readme-source/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapiteststest_mlperfreadme href=/report/cloudmesh-openapi/tests/test_mlperf/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapiteststest_mlperfresultsreadme href=/report/cloudmesh-openapi/tests/test_mlperf/results/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapiteststimeseries-examplereadme href=/report/cloudmesh-openapi/tests/timeseries-example/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-301assignment6assignment6 href=/report/fa20-523-301/assignment6/assignment6/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-301projectmisc_filesblank href=/report/fa20-523-301/project/misc_files/blank/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-301projectplan href=/report/fa20-523-301/project/plan/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-301projectproject href=/report/fa20-523-301/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-301test href=/report/fa20-523-301/test/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-302assignment6wearables_and_ai href=/report/fa20-523-302/assignment6/wearables_and_ai/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-302projectplan href=/report/fa20-523-302/project/plan/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-302projectproject href=/report/fa20-523-302/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-304projectproject href=/report/fa20-523-304/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-304reportreport href=/report/fa20-523-304/report/report/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-304test href=/report/fa20-523-304/test/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-305homework3cody_harris_hw3 href=/report/fa20-523-305/homework3/cody_harris_hw3/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-305homework6cody_harris_hw6 href=/report/fa20-523-305/homework6/cody_harris_hw6/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-305projectproject href=/report/fa20-523-305/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-305test href=/report/fa20-523-305/test/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-307assignment6assignment6 href=/report/fa20-523-307/assignment6/assignment6/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-307projectproject href=/report/fa20-523-307/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-308hw7task_3_next_steps href=/report/fa20-523-308/hw7/task_3_next_steps/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-308projectproject href=/report/fa20-523-308/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-309projectproject href=/report/fa20-523-309/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-312assignment6assignment6 href=/report/fa20-523-312/assignment6/assignment6/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-312projectproject href=/report/fa20-523-312/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-313assignment5 href=/report/fa20-523-313/assignment5/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-313assignment6assignment6 href=/report/fa20-523-313/assignment6/assignment6/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-313projectproject href=/report/fa20-523-313/project/project/></a></li></ul></ul></nav></div></div><div class="d-none d-xl-block col-xl-2 td-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"><a href=https://github.com/cybertraining-dsc/cybertraining-dsc.github.io/edit/main/content/en/report/fa20-523-341/project/project.md target=_blank><i class="fa fa-edit fa-fw"></i>Edit this page</a>
<a href="https://github.com/cybertraining-dsc/cybertraining-dsc.github.io/issues/new?title=" target=_blank><i class="fab fa-github fa-fw"></i>Create documentation issue</a>
<a href=https://github.com/cybertraining-dsc/cybertraining-dsc.github.io/issues/new target=_blank><i class="fas fa-tasks fa-fw"></i>Create project issue</a></div><nav id=TableOfContents><ul><li><a href=#1-introduction>1. Introduction</a></li><li><a href=#2-related-work>2. Related Work</a></li><li><a href=#3-datasets>3. Datasets</a></li><li><a href=#4-analysis>4. Analysis</a><ul><li><a href=#41-accumulation-of-audio-features-and-lyrics>4.1 Accumulation of audio features and lyrics</a></li><li><a href=#42-performance-of-sentiment-analysis-on-lyrics>4.2 Performance of sentiment analysis on lyrics</a></li><li><a href=#43-description-of-select-data-fields>4.3 Description of select data fields</a></li><li><a href=#44-preliminary-analysis-of-data>4.4 Preliminary Analysis of Data</a></li><li><a href=#45-scatterplot-analysis>4.5 Scatterplot Analysis</a></li><li><a href=#46-linear-and-polynomial-regression-analyses>4.6 Linear and Polynomial Regression Analyses</a></li><li><a href=#47-multivariate-regression-analysis>4.7 Multivariate Regression Analysis</a></li></ul></li><li><a href=#5-benchmarks>5. Benchmarks</a></li><li><a href=#6-conclusion>6. Conclusion</a></li><li><a href=#7-acknowledgements>7. Acknowledgements</a></li><li><a href=#8-references>8. References</a></li></ul></nav></div><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><nav aria-label=breadcrumb class="d-none d-md-block d-print-none"><ol class="breadcrumb spb-1"><li class=breadcrumb-item><a href=/report/>Reports</a></li><li class="breadcrumb-item active" aria-current=page><a href=/report/fa20-523-341/project/project/></a></li></ol></nav><div class=td-content><h1></h1><h1 id=music-mood-classification>Music Mood Classification</h1><p><a href=https://github.com/cybertraining-dsc/fa20-523-341/actions><img src=https://github.com/cybertraining-dsc/fa20-523-341/workflows/Check%20Report/badge.svg alt="Check Report"></a>
<a href=https://github.com/cybertraining-dsc/fa20-523-341/actions><img src=https://github.com/cybertraining-dsc/fa20-523-341/workflows/Status/badge.svg alt=Status></a>
Status: final, Type: Project</p><p>Kunaal Shah, <a href=https://github.com/cybertraining-dsc/fa20-523-341/>fa20-523-341</a>, <a href=https://github.com/cybertraining-dsc/fa20-523-341/blob/master/project/project.md>Edit</a></p><div class="pageinfo pageinfo-primary"><h2 id=abstract>Abstract</h2><p>Music analysis on an individual level is incredibly subjective. A particular song can leave polarizing impressions on the emotions of its listener. One person may find a sense of calm in a piece, while another feels energy. In this study we examine the audio and lyrical features of popular songs in order to find relationships in a song&rsquo;s lyrics, audio features, and its valence. We take advantage of the audio data provided by Spotify for each song in their massive library, as well as lyrical data from popular music news and lyrics site, Genius.</p><p>Contents</p><div class=toc><nav id=TableOfContents><ul><li><a href=#1-introduction>1. Introduction</a></li><li><a href=#2-related-work>2. Related Work</a></li><li><a href=#3-datasets>3. Datasets</a></li><li><a href=#4-analysis>4. Analysis</a><ul><li><a href=#41-accumulation-of-audio-features-and-lyrics>4.1 Accumulation of audio features and lyrics</a></li><li><a href=#42-performance-of-sentiment-analysis-on-lyrics>4.2 Performance of sentiment analysis on lyrics</a></li><li><a href=#43-description-of-select-data-fields>4.3 Description of select data fields</a></li><li><a href=#44-preliminary-analysis-of-data>4.4 Preliminary Analysis of Data</a></li><li><a href=#45-scatterplot-analysis>4.5 Scatterplot Analysis</a></li><li><a href=#46-linear-and-polynomial-regression-analyses>4.6 Linear and Polynomial Regression Analyses</a></li><li><a href=#47-multivariate-regression-analysis>4.7 Multivariate Regression Analysis</a></li></ul></li><li><a href=#5-benchmarks>5. Benchmarks</a></li><li><a href=#6-conclusion>6. Conclusion</a></li><li><a href=#7-acknowledgements>7. Acknowledgements</a></li><li><a href=#8-references>8. References</a></li></ul></nav></div></div><p><strong>Keywords:</strong> music, mood classification, audio, audio content analysis, lyrics, lyrical analysis, big data, spotify, emotion</p><h2 id=1-introduction>1. Introduction</h2><p>The overall mood of a musical piece is generally very difficult to decipher due to the highly subjective nature of music. One person might think a song is energetic and happy, while another may think it is quite sad. This can be attributed to varying interpretations of tone and lyrics in song between different listeners. In this project we study both the audio and lyrical patterns of a song through machine learning and natural language processing (NLP) to find a relationship between the song&rsquo;s lyrics and its valence, or its overall positivity.</p><h2 id=2-related-work>2. Related Work</h2><p>Previous studies take three different ways in classifying the mood of a song according to various mood models by analyzing audio, analyzing lyrics, and analyzing lyrics and audio. Most of these studies have been successful in their goals but have uses a limited collection of songs/words for their analysis <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. Perhaps obviously, the best results come when combining audio and lyrics. A simple weighting is given by a study from the University of Illinois to categorize moods of a song by audio and lyrical content analysis, A simple weighting is given by a study from the University of Illinois to categorize moods of a song by audio and lyrical content analysis.</p><p><code>phybrid = \alpha plyrics + (1 - \alpha )paudio</code></p><p>When researching existing work, we found two applications that approach music recommendations based on mood, one is called &lsquo;moooodify&rsquo;, a free web application developed by an independent music enthusiast, Siddharth Ahuja <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. Another website, Organize Your Music, aims to organize a Spotify user&rsquo;s music library based on mood, genre, popularity, style, and other categories <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>. However, both of these applications do not seem to take into account any lyrical analysis of a song.</p><p>Lyrics of a song can be used to learn a lot about music from lexical pattern analysis to gender, genre, and mood analyses. For example, in an individual study a researcher found that female artists tend to mention girls, women, and friends a lot, while male artists sing about late Saturday Nights, play and love <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>. Another popular project, SongSim, used repetition to visualize the parts of a song <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>. Findings such as these can be used to uncover the gender of an artist based on their lyrics. Similarly, by use of NLP tools, lyrical text can be analyzed to elicit the mood and emotion of a song.</p><h2 id=3-datasets>3. Datasets</h2><p>For the audio content analysis portion of this project, we use Spotify&rsquo;s Web API, which provides a great amount audio data for every song in Spotify&rsquo;s song collection, including valence, energy, and danceability <sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>.</p><p>For the lyrical analysis portion of this project, we use Genius&rsquo;s API to pull lyrics information for a song. Genius is a website where users submit lyrics and annotations to several popular songs <sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup>. To perform sentiment analysis on a set of lyrics collected from Genius, we use the NLTK Vader library.</p><h2 id=4-analysis>4. Analysis</h2><p>For the purposes of this study, we analyze a track&rsquo;s lyrics and assign them scores based on their positivity, negativity, and neutrality. We then append this data to the audio feature data we receive from Spotify. To compare and find relationships and meaningfulness in using lyrics and audio features to predict a song&rsquo;s valence, we employ several statistical and machine learning approaches. We try linear regression and polynomial regression to find relationships between several features of a track and a song&rsquo;s valence. Then we perform multivariate linear regression to find how accurately we can predict a song&rsquo;s valence based on the audio and lyrical features available in our dataset.</p><h3 id=41-accumulation-of-audio-features-and-lyrics>4.1 Accumulation of audio features and lyrics</h3><p>From our data sources, we collected data for roughly 10000 of the most popular songs released between 2017 and 2020, taking account of several audio and lyrical features present in the track. We gathered this data by hand, first querying the most popular 2000 newly released songs in each year between 2017 and 2020. We then sent requests to Genius to gather lyrics for each song. Some songs, even though they were popular, did not have lyrics present on Genius, these songs were excluded from our dataset. With BeautifulSoup, we extracted and cleaned up the lyrics, removing anything that is not a part of the song&rsquo;s lyrics like annotations left by users, section headings (Chorus, Hook, etc), and empty lines. After exclusions our data covered 6551 Spotify tracks.</p><h3 id=42-performance-of-sentiment-analysis-on-lyrics>4.2 Performance of sentiment analysis on lyrics</h3><p>With a song&rsquo;s lyrics in hand, we used NLTK&rsquo;s sentiment module, Vader, to read each line in the lyrics. NLTK Vader Sentiment Intensity Analyzer is a pretrained machine learning model that reads a line of text and assigns it scores of positivity, negativity, neutrality, and and overall compound score. We marked lines with a compound score greater than 0.5 as positive, less than -0.1 as negative, and anything in between as neutral. We then found the percentages of positive, negative, and neutral lines in a song&rsquo;s composition and saved them to our dataset.</p><p>We performed a brief analysis of the legibility of the Vader module in determining sentiment on four separate strings. &ldquo;I&rsquo;m happy&rdquo; and &ldquo;I&rsquo;m so happy&rdquo; were used to compare two positive lines, &ldquo;I&rsquo;m happy&rdquo; was expected to have a positive compound score, but slightly less positive than &ldquo;I&rsquo;m so happy&rdquo;. Similarly, we used two negative lines &ldquo;I&rsquo;m sad&rdquo; and the slightly more extreme, &ldquo;I&rsquo;m so sad&rdquo; which were expected to result in negative compound scores with &ldquo;I&rsquo;m sad&rdquo; being less negative than &ldquo;I&rsquo;m so sad&rdquo;.</p><pre><code>Scores for 'I'm happy': {
    'neg': 0.0, 
    'neu': 0.213, 
    'pos': 0.787, 
    'compound': 0.5719
}

Scores for 'I'm so happy': {
    'neg': 0.0, 
    'neu': 0.334, 
    'pos': 0.666, 
    'compound': 0.6115
}

Scores for 'I'm sad': {
    'neg': 0.756, 
    'neu': 0.244, 
    'pos': 0.0, 
    'compound': -0.4767
}

Scores for 'I'm so sad': {
    'neg': 0.629, 
    'neu': 0.371, 
    'pos': 0.0, 
    'compound': -0.5256
}
</code></pre><p>While these results confirmed our expectations, a few issues come to the table with our use of the Vader module. One is that Vader takes into consideration additional string features such as punctuation in its determination of score, meaning &ldquo;I&rsquo;m so sad!&rdquo; will be more negative than &ldquo;I&rsquo;m so sad&rdquo;. Since lyrics on Genius are contributed by the community, in most cases there is a lack of consistency using accurate punctuation. Additionally, in some cases there can be typos present in a line of lyrics, both of which can skew our data. However we determined that our method in using the Vader module is suitable for our project as we simply want to determine if a track is positive or negative without needing to be too specific. Another issue is that our implementation of Vader acts only on English words. Again, since lyrics on Genius are contributed by the community, there could be errors in our data from misspelled word contributions as well as sections or entire lyrics written in different languages.</p><p>In addition to performing sentiment analysis on the lyrics, we tokenized the lyrics, removing common words such as &lsquo;a&rsquo;, &lsquo;the&rsquo;,&lsquo;for&rsquo;, etc. This was done to collect data on the number of meaningful and number of non-repeating words in each song. Albeit while this data was never used in our study, it could prove useful in future studies.</p><p><em>Table 1</em> displays a snapshot of the data we collected from seven tracks released in 2020. The dataset contains 27 fields, 12 of which describe the audio features of a track, and 8 of which describe the lyrics of the track. For the purpose of this study we exclude the use of audio features key, duration, and time signature.</p><p><strong>Table 1:</strong> Snapshot of dataset containing tracks released in 2020</p><table><thead><tr><th>danceability</th><th>energy</th><th>key</th><th>loudness</th><th>speechiness</th><th>acousticness</th><th>instrumentalness</th><th>liveness</th><th>valence</th><th>tempo</th><th>duration_ms</th><th>time_signature</th><th>name</th><th>artist</th><th>num_positive</th><th>num_negative</th><th>num_neutral</th><th>positivity</th><th>negativity</th><th>neutrality</th><th>word_count</th><th>unique_word_count</th></tr></thead><tbody><tr><td>0.709</td><td>0.548</td><td>10</td><td>-8.493</td><td>0.353</td><td>0.65</td><td>1.59E-06</td><td>0.133</td><td>0.543</td><td>83.995</td><td>160000</td><td>4</td><td>What You Know Bout Love</td><td>Pop Smoke</td><td>7</td><td>2</td><td>33</td><td>0.166666667</td><td>0.047619048</td><td>0.785714286</td><td>209</td><td>130</td></tr><tr><td>0.799</td><td>0.66</td><td>1</td><td>-6.153</td><td>0.079</td><td>0.256</td><td>0</td><td>0.111</td><td>0.471</td><td>140.04</td><td>195429</td><td>4</td><td>Lemonade</td><td>Internet Money</td><td>8</td><td>15</td><td>34</td><td>0.140350877</td><td>0.263157895</td><td>0.596491228</td><td>307</td><td>177</td></tr><tr><td>0.514</td><td>0.73</td><td>1</td><td>-5.934</td><td>0.0598</td><td>0.00146</td><td>9.54E-05</td><td>0.0897</td><td>0.334</td><td>171.005</td><td>200040</td><td>4</td><td>Blinding Lights</td><td>The Weeknd</td><td>3</td><td>10</td><td>22</td><td>0.085714286</td><td>0.285714286</td><td>0.628571429</td><td>150</td><td>75</td></tr><tr><td>0.65</td><td>0.613</td><td>9</td><td>-6.13</td><td>0.128</td><td>0.00336</td><td>0</td><td>0.267</td><td>0.0804</td><td>149.972</td><td>194621</td><td>4</td><td>Wishing Well</td><td>Juice WRLD</td><td>0</td><td>22</td><td>30</td><td>0</td><td>0.423076923</td><td>0.576923077</td><td>238</td><td>104</td></tr><tr><td>0.737</td><td>0.802</td><td>0</td><td>-4.771</td><td>0.0878</td><td>0.468</td><td>0</td><td>0.0931</td><td>0.682</td><td>144.015</td><td>172325</td><td>4</td><td>positions</td><td>Ariana Grande</td><td>10</td><td>5</td><td>33</td><td>0.208333333</td><td>0.104166667</td><td>0.6875</td><td>178</td><td>73</td></tr><tr><td>0.357</td><td>0.425</td><td>5</td><td>-7.301</td><td>0.0333</td><td>0.584</td><td>0</td><td>0.322</td><td>0.27</td><td>102.078</td><td>198040</td><td>3</td><td>Heather</td><td>Conan Gray</td><td>3</td><td>4</td><td>22</td><td>0.103448276</td><td>0.137931034</td><td>0.75862069</td><td>114</td><td>66</td></tr><tr><td>0.83</td><td>0.585</td><td>0</td><td>-6.476</td><td>0.094</td><td>0.237</td><td>0</td><td>0.248</td><td>0.485</td><td>109.978</td><td>173711</td><td>4</td><td>34+35</td><td>Ariana Grande</td><td>3</td><td>13</td><td>52</td><td>0.044117647</td><td>0.191176471</td><td>0.764705882</td><td>249</td><td>127</td></tr></tbody></table><h3 id=43-description-of-select-data-fields>4.3 Description of select data fields</h3><p>The following terms defined are important in our analyses. In our data set most terms contain are represented by a value between 0 and 1, indicating least to most. For example, looking at the first two rows in <em>Table 1</em>, we can see that the track by the artist, Pop Smoke, has a greater speechiness score, indicating a greater percentage of that song contains spoken word.</p><ul><li><strong>Danceability:</strong> uses several musical elements (tempo, stability, beat strength, regularity) to determine how suitable a given track is for dancing</li><li><strong>Energy:</strong> measures intensity of a song</li><li><strong>Loudness:</strong> a songs overall loudness measured in decibels</li><li><strong>Speechiness:</strong> identifies how much of a track contains spoken word</li><li><strong>Acousticness:</strong> confidence of a track being acoustic, or with physical instruments</li><li><strong>Instrumentalness:</strong> confidence of a track having no vocals</li><li><strong>Liveness:</strong> confidence of a track being a live recording</li><li><strong>Valence:</strong> predicts the overall happiness, or positivity of a track based on its musical features</li><li><strong>Tempo:</strong> the average beats per minute of a track</li><li><strong>Positivity:</strong> percentage of lines in a track&rsquo;s lyrics determined to have a positive sentiment score</li><li><strong>Negativity:</strong> percentage of lines in a track&rsquo;s lyrics determined to have a negative sentiment score</li><li><strong>Neutrality:</strong> percentage of lines in a track&rsquo;s lyrics determined to have a neutral sentiment score</li></ul><p>Out of these fields, we seek to find which audio features correlate to a song&rsquo;s valence and if our positivity and negativity scores of a song&rsquo;s lyrics provide any meaningfulness in determining a song&rsquo;s positivity. For the purpose of this study we mainly focus on valence, energy, danceability, positivity, and negativity.</p><h3 id=44-preliminary-analysis-of-data>4.4 Preliminary Analysis of Data</h3><p>When calculating averages of the feature fields captured in our dataset, we found it interesting that based on our lyrical interpretation, tracks between 2017 and 2020 tended to be more negative than positive. The average negativity score for a track in our dataset was 0.21 which means 21% of the lines in the track were deemed to have negative connotation, while having a 0.08 positivity score.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-341/raw/main/project/images/all_tracks_heatmap.png alt=Heatmap></p><p><strong>Figure 1:</strong> Heatmap of data with fields valence, energy, danceability, positivity, negativity</p><p>Backed by <em>Figure 1</em>, we find that track lyrics tend to be more negative than positive. However for the most part, even with tracks with negative lyrics, the valence, or overall happiness of the audio features hovers around 0.5; indicating that most songs tend to have neutral audio features. Looking at tracks with lyrics that are highly positive we find that the valence rises to about 0.7 to 0.8 and that songs with extremely high negatively also cause the valence to drop to the 0.3 range. These observations indicate that only extremes in lyrical sentiment correlate significantly in a song&rsquo;s valence, as some songs with negative lyrics may also be fast-tempo and energetic, keeping the valence relatively high compared to lyrical composition. This is shown in our visualization, where both tracks with positive and negative lyricals have high energy and danceability values, indicating fast-tempos and high-pitches.</p><h3 id=45-scatterplot-analysis>4.5 Scatterplot Analysis</h3><p><img src=https://github.com/cybertraining-dsc/fa20-523-341/raw/main/project/images/audio_features_scatterplots.png alt=Audio_Features_Scatterplots></p><p><strong>Figure 2:</strong> Scatterplots showing relation of features danceability, energy, speechiness, positivity, negativity, and neutrality to valence.</p><p><em>Figure 2</em> describes the relation of several data fields we collected to a song&rsquo;s valence, or its overall positivity. We find that the positivity and negativity plots reflect that of the speechiness plot in that there seems to be little correlation between the x and y axes. On the other hand neutrality seems to show a positive correlation between a song&rsquo;s lyrical content and its respective valence. If a song is more neutral, it seems more likely to have a higher valence.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-341/raw/main/project/images/spotify_distributions.png alt="Spotify Distributions"></p><p><strong>Figure 3:</strong> Distributions of field values across the Spotify music library <sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>.</p><p>Our scatterplots do show consistency with the expected distributions exemplified in the Spotify API documentation, as shown in <em>Figure 3</em>. In the top three plots, which use values for audio features obtained exclusively obtained from the audio features given by Spotify, we can see the these matching distributions which imply that most songs fall in the 0.4 to 0.8 range for danceability, energy, and valence, and 0 to 0.1 for speechiness. The low distribution in speechiness can be explained by music features being more dependant on instruments and sounds than spoken word. A track with higher than 0.33 speechiness score indicates that the track is very high in spoken word content over music, like a poetry recitation, talk show clip, etc <sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>.</p><h3 id=46-linear-and-polynomial-regression-analyses>4.6 Linear and Polynomial Regression Analyses</h3><p>We performed a simple linear regression test against valence with the audio and lyrical features described in <em>Figure 2</em> and <em>Figure 3</em>. Like the charts show, it was hard to find any linear correlation between the fields. <em>Table 2</em> displays the r-squared results that we obtained when applying linear regression to find the relationship between a song&rsquo;s feature and its valence. The only features that indicate potential relationships with a song&rsquo;s valence are energy, and danceability, as definitions of energy and and danceability indicate some semblance of positivity as well.</p><p><strong>Table 2:</strong> R-Squared results obtained from linear regression application on select fields against valence</p><table><thead><tr><th>Feature</th><th>R-Squared</th></tr></thead><tbody><tr><td>Positivity</td><td>-0.090859047</td></tr><tr><td>Negativity</td><td>-0.039686828</td></tr><tr><td>Neutrality</td><td>0.093002783</td></tr><tr><td>Energy</td><td>0.367113611</td></tr><tr><td>Danceability</td><td>0.324412662</td></tr><tr><td>Speechiness</td><td>0.066492856</td></tr></tbody></table><p>Since we found little relation between the selected features and valence, we tried applying polynomial regression with the same features as shown in <em>Table 3</em>. Again, we failed to find any relationship between a feature in our dataset and the song&rsquo;s valence. Energy and danceability once again were found to have the highest relationship with valence. We speculate that some of the data we have is misleading the regression applications; as mentioned before, we found some issues in reading sentiment in the lyrics we collected due to misspelled words, inaccurate punctuations, and non-english words.</p><p><strong>Table 3:</strong> R-Square results obtained from polynomial regression application on select data fields against valence</p><table><thead><tr><th>Feature</th><th>R-Squared</th></tr></thead><tbody><tr><td>Positivity</td><td>0.013164307</td></tr><tr><td>Negativity</td><td>0.001588184</td></tr><tr><td>Neutrality</td><td>0.010308495</td></tr><tr><td>Energy</td><td>0.136822113</td></tr><tr><td>Danceability</td><td>0.113119545</td></tr><tr><td>Speechiness</td><td>0.008913925</td></tr></tbody></table><h3 id=47-multivariate-regression-analysis>4.7 Multivariate Regression Analysis</h3><p>We performed multivariate regression tests to predict a song&rsquo;s valence with a training set of 5500 tracks and a test set of 551 tracks. Our first test only included four independent variables: neutrality, energy, danceability, and speechiness. Our second test included all numerical fields available in our data, adding loudness, acousticness, liveness, instrumentalness, tempo, positivity, word count, and unique word count to the regression coefficient calculations. In both tests we calculated the relative mean squared error (RMSE) between our predicted values and the actual values of a song&rsquo;s valence given several features. Our RMSEs were 0.1982 and 0.1905 respectively, indicating that as expected, adding additional pertinent independent variables gave slightly better results. However given that a song&rsquo;s valence is captured between 0 and 1.0, and both our RSMEs were approximately 0.19, it is unclear how significant the results of these tests are. <em>Figure 4</em> and <em>Figure 5</em> show the calculated differences between the predicted and actual values for the first 50 tracks in our testing dataset for each regression test respectively.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-341/raw/main/project/images/multivariate_regression_1.png alt="Multivariate Regression 1"></p><p><strong>Figure 4:</strong> Differences between expected and predicted values with application of multivariate regression model with 4 independent variables</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-341/raw/main/project/images/multivariate_regression_2.png alt="Multivariate Regression 2"></p><p><strong>Figure 5:</strong> Differences between expected and predicted values with application of multivariate regression model with 12 independent variables</p><h2 id=5-benchmarks>5. Benchmarks</h2><p><em>Table 4</em> displays the benchmarks we received from key parts of our analyses. As expected, creating our dataset took a longer amount of time relative to the rest of the benchmarks. This is because accumulating the data involved sending two requests to online sources, and running the sentiment intensity analyzer on the lyrics received from the Genius API calls. Getting the sentiment of a line of text itself did not take much time at all. We found it interesting that applying multivariate regression on our dataset was much quicker than calculating averages on our dataset with numpy, and that it was the fastest process to complete.</p><p><strong>Table 4:</strong> Benchmark Results</p><table><thead><tr><th>Name</th><th>Status</th><th>Time</th><th>Sum</th><th>Start</th><th>tag</th><th>Node</th><th>User</th><th>OS</th><th>Version</th></tr></thead><tbody><tr><td>Create dataset of 10 tracks</td><td>ok</td><td>12.971</td><td>168.523</td><td>2020-12-07 00:19:30</td><td></td><td>884e3d61f237</td><td>collab</td><td>Linux</td><td>#1 SMP Thu Jul 23 08:00:38 PDT 2020</td></tr><tr><td>Sentiment Intensity Analyzer on a line of lyrical text</td><td>ok</td><td>0.001</td><td>0.005</td><td>2020-12-07 00:19:49</td><td></td><td>884e3d61f237</td><td>collab</td><td>Linux</td><td>#1 SMP Thu Jul 23 08:00:38 PDT 2020</td></tr><tr><td>Load dataset</td><td>ok</td><td>0.109</td><td>1.08</td><td>2020-12-07 00:19:59</td><td></td><td>884e3d61f237</td><td>collab</td><td>Linux</td><td>#1 SMP Thu Jul 23 08:00:38 PDT 2020</td></tr><tr><td>Calculate averages of values in dataset</td><td>ok</td><td>0.275</td><td>0.597</td><td>2020-12-07 00:19:59</td><td></td><td>884e3d61f237</td><td>collab</td><td>Linux</td><td>#1 SMP Thu Jul 23 08:00:38 PDT 2020</td></tr><tr><td>Multivariate Regression Analysis on dataset</td><td>ok</td><td>0.03</td><td>0.151</td><td>2020-12-07 00:21:49</td><td></td><td>884e3d61f237</td><td>collab</td><td>Linux</td><td>#1 SMP Thu Jul 23 08:00:38 PDT 2020</td></tr><tr><td>Generate and display heatmap of data</td><td>ok</td><td>0.194</td><td>0.194</td><td>2020-12-07 00:20:03</td><td></td><td>884e3d61f237</td><td>collab</td><td>Linux</td><td>#1 SMP Thu Jul 23 08:00:38 PDT 2020</td></tr><tr><td>Plot differences</td><td>ok</td><td>0.504</td><td>1.473</td><td>2020-12-07 00:21:50</td><td></td><td>884e3d61f237</td><td>collab</td><td>Linux</td><td>#1 SMP Thu Jul 23 08:00:38 PDT 2020</td></tr></tbody></table><h2 id=6-conclusion>6. Conclusion</h2><p>We received inconclusive results from our study. The linear and polynomial regression tests that we performed, showed little correlation between our lyrical features and a track&rsquo;s valence. This was backed by our multivariate regression test which performed with a RSME score of about 0.19 on our dataset. Since valence is recorded on a scale from 0 to 1.0, this means that our predictions typically fall within 20% of the actual value, which is considerably inaccurate. As previous studies have shown massive improvements in combining lyrical and audio features for machine learning applications in music, we believe that the blame for our low scores falls heavily on our approach to assigning sentiment scores on our lyrics <sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. Future studies should consider the presence of foreign lyrics and the potential inaccuracies of community submitted lyrics.</p><p>There are several other elements of this study that could be improved upon in future iterations. In this project we only worked with songs released after the beginning of 2017, but obviously, people would still enjoy listening to songs from previous years. The Spotiy API contains audio features data for every song in its library, so it would be worth collecting that data on every song for usage in the generation of song recommendations. Secondly, our data set excluded songs on Spotify, whose lyrics could not be found easily on Genius.com. We should have handled these cases by attempting to find the lyrics from other popular websites which store music lyrics. And lastly, we worked with a very small dataset relative to the total amount of songs that exist, or that are available on Spotify. There is great possibility in repeating this study quite easily with a greater selection of songs. We were surprised by how small the file sizes were of our dataset of 6551 songs, the aggregated data set being only 2.3 megabytes in size. Using that value, a set of one million songs can be estimated to only be around 350 megabytes.</p><h2 id=7-acknowledgements>7. Acknowledgements</h2><p>We would like to give our thanks to Dr. Geoffrey Fox, Dr. Gregor von Laszewski, and the other associate instructors who taught FA20-BL-ENGR-E534-11530: Big Data Applications during the Fall 2020 semester at Indiana University, Bloomington for their suggestions and assistance in compiling this project report. Additionally we would like to thank the students who contributed to Piazza by either answering questions that we had ourselves, or giving their own suggestions and experiences in building projects. In taking this course we learned of several applications of and use cases for big data applications, and gained the knowledge to build our own big data projects.</p><h2 id=8-references>8. References</h2><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>Kashyap, N., Choudhury, T., Chaudhary, D. K., & Lal, R. (2016). Mood Based Classification of Music by Analyzing Lyrical Data Using Text Mining. 2016 International Conference on Micro-Electronics and Telecommunication Engineering (ICMETE). doi:10.1109/icmete.2016.65 <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>Ahuja, S. (2019, September 25). Sort your music by any mood - Introducing moooodify. Retrieved November 17, 2020, from <a href=https://blog.usejournal.com/sort-your-music-by-any-mood-introducing-moooodify-41749e80faab>https://blog.usejournal.com/sort-your-music-by-any-mood-introducing-moooodify-41749e80faab</a> <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>Lamere, P. (2016, August 6). Organize Your Music. Retrieved November 17, 2020, from <a href=http://organizeyourmusic.playlistmachinery.com/>http://organizeyourmusic.playlistmachinery.com/</a> <a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p>Jeong, J. (2019, January 19). What Songs Tell Us About: Text Mining with Lyrics. Retrieved November 17, 2020, from <a href=https://towardsdatascience.com/what-songs-tell-us-about-text-mining-with-lyrics-ca80f98b3829>https://towardsdatascience.com/what-songs-tell-us-about-text-mining-with-lyrics-ca80f98b3829</a> <a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5 role=doc-endnote><p>Morris, C. (2016). SongSim. Retrieved November 17, 2020, from <a href=https://colinmorris.github.io/SongSim/>https://colinmorris.github.io/SongSim/</a> <a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6 role=doc-endnote><p>Get Audio Features for a Track. (2020). Retrieved November 17, 2020, from <a href=https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/>https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/</a> <a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7 role=doc-endnote><p>Genius API Documentation. (2020). Retrieved November 17, 2020, from <a href=https://docs.genius.com/>https://docs.genius.com/</a> <a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:8 role=doc-endnote><p>Hu, X., & Downie, J. S. (2010). Improving mood classification in music digital libraries by combining lyrics and audio. Proceedings of the 10th Annual Joint Conference on Digital Libraries - JCDL &lsquo;10. doi:10.1145/1816123.1816146 <a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section><div class="text-muted mt-5 pt-3 border-top">Last modified January 1, 0001</div></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Gregor von Laszewski" aria-label="Gregor von Laszewski"><a class=text-white target=_blank href=https://laszewski.github.io><i class="fa fa-envelope"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/cybertraining-dsc/cybertraining-dsc.github.io/><i class="fab fa-github"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2021 Indiana University, 2020 All Rights Reserved</small><p class=mt-2><a href=/about/>About Cybertraining</a></p></div></div></div></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script><script src=https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js integrity=sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy crossorigin=anonymous></script><script src=/js/main.min.29b0315468c00226fa6f4556a9cebc0ac4fe1ce1457a01b22c0a06b329877383.js integrity="sha256-KbAxVGjAAib6b0VWqc68CsT+HOFFegGyLAoGsymHc4M=" crossorigin=anonymous></script></body></html>