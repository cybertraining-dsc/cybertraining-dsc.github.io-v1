<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.79.1"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Cybertraining</title><meta property="og:title" content><meta property="og:description" content="Big Data Application in E-commerce   Status: final, Type: Project
Tao Liu, fa20-523-339, Edit
Abstract As a result of the last twenty year&rsquo;s Internet development globally, the E-commerce industry is getting stronger and stronger. While customers enjoyed their convenient online purchase environment, E-commerce sees the potential for the data and information customers left during their online shopping process. One fundamental usage for this information is to perform a Recommendation Strategy to give customers potential products they would also like to purchase."><meta property="og:type" content="article"><meta property="og:url" content="/report/fa20-523-339/project/project/"><meta property="og:site_name" content="Cybertraining"><meta itemprop=name content><meta itemprop=description content="Big Data Application in E-commerce   Status: final, Type: Project
Tao Liu, fa20-523-339, Edit
Abstract As a result of the last twenty year&rsquo;s Internet development globally, the E-commerce industry is getting stronger and stronger. While customers enjoyed their convenient online purchase environment, E-commerce sees the potential for the data and information customers left during their online shopping process. One fundamental usage for this information is to perform a Recommendation Strategy to give customers potential products they would also like to purchase."><meta itemprop=wordCount content="3473"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Big Data Application in E-commerce   Status: final, Type: Project
Tao Liu, fa20-523-339, Edit
Abstract As a result of the last twenty year&rsquo;s Internet development globally, the E-commerce industry is getting stronger and stronger. While customers enjoyed their convenient online purchase environment, E-commerce sees the potential for the data and information customers left during their online shopping process. One fundamental usage for this information is to perform a Recommendation Strategy to give customers potential products they would also like to purchase."><link rel=preload href=/scss/main.min.541f105c34f11dd207a9775a00ff9f1f41884f48abc84ab786959ab04f5fa8a0.css as=style><link href=/scss/main.min.541f105c34f11dd207a9775a00ff9f1f41884f48abc84ab786959ab04f5fa8a0.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script></head><body class=td-page><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zM197.0804 232.033c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><rect x="198.8952" y="225.1043" style="fill:#5b7fc0" width="122.6266" height="13.8671"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zM197.0804 177.6188c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><rect x="198.8952" y="170.69" style="fill:#d95140" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zM197.5309 286.4723c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><rect x="199.3456" y="279.5436" style="fill:#56a55c" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zM197.0804 340.5784c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><rect x="198.8952" y="333.6497" style="fill:#f1bc42" width="122.6266" height="13.8671"/></g></g></svg></span><span class="text-uppercase font-weight-bold">Cybertraining</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/about/><span>About</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/courses/><span>Courses</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/modules/><span>Modules</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/tutorial/><span>Tutorials</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/report/><span class=active>Reports</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/report/2021/><span>Reports 2021</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog/><span>Blog</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/contrib/><span>Contributing</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><br><ul><li><a href=/courses/ai-first/>AI-First</a></li><ul><li><a href=/modules/ai-first/2021/course_lectures/>Lectures</a></li><li><a href=/modules/ai-first/2021/introduction/>Introduction</a></li><li><a href=/courses/ai-first>Other Material</a></li><li><a href=/report/2021>Reports</a></li></ul></ul><hr><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-docs-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="collapse td-sidebar-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3"><li class=td-sidebar-nav__section-title><a href=/report/ class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section"><div style=border:1px;border-style:solid;border-color:#d1d1d1;padding:0>Reports</div></a></li><ul><li class="collapse show" id=report><a class="td-sidebar-link td-sidebar-link__page" id=m-report2021 href=/report/2021/>Reports 2021</a>
<a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapicloudmeshopenapireadme href=/report/cloudmesh-openapi/cloudmesh/openapi/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapicloudmeshopenapiscikitlearnreadme href=/report/cloudmesh-openapi/cloudmesh/openapi/scikitlearn/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapideprecatedopenapireadme href=/report/cloudmesh-openapi/deprecated/openapi/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapideprecatedpaperresultsinstallcloud_lscpu href=/report/cloudmesh-openapi/deprecated/paper/results/install/cloud_lscpu/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapidockerubuntu1910todo href=/report/cloudmesh-openapi/docker/ubuntu19.10/todo/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapidockerubuntu2004-sklearntodo href=/report/cloudmesh-openapi/docker/ubuntu20.04-sklearn/todo/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapidockerubuntu2004todo href=/report/cloudmesh-openapi/docker/ubuntu20.04/todo/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapiproject_review href=/report/cloudmesh-openapi/project_review/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapireadme-adam href=/report/cloudmesh-openapi/readme-adam/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapireadme-eigenfaces-test href=/report/cloudmesh-openapi/readme-eigenfaces-test/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapireadme-scikitlearn href=/report/cloudmesh-openapi/readme-scikitlearn/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapireadme-security href=/report/cloudmesh-openapi/readme-security/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapireadme href=/report/cloudmesh-openapi/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsadd-floatreadme href=/report/cloudmesh-openapi/tests/add-float/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsadd-jsonreadme href=/report/cloudmesh-openapi/tests/add-json/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsgenerator-natural-langgooglecloudvmset href=/report/cloudmesh-openapi/tests/generator-natural-lang/googlecloudvmset/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsgregorreadme href=/report/cloudmesh-openapi/tests/gregor/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsimage-analysisreadme href=/report/cloudmesh-openapi/tests/image-analysis/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsreadme href=/report/cloudmesh-openapi/tests/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapitestsserver-cpureadme href=/report/cloudmesh-openapi/tests/server-cpu/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapiteststest_mlperfreadme-source href=/report/cloudmesh-openapi/tests/test_mlperf/readme-source/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapiteststest_mlperfreadme href=/report/cloudmesh-openapi/tests/test_mlperf/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapiteststest_mlperfresultsreadme href=/report/cloudmesh-openapi/tests/test_mlperf/results/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportcloudmesh-openapiteststimeseries-examplereadme href=/report/cloudmesh-openapi/tests/timeseries-example/readme/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-301assignment6assignment6 href=/report/fa20-523-301/assignment6/assignment6/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-301projectmisc_filesblank href=/report/fa20-523-301/project/misc_files/blank/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-301projectplan href=/report/fa20-523-301/project/plan/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-301projectproject href=/report/fa20-523-301/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-301test href=/report/fa20-523-301/test/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-302assignment6wearables_and_ai href=/report/fa20-523-302/assignment6/wearables_and_ai/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-302projectplan href=/report/fa20-523-302/project/plan/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-302projectproject href=/report/fa20-523-302/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-304projectproject href=/report/fa20-523-304/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-304reportreport href=/report/fa20-523-304/report/report/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-304test href=/report/fa20-523-304/test/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-305homework3cody_harris_hw3 href=/report/fa20-523-305/homework3/cody_harris_hw3/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-305homework6cody_harris_hw6 href=/report/fa20-523-305/homework6/cody_harris_hw6/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-305projectproject href=/report/fa20-523-305/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-305test href=/report/fa20-523-305/test/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-307assignment6assignment6 href=/report/fa20-523-307/assignment6/assignment6/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-307projectproject href=/report/fa20-523-307/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-308hw7task_3_next_steps href=/report/fa20-523-308/hw7/task_3_next_steps/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-308projectproject href=/report/fa20-523-308/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-309projectproject href=/report/fa20-523-309/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-312assignment6assignment6 href=/report/fa20-523-312/assignment6/assignment6/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-312projectproject href=/report/fa20-523-312/project/project/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-313assignment5 href=/report/fa20-523-313/assignment5/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-313assignment6assignment6 href=/report/fa20-523-313/assignment6/assignment6/></a><a class="td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-313projectproject href=/report/fa20-523-313/project/project/></a></li></ul></ul></nav></div></div><div class="d-none d-xl-block col-xl-2 td-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"><a href=https://github.com/cybertraining-dsc/cybertraining-dsc.github.io/edit/main/content/en/report/fa20-523-339/project/project.md target=_blank><i class="fa fa-edit fa-fw"></i>Edit this page</a>
<a href="https://github.com/cybertraining-dsc/cybertraining-dsc.github.io/issues/new?title=" target=_blank><i class="fab fa-github fa-fw"></i>Create documentation issue</a>
<a href=https://github.com/cybertraining-dsc/cybertraining-dsc.github.io/issues/new target=_blank><i class="fas fa-tasks fa-fw"></i>Create project issue</a></div><nav id=TableOfContents><ul><li><a href=#1-introduction>1. Introduction</a></li><li><a href=#2-background>2. Background</a></li><li><a href=#3-choice-of-data-sets>3. Choice of Data-sets</a></li><li><a href=#4-data-preprocessing-and-cleaning>4. Data Preprocessing and cleaning</a></li><li><a href=#5-recommendation-rate-and-similarity-calculation>5. Recommendation Rate and Similarity Calculation</a></li><li><a href=#6-accuracy>6. Accuracy</a></li><li><a href=#7-benchmark>7. Benchmark</a></li><li><a href=#8-conclusion>8. Conclusion</a></li><li><a href=#9-acknowledgements>9. Acknowledgements</a></li><li><a href=#10-references>10. References</a></li></ul></nav></div><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><nav aria-label=breadcrumb class="d-none d-md-block d-print-none"><ol class="breadcrumb spb-1"><li class=breadcrumb-item><a href=/report/>Reports</a></li><li class="breadcrumb-item active" aria-current=page><a href=/report/fa20-523-339/project/project/></a></li></ol></nav><div class=td-content><h1></h1><h1 id=big-data-application-in-e-commerce>Big Data Application in E-commerce</h1><p><a href=https://github.com/cybertraining-dsc/fa20-523-339/actions><img src=https://github.com/cybertraining-dsc/fa20-523-339/workflows/Check%20Report/badge.svg alt="Check Report"></a>
<a href=https://github.com/cybertraining-dsc/fa20-523-339/actions><img src=https://github.com/cybertraining-dsc/fa20-523-339/workflows/Status/badge.svg alt=Status></a>
Status: final, Type: Project</p><p>Tao Liu, <a href=https://github.com/cybertraining-dsc/fa20-523-339/>fa20-523-339</a>, <a href=https://github.com/cybertraining-dsc/fa20-523-339/blob/main/project/project.md>Edit</a></p><div class="pageinfo pageinfo-primary"><h2 id=abstract>Abstract</h2><p>As a result of the last twenty year&rsquo;s Internet development globally, the E-commerce industry is getting stronger and stronger. While customers enjoyed their convenient online purchase environment, E-commerce sees the potential for the data and information customers left during their online shopping process. One fundamental usage for this information is to perform a Recommendation Strategy to give customers potential products they would also like to purchase. This report will build a User-Based Collaborative Filtering strategy to provide customer recommendation products based on the database of previous customer purchase records. This report will start with an overview of the background and explain the dataset it chose <em>Amazon Review Data</em>. After that, each step for the code and step made in a corresponding file <em>Big_tata_Application_in_E_commense.ipynb</em> [^6] will be illustrated, and the User-Based Collaborative Filtering strategy will be presented step by step.</p><p>Contents</p><div class=toc><nav id=TableOfContents><ul><li><a href=#1-introduction>1. Introduction</a></li><li><a href=#2-background>2. Background</a></li><li><a href=#3-choice-of-data-sets>3. Choice of Data-sets</a></li><li><a href=#4-data-preprocessing-and-cleaning>4. Data Preprocessing and cleaning</a></li><li><a href=#5-recommendation-rate-and-similarity-calculation>5. Recommendation Rate and Similarity Calculation</a></li><li><a href=#6-accuracy>6. Accuracy</a></li><li><a href=#7-benchmark>7. Benchmark</a></li><li><a href=#8-conclusion>8. Conclusion</a></li><li><a href=#9-acknowledgements>9. Acknowledgements</a></li><li><a href=#10-references>10. References</a></li></ul></nav></div></div><p><strong>Keywords:</strong> recommendation strategy,user-based, collaborative filtering, business, big data, E-commerce, customer behavior</p><h2 id=1-introduction>1. Introduction</h2><p>Big data have many applications in scientific research and business, from those in the hardware perspective like Higgs Discovery to the software perspective like E-commence. However, with the passage of time, online shopping and E-commerce have become one of the most popular events for citizens' lives and society. Millions of goods are now sold online the customers all over the world. With the 5G technology&rsquo;s implementation, this trend is now inevitable. These activities will create millions of data about customer&rsquo;s behaviors like how they value products, how they purchase or sell the products, and how they review the goods purchased would have a tremendous contribution for corporations to analyze. These data can not only help convince the current strategies of E-commerce on the right track, but a potential way to see which step E-commerce can make up for attracting more customers to buy the goods. At the same time, these data can also be implemented as a way for recommendation strategies for E-commerce. It will help customers find the next products they like in a short period by implementing machine learning technology on Big Data. The corporations also can enjoy the increase of sales and attractions by recommendation strategies. A better recommendation strategy on E-commerce is now the new trend for massive data scientists and researchers’ target. Therefore, this field is now one of the most popular research areas in the data science fields.</p><p>In this final project, An User-Based Collaborative Filtering Strategy will be implemented to get a taste of the recommendation strategy based on Customer&rsquo;s Gift card purchase records and the item they also viewed and bought. The algorithm&rsquo;s logic is the following: A used record indicates that customer who bought product A and also view/buy products B&C. When a new customer comes and shows his interest in B&C, product A would be recommended. This logic is addressed based on the daily-experience of customer behaviors on their E-commerce experience.</p><h2 id=2-background>2. Background</h2><p>Recommendation Strategy is a quite popular research area in recent years with a strong real-world influence. It is largely used in E-commerce platforms like Taobao, Amazon, etc. Therefore, It is obvious that there are plenty of recommendation strategies have been done. Though every E-commerce recommendation algorithm may be different from each other, the most popular technique for recommendation systems is called Collaborative Filtering. It is a technique that can filter out items that a user might like based on reactions by similar users. During this technique, the memory-based method is considered in this report since it uses a dataset to calculate the prediction using statistical techniques. This strategy will be able to fulfill in the local environment with a proper dataset. There are two kinds of memory-based methods available in the market: <em>User-Based Collaborative Filtering</em>, <em>Item-Based Collaborative Filtering</em> <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. This project will only focus on the User-Based Collaborative Filtering Strategy since Item-Based Collaborative Filtering requires a customer review rate for evaluation. The customer review rate for evaluation is not in the dataset available in the market. Therefore, Item-Based Collaborative Filtering unlikely to be implemented, and the User-Based Collaborative Filtering Strategy is considered.</p><h2 id=3-choice-of-data-sets>3. Choice of Data-sets</h2><p>The dataset for this study is called <em>Amazon Review Data</em> <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. Particularly, since the dataset is now reached billions of amount, the subcategory gift card will be used as an example since the overall customer record is 1547 and the amount of data retrieved is currently in the right amount of training. This fact can help to perform User-Based Collaborative Filtering in a controlled timeline.</p><h2 id=4-data-preprocessing-and-cleaning>4. Data Preprocessing and cleaning</h2><p>The first step will be data collection and data cleaning. The raw data-set is imported directly from data-set contributors' online storage <em>meta_Gift_Cards.json.gz</em> <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> to Google Colab notebook. The raw database retrieved directly from the website will be shown in <strong>Table 1</strong>.</p><table><thead><tr><th style=text-align:center>Attribute</th><th style=text-align:center>Description</th><th style=text-align:center>Example</th></tr></thead><tbody><tr><td style=text-align:center>category</td><td style=text-align:center>The category of the record</td><td style=text-align:center>["Gift Cards", &ldquo;Gift Cards&rdquo;]\</td></tr><tr><td style=text-align:center>tech1</td><td style=text-align:center>tech relate to it</td><td style=text-align:center>""</td></tr><tr><td style=text-align:center>description</td><td style=text-align:center>The description of the product</td><td style=text-align:center>&ldquo;Gift card for the purchase of goods&mldr;&rdquo;</td></tr><tr><td style=text-align:center>fit</td><td style=text-align:center>fit for its record</td><td style=text-align:center>""</td></tr><tr><td style=text-align:center>title</td><td style=text-align:center>title for the product</td><td style=text-align:center>&ldquo;Serendipity 3 $100.00 Gift Card&rdquo;</td></tr><tr><td style=text-align:center><strong>also_buy</strong></td><td style=text-align:center>the product also bought</td><td style=text-align:center>["B005ESMEBQ"]\</td></tr><tr><td style=text-align:center>image</td><td style=text-align:center>image of the gift card</td><td style=text-align:center>""</td></tr><tr><td style=text-align:center>tech2</td><td style=text-align:center>tech relate to it</td><td style=text-align:center>""</td></tr><tr><td style=text-align:center>brand</td><td style=text-align:center>brand of the product</td><td style=text-align:center>&ldquo;Amazon&rdquo;</td></tr><tr><td style=text-align:center>feature</td><td style=text-align:center>feature of the product</td><td style=text-align:center>&ldquo;Amazon.com Gift cards never expire&rdquo;</td></tr><tr><td style=text-align:center>rank</td><td style=text-align:center>rank of the product</td><td style=text-align:center>""</td></tr><tr><td style=text-align:center><strong>also_view</strong></td><td style=text-align:center>the product also view</td><td style=text-align:center>["BT00DC6QU4"]\</td></tr><tr><td style=text-align:center>details</td><td style=text-align:center>detail for the product</td><td style=text-align:center>&ldquo;3.4 x 2.1 inches ; 1.44 ounces&rdquo;</td></tr><tr><td style=text-align:center>main_cat</td><td style=text-align:center>main category of the product</td><td style=text-align:center>&ldquo;Grocery&rdquo;</td></tr><tr><td style=text-align:center>similar_item</td><td style=text-align:center>similar_item of the product</td><td style=text-align:center>""</td></tr><tr><td style=text-align:center>date</td><td style=text-align:center>date of the product assigned</td><td style=text-align:center>""</td></tr><tr><td style=text-align:center>price</td><td style=text-align:center>price of the product</td><td style=text-align:center>""</td></tr><tr><td style=text-align:center><strong>asin</strong></td><td style=text-align:center>product asin code</td><td style=text-align:center>&ldquo;B001BKEWF2&rdquo;</td></tr></tbody></table><p><strong>Table 1:</strong> The description for the dataset</p><p>Since the attributes <em>category</em>, <em>main_cat</em> are the same for the whole dataset, they will not be valid training labels. The attributes <em>tech1</em>, <em>fit</em>, <em>tech2</em>, <em>rank</em>, <em>similar_item</em>, <em>date</em>, <em>price</em> have no/ extremely less filled in. That made them also invalid for being training labels. The attributes <em>image</em>, <em>description</em> and <em>feature</em> is unique per item and hard to find the similarity in numeric purpose and then hard to be used as labels. Therefore, only attributes <strong>also_buy</strong>, <strong>also_view</strong>, <strong>asin</strong> are trained as attributes and labels in this algorithm. <strong>Figure 1</strong> is a shortcut for the raw database.</p><pre><code>THE RAW DATABASE 
The size of DATABASE : 1547
                                                      0
0     {&quot;category&quot;: [&quot;Gift Cards&quot;, &quot;Gift Cards&quot;], &quot;te...
1     {&quot;category&quot;: [&quot;Gift Cards&quot;, &quot;Gift Cards&quot;], &quot;te...
2     {&quot;category&quot;: [&quot;Gift Cards&quot;, &quot;Gift Cards&quot;], &quot;te...
3     {&quot;category&quot;: [&quot;Gift Cards&quot;, &quot;Gift Cards&quot;], &quot;te...
4     {&quot;category&quot;: [&quot;Gift Cards&quot;, &quot;Gift Cards&quot;], &quot;te...
...                                                 ...
1542  {&quot;category&quot;: [&quot;Gift Cards&quot;, &quot;Gift Cards&quot;], &quot;te...
1543  {&quot;category&quot;: [&quot;Gift Cards&quot;, &quot;Gift Cards&quot;], &quot;te...
1544  {&quot;category&quot;: [&quot;Gift Cards&quot;, &quot;Gift Cards&quot;], &quot;te...
1545  {&quot;category&quot;: [&quot;Gift Cards&quot;, &quot;Gift Cards&quot;], &quot;te...
1546  {&quot;category&quot;: [&quot;Gift Cards&quot;, &quot;Gift Cards&quot;], &quot;te...

[1547 rows x 1 columns]
</code></pre><p><strong>Figure 1:</strong> The raw database</p><p>For the training purpose, all asins that appeared in the dataset, either from <em>also_buy & also_view</em> list or * asin*, have to be reformatted from alphabet character to numeric character. For example, the original label for a particular item may be called **B001BKEWF2**. It will now be reformatted to a numeric number as 0. In that case, it can be a better fit-in the next step training method and easy to track. This step will be essential since it will help the also_view and also_buy dataset to be reformatted and make sure they are reformed in the track without overlapping each other. Therefore, a reformat_asin function is called for reformatting all the asins in the dataset and is performed as a dictionary. A shortcut for the *Asin Dictionary* is shown in **Figure 2**.</p><pre><code>The 4561  Lines of Reformatted ASIN reference dictionary as following.
{'B001BKEWF2': 0, 'B001GXRQW0': 1, 'B001H53QE4': 2, 'B001H53QEO': 3, 'B001KMWN2K': 4, 'B001M1UVQO': 5, 
 'B001M1UVZA': 6, 'B001M5GKHE': 7, 'B002BSHDJK': 8, 'B002DN7XS4': 9, 'B002H9RN0C': 10, 'B002MS7BPA': 11, 
 'B002NZXF9S': 12, 'B002O018DM': 13, 'B002O0536U': 14, 'B002OOBESC': 15, 'B002PY04EG': 16, 'B002QFXC7U': 17, 
 'B002QTM0Y2': 18, 'B002QTPZUI': 19, 'B002SC9DRO': 20, 'B002UKLD7M': 21, 'B002VFYGC0': 22, 'B002VG4AR0': 23, 
 'B002VG4BRO': 24, 'B002W8YL6W': 25, 'B002XNLC04': 26, 'B002XNOVDE': 27, 'B002YEWXZ0': 28, 'B002YEWXMI': 29, 
 'B003755QI6': 30, 'B003CMYYGY': 31, 'B003NALDC8': 32, 'B003XNIBTS': 33, 'B003ZYIKDM': 34, 'B00414Y7Y6': 35, 
 'B0046IIHMK': 36, 'B004BVCHDC': 37, 'B004CG61UQ': 38, 'B004CZRZKW': 39, 'B004D01QJ2': 40, 'B004KNWWPE': 41, 
 'B004KNWWP4': 42, 'B004KNWWR2': 43, 'B004KNWWRC': 44, 'B004KNWWT0': 45, 'B004KNWWRW': 46, 'B004KNWWQ8': 47, 
 'B004KNWWNG': 48, 'B004KNWWPO': 49, 'B004KNWWXQ': 50, 'B004KNWWUE': 51, 'B004KNWWYU': 52, 'B004KNWWWC': 53, 
 'B004KNWX3A': 54, 'B004KNWX1W': 55, 'B004KNWWZE': 56, 'B004KNWWSQ': 57, 'B004KNWX4Y': 58, 'B004KNWX12': 59, 
 'B004KNWX3U': 60, 'B004KNWX62': 61, 'B004KNWX2Q': 62, 'B004KNWX6C': 63...}
</code></pre><p><strong>Figure 2:</strong> The ASIN dictionary</p><p>Then the data contained in the each record&rsquo;s attributes: <strong>also_view</strong> & <strong>also_buy</strong> will be reformated as <strong>Figure 3</strong> and <strong>Figure 4</strong>. <strong>Figure 3</strong> is about the also_view item in reformatted numeric numbers based on each item customer purchased. <strong>Figure 4</strong> is about the also_buy item in reformatted numeric numbers based on each item customer purchased.</p><pre><code>also_view List: The first 10 lines
Item  0 :  []
Item  1 :  [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 
            2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]
Item  2 :  [2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 922, 2036, 283, 
            2037, 2038, 2001, 2000, 2013, 2039, 2040, 2007, 2041, 2042, 2009, 1233, 2043, 
            2014, 234, 2044, 2012, 2005, 2045, 2046, 2002, 2047, 378, 2048, 1382, 2008, 
            2004, 2011, 2049, 2050, 2051, 2052, 2003, 2053, 2054, 2018, 2055, 2056]
Item  3 :  []
Item  4 :  []
Item  5 :  []
Item  6 :  []
Item  7 :  []
Item  8 :  []
Item  9 :  []
Item  10 :  [2057, 2058, 2059]
</code></pre><p><strong>Figure 3:</strong> The also_view list</p><pre><code>also_buy List: The first 20 lines
Item  0 :  []
Item  1 :  []
Item  2 :  [2026, 2028, 2027, 2049, 1382, 2037, 2012, 2023]
Item  3 :  []
Item  4 :  []
Item  5 :  []
Item  6 :  []
Item  7 :  []
Item  8 :  [4224, 4225, 4226, 4227, 4228, 4229, 4230, 4231, 4232, 4233, 
            4234, 4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4243, 
            4244, 4245, 4246, 4247, 4248, 4249, 4250, 4251, 4252]
Item  9 :  []
Item  10 :  []
</code></pre><p><strong>Figure 4:</strong> The also_buy list</p><p>While the also_buy list and also_view list is addressed. It is also important to know how many times a particular item appeared in other items' also view list and also buy list. These dictionaries will help to calculate the recommendation rate later. <strong>Figure 5</strong> and <strong>Figure 6</strong> is an example for how many times item 2000 appeared in other item&rsquo;s also_view and also_buy lists.</p><pre><code>also_view dictionary: use Item 2000 as an example
Item  2000 :  [1, 2, 11, 12, 51, 60, 63, 65, 66, 67, 85, 86, 90, 94, 99, 100, 101, 103, 107, 108, 113, 116, 123, 126, 127, 129, 130, 141, 142, 143, 145, 146, 147, 148, 194, 199, 200, 204, 217, 221, 225, 229, 230, 231, 232, 233, 234, 235, 251, 253, 254, 260, 264, 268, 269, 270, 271, 280, 284, 285, 286, 287, 288, 294, 295, 296, 298, 299, 305, 306, 307, 308, 309, 313, 319, 327, 328, 338, 339, 344, 346, 348, 355, 356, 360, 371, 372, 377, 380, 389, 394, 406, 407, 410, 415, 440, 456, 469, 480, 490, 494, 495, 496, 502, 505, 509, 511, 512, 514, 517, 519, 520, 527, 530, 548, 591, 595, 600, 608, 609, 621, 631, 633, 670, 671, 672, 673, 675, 681, 689, 691, 695, 697, 707, 708, 709, 719, 783, 792, 793, 796, 797, 801, 803, 804, 807, 810, 816, 817, 818, 819, 836, 840, 842, 856, 892, 902, 913, 914, 917, 921, 955, 968, 972, 974, 975, 979, 981, 990, 991, 997, 998, 999, 1000, 1001, 1003, 1005, 1006, 1007, 1010, 1011, 1014, 1015, 1017, 1018, 1023, 1024, 1026, 1027, 1028, 1031, 1032, 1035, 1037, 1038, 1039, 1040, 1042, 1043, 1050, 1069, 1070, 1084, 1114, 1115, 1116, 1117, 1119, 1143, 1153, 1171, 1175, 1192, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1207, 1208, 1213, 1217, 1218, 1220, 1222, 1233, 1236, 1238, 1242, 1244, 1245, 1246, 1249, 1251, 1258, 1268, 1270, 1280, 1285, 1289, 1290, 1292, 1295, 1315, 1318, 1319, 1324, 1328, 1330, 1333, 1336, 1341, 1345, 1346, 1347, 1348, 1352, 1359, 1361, 1365, 1366, 1373, 1378, 1384, 1389, 1394, 1395, 1396, 1403, 1405, 1406, 1407, 1414, 1415, 1417, 1418, 1419, 1420, 1423, 1424, 1426, 1427, 1430, 1431, 1432, 1433, 1434, 1437, 1443, 1453, 1454, 1455, 1457, 1458, 1462, 1463, 1464, 1467, 1468, 1469, 1470, 1472, 1474, 1475, 1477, 1478, 1480, 1481, 1482, 1486, 1488, 1492, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1505, 1506, 1508, 1509, 1512, 1513, 1514, 1515, 1523, 1530, 1533, 1537, 1539, 1546]
</code></pre><p><strong>Figure 5:</strong> The also_view dictionary</p><pre><code>also_buy dictionary: use Item 2000 as an example
Item  2000 :  [217, 231, 235, 236, 277, 284, 285, 286, 287, 306, 307, 308, 327, 
               359, 476, 482, 505, 583, 609, 719, 891, 922, 963, 1065, 1328, 1359, 
               1384, 1399, 1482, 1483, 1490, 1496, 1497, 1499, 1509, 1512, 1540]
</code></pre><p><strong>Figure 6:</strong> The also_buy dictionary</p><h2 id=5-recommendation-rate-and-similarity-calculation>5. Recommendation Rate and Similarity Calculation</h2><p>While all the dictionaries and attributes-label relationship are prepared in Part4, the recommendation rate calculation is addressed in this part. There are two types of similarity methods in this algorithm: <strong>Cosine Similarity</strong> and <strong>Euclidean Distance Similarity</strong> that perform the similarity calculation. Before calculating the similarity, the first step would be phrasing the recommendation rate for each item to another item. The <strong>Figure 8</strong> is a shortcut for the recommendation rate matrix. It will use the logic in <strong>Figure 7</strong>.</p><pre><code>for item in the asin list:
  for asin in the also_view dictionary:
    if asin is founded in also_view dictionary[item] list:
        score for this item increase 2
    each item in the also_view_dict[asin]'s score will be also increase 2
  for asin in the also_view dictionary:
    if asin is founded in also_view dictionary[item] list:
        score for this item increase 10
    each item in the also_view_dict[asin]'s score will be also increase 10
for other scores which is currently 0, assigned the average value for it
return the overall matrix for the further step
</code></pre><p><strong>Figure 7:</strong> The sudocode for giving the recommendation rate for the likelyhood of the next purchase item based the current purchase</p><pre><code>Item  0 :  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ...]
Item  1 :  [13.0, 52, 28, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 2, 2, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0 ...]
Item  2 :  [29.5, 28, 182, 29.5, 29.5, 29.5, 29.5, 29.5, 29.5, 29.5, 29.5, 4, 2, 29.5, 29.5, 29.5, 29.5, 29.5, 29.5, 29.5 ...]
Item  3 :  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ...]
Item  4 :  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ...]
Item  5 :  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ...]
Item  6 :  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ...]
Item  7 :  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ...]
Item  8 :  [14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 290, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5, 14.5 ...]
Item  9 :  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 ...]
Item  10 :  [1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 6, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5 ...]
</code></pre><p><strong>Figure 8:</strong> The shortcut for recommenation rate matrix</p><p>The first similarity method implemented is <em>Cosine Similarity</em> <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>. It will use the cosine of the angle between vectors(see <strong>Figure 9</strong>) to address the similarity between different items. By implementing this method with <em>sklearn.metrics.pairwise</em> package, it will rephrase the whole recommendation similarity as <strong>table 2</strong>.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-339/raw/main/project/images/cosine-similarity.png alt="image info"></p><p><strong>Figure 9:</strong> The cosine similarity</p><table><thead><tr><th style=text-align:center>item</th><th style=text-align:center>0</th><th style=text-align:center>1.</th><th style=text-align:center>2</th><th style=text-align:center>3</th><th style=text-align:center>4</th><th style=text-align:center>5</th><th style=text-align:center>6</th><th style=text-align:center>7.</th><th style=text-align:center>8.</th><th style=text-align:center>&mldr;1547</th></tr></thead><tbody><tr><td style=text-align:center>0</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>&mldr;</td></tr><tr><td style=text-align:center>1</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.928569</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.873242</td><td style=text-align:center>&mldr;</td></tr><tr><td style=text-align:center>2</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.928569</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>0.</td><td style=text-align:center>&mldr;</td></tr></tbody></table><p><strong>table 2:</strong> The shortcut for using consine similarity to address the recommendation result</p><p>The second similarity method implemented is <em>Euclidean Distance Similarity</em><sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>. It will use Euclidean Distance to calculate the distance between each items as a way to calculate similarity (see <strong>Figure 10</strong>). By implementing this method with <em>scipy.spatial.distance_matrix</em> package, it will rephrase the whole recommendation similarity. <strong>Figure 11</strong> is an example with the item 1.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-339/raw/main/project/images/euclidean.png alt="image info"></p><p><strong>Figure 10</strong> The Euclidean Distance calculation</p><pre><code>Item  1 :  [1005.70671669    0.         1370.09142031 1005.70671669 1005.70671669
 1005.70671669 1005.70671669 1005.70671669  710.89169358 1005.70671669
  905.23339532  862.88933242  971.0745337  1005.70671669 1005.70671669
 1005.70671669 1005.70671669 1005.70671669 1005.70671669 1005.70671669...]
</code></pre><p><strong>Figure 11:</strong> The Euclidean Distance similarity example of item 1</p><h2 id=6-accuracy>6. Accuracy</h2><p>The accuracy for the consine_similarity and euclidean distance similarity with the number of items already purchased is shown as <strong>Figure 12</strong>. Here the blue line represented the cosine similarity, and the red line represented the euclidean distance similarity. As presented, the more item joined as purchased, the less likely both similarity algorithms accurately locate the next item the customer may want to purchase next. However, overall the consine_similarity performed better accuracy compared to Euclidean Distance similarity. In <strong>Figure 13</strong>, both accurate number and both wrong number is addressed. Both wrong numbers changed dramatically after more already-purchased items joined. This fact convinces the prior statement: this algorithm works better when the given object is <em>1</em> but can&rsquo;t handle many purchased item.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-339/raw/main/project/images/CosVSEuc.png alt="image info"></p><p><strong>Figure 12:</strong> The Cosine similarity and Euclidean Distance Accuracy Comparison</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-339/raw/main/project/images/bothrightandwrong.png alt="image info"></p><p><strong>Figure 13:</strong> The bothright and bothwrong accuracy comparison</p><h2 id=7-benchmark>7. Benchmark</h2><p>The Benchmark for each step for the project is stated in <strong>Figure 14</strong> The overall Time spent is affordable. The accuracy calculation part(57s) and the Euclidean Distance algorithm implementation(74s) have taken the majority of time for the running. The Accuracy time consumed would be considered proper since it will randomly assign one to ten items and perform recommendation items based on it. The time spent is necessary and should be considered normal. The Euclidean Distance algorithm would be considered making sense since it is trying to perform the difference in two 1547X1547 matrixs.</p><table><thead><tr><th style=text-align:center>Name</th><th style=text-align:center>Status</th><th style=text-align:center>Time</th></tr></thead><tbody><tr><td style=text-align:center>Data Online Downloading Process</td><td style=text-align:center>ok</td><td style=text-align:center>1.028</td></tr><tr><td style=text-align:center>Raw Database</td><td style=text-align:center>ok</td><td style=text-align:center>0.529</td></tr><tr><td style=text-align:center>Database Reformatting process</td><td style=text-align:center>ok</td><td style=text-align:center>0.587</td></tr><tr><td style=text-align:center>Recommendation Rate Calculation</td><td style=text-align:center>ok</td><td style=text-align:center>1.197</td></tr><tr><td style=text-align:center>Consine_Similarity</td><td style=text-align:center>ok</td><td style=text-align:center>0.835</td></tr><tr><td style=text-align:center>Euclidean distance</td><td style=text-align:center>ok</td><td style=text-align:center>73.895</td></tr><tr><td style=text-align:center>Recommendation strategy showcase-Cosine_Similarity</td><td style=text-align:center>ok</td><td style=text-align:center>0.003</td></tr><tr><td style=text-align:center>Recommendation strategy showcase-Euclidean distance</td><td style=text-align:center>ok</td><td style=text-align:center>0.004</td></tr><tr><td style=text-align:center>Accuracy</td><td style=text-align:center>ok</td><td style=text-align:center>57.119</td></tr><tr><td style=text-align:center>Showcase-Cosine_Similarity</td><td style=text-align:center>ok</td><td style=text-align:center>0.003</td></tr><tr><td style=text-align:center>Showcase-Euclidean distance</td><td style=text-align:center>ok</td><td style=text-align:center>0.003</td></tr></tbody></table><p><strong>Figure 14:</strong> Benchmark</p><p>The time comparison for Cosine Similarity and Euclidean Distance Time Comparison is addressed in <strong>Figure 15</strong> As stated, the euclidean distance algorithm has taken much more time than cosine similarity. Therefore, the cosine similarity should be considered as efficient in these two similarities.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-339/raw/main/project/images/timecompare.png alt="image info"></p><p><strong>Figure 15:</strong> The Cosine Similarity and Euclidean Distance Time Comparison</p><h2 id=8-conclusion>8. Conclusion</h2><p>This project <em>Big_tata_Application_in_E_commense.ipynb</em> <sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup> is attempted to get a taste of the recommendation strategy based on <em>User-Based Collaborative Filtering</em>. Based on this attemption, the two similarity methods: <strong>Cosine Similarity</strong> and <strong>Euclidean Distance</strong> are addressed. After analyzing accuracy and time consumption for each method, Cosine Similarity performed better in both the accuracy and implementation time. Therefore the cosine similarity method is recommended to use in the recommendation algorithm strategies.
This project should be aware of Limitations. Since the rating attribute is missing in the dataset, the recommendation rate was assigned by the author. Therefore, in real-world implementation, both methods' accuracy can be expected to be higher than in this project. Besides, the cross-section recommendation strategies are not implemented. This project is only focused on the gift card section recommendations. With the multiple aspects of goods customer purchases addressed, both methods' accuracy can also be expected to be higher.</p><h2 id=9-acknowledgements>9. Acknowledgements</h2><p>The author would like to thank Dr. Gregor Von Laszewski, Dr. Geoffrey Fox, and the associate instructors in the <em>FA20-BL-ENGR-E534-11530: Big Data Applications</em> course (offered in the Fall 2020 semester at Indiana University, Bloomington) for their continued assistance and suggestions with regard to exploring this idea and also for their aid with preparing the various drafts of this article.</p><h2 id=10-references>10. References</h2><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>Build a Recommendation Engine With Collaborative Filtering. Ajitsaria, A. 2020
<a href=https://realpython.com/build-recommendation-engine-collaborative-filtering/>https://realpython.com/build-recommendation-engine-collaborative-filtering/</a> <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>Justifying recommendations using distantly-labeled reviews and fined-grained aspects. Jianmo Ni, Jiacheng Li, Julian McAuley. Empirical Methods in Natural Language Processing (EMNLP), 2019 <a href=http://jmcauley.ucsd.edu/data/amazon/>http://jmcauley.ucsd.edu/data/amazon/</a> <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>meta_Gift_Cards.json.gz <a href=http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles/meta_Gift_Cards.json.gz>http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles/meta_Gift_Cards.json.gz</a> <a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p>Recommendation Systems : User-based Collaborative Filtering using N Nearest Neighbors. Ashay Pathak. 2019
<a href=https://medium.com/sfu-cspmp/recommendation-systems-user-based-collaborative-filtering-using-n-nearest-neighbors-bf7361dc24e0>https://medium.com/sfu-cspmp/recommendation-systems-user-based-collaborative-filtering-using-n-nearest-neighbors-bf7361dc24e0</a> <a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5 role=doc-endnote><p>Similarity and Distance Metrics for Data Science and Machine Learning. Gonzalo Ferreiro Volpi. 2019
<a href=https://medium.com/dataseries/similarity-and-distance-metrics-for-data-science-and-machine-learning-e5121b3956f8>https://medium.com/dataseries/similarity-and-distance-metrics-for-data-science-and-machine-learning-e5121b3956f8</a> <a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6 role=doc-endnote><p>Big_tata_Application_in_E_commense.ipynb <a href=https://github.com/cybertraining-dsc/fa20-523-339/raw/main/project/Big_tata_Application_in_E_commense.ipynb>https://github.com/cybertraining-dsc/fa20-523-339/raw/main/project/Big_tata_Application_in_E_commense.ipynb</a> <a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section><div class="text-muted mt-5 pt-3 border-top">Last modified January 1, 0001</div></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Gregor von Laszewski" aria-label="Gregor von Laszewski"><a class=text-white target=_blank href=https://laszewski.github.io><i class="fa fa-envelope"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank href=https://github.com/cybertraining-dsc/cybertraining-dsc.github.io/><i class="fab fa-github"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2021 Indiana University, 2020 All Rights Reserved</small><p class=mt-2><a href=/about/>About Cybertraining</a></p></div></div></div></footer></div><script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script><script src=https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js integrity=sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy crossorigin=anonymous></script><script src=/js/main.min.29b0315468c00226fa6f4556a9cebc0ac4fe1ce1457a01b22c0a06b329877383.js integrity="sha256-KbAxVGjAAib6b0VWqc68CsT+HOFFegGyLAoGsymHc4M=" crossorigin=anonymous></script></body></html>