<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cybertraining â€“ Report</title>
    <link>/report/</link>
    <description>Recent content in Report on Cybertraining</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/report/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/cloudmesh/openapi/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/cloudmesh/openapi/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;openapi-function-generator&#34;&gt;Openapi Function generator&lt;/h1&gt;
&lt;h2 id=&#34;activity-log&#34;&gt;Activity Log&lt;/h2&gt;
&lt;h2 id=&#34;week-of-mar-9---mar-16&#34;&gt;Week of Mar 9 - Mar 16&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Andrew Goldfarb&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Worked with Ishan and Jonathan to finalize the start stop
functionality.&lt;/li&gt;
&lt;li&gt;Added functionality to delete the process entry from the
registry upon stop command.&lt;/li&gt;
&lt;li&gt;Debugged weird start error for my personal machine where the
start functionality was running two bash terminals causing the
start function to fail.&lt;/li&gt;
&lt;li&gt;Met with Professor to discuss proper implementation of the
start/stop and how to tie into registry functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;week-prior-to-mar-9th&#34;&gt;Week prior to Mar 9th&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;bkgerreis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Jonathan Beckford&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prateek&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Andrew Goldfarb&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Edited the stop function to take process PID and use os.kill to
stop the process based on the name of the python file. However,
according to Ishan this is still not working.&lt;/li&gt;
&lt;li&gt;Resolved conflicts between main and our working branch&lt;/li&gt;
&lt;li&gt;Began work on assigning a default name if the user does not provide
one for server start. Potetially, a function to assign an alias
name to the whole process to amke it easier to reference.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;install-for-development&#34;&gt;Install for development&lt;/h2&gt;
&lt;p&gt;cloudmesh-installer git pull analytics&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd cloudmesh-openapi
pip install -e .
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;keep-up-to-date&#34;&gt;Keep up to date&lt;/h2&gt;
&lt;p&gt;explain how to set up and use upstream sync&lt;/p&gt;
&lt;h3 id=&#34;project-meeting&#34;&gt;Project Meeting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://iu.zoom.us/rec/share/4dIpJZ-p8ztIHpH_q1HAZ6wzL6iiaaa8h3QX8_YMzRkn8tBfY_mRIe8z3j-3cZ_9?startTime=1581987567000&#34;&gt;Mon 17 Feb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://iu.zoom.us/rec/share/_8ZLKK7Z6zpLb53f73_UW4EFBY_iX6a8gydM_vVbzRu2MhrC_sUCKhChUkLzgEK8?startTime=1582591839000&#34;&gt;Mon 24 Feb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;basic-function-generator&#34;&gt;Basic Function Generator&lt;/h3&gt;
&lt;h4 id=&#34;prateek-shaw----code-link&#34;&gt;Prateek Shaw -  code link.&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-229/tree/main/cloudmesh-openapi&#34;&gt;https://github.com/cloudmesh-community/sp20-516-229/tree/main/cloudmesh-openapi&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;created a basic function that will return the OpenAPI YAML file
of given python function including parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sp20-516-237----jonathan-beckford&#34;&gt;SP20-516-237 &amp;ndash; Jonathan Beckford&lt;/h4&gt;
&lt;p&gt;I created a class that generates the OpenAPI yaml file. I also created
a sample program that defines an example function, instantiates my
OpenAPI generator class and passes in the sample function as input. I
figured this would make things really easy to just paste any new
sample function for testing purposes. I also included the parameters
as was requested. I also ran my output yaml through the swagger
validator (&lt;a href=&#34;https://editor.swagger.io/&#34;&gt;https://editor.swagger.io/&lt;/a&gt;) to make sure it was compliant
and it was.&lt;br&gt;
&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-237/tree/main/projectAI/generateOpenAPI&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;sp20-516-231---brian-kegerreis&#34;&gt;sp20-516-231 - Brian Kegerreis&lt;/h4&gt;
&lt;p&gt;I created a function to generate an OpenAPI spec including a rough
attempt at response types (only supports text/plain media types at
this point)
&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-231/blob/main/openapi-exercises/example_echo.py&#34;&gt;https://github.com/cloudmesh-community/sp20-516-231/blob/main/openapi-exercises/example_echo.py&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;server-start&#34;&gt;Server Start&lt;/h3&gt;
&lt;h4 id=&#34;andrew-goldfarb---sp20-516-234&#34;&gt;Andrew Goldfarb - SP20-516-234&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-234/tree/open-api-exercise/openAPI&#34;&gt;https://github.com/cloudmesh-community/sp20-516-234/tree/open-api-exercise/openAPI&lt;/a&gt;
I have created a basic function that returns the IP address of the
server running the function to tell if it is running on the device
itself or connected to the internet running while running the
function.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/cloudmesh/openapi/scikitlearn/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/cloudmesh/openapi/scikitlearn/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;sklearngeneratorfile-high-level-overview&#34;&gt;SKlearnGeneratorFile High level Overview&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The SklearnGeneratorFile.py is the generator function which outputs the python file for given
Sckit-learn Library.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The function takes two inputs&lt;/p&gt;
&lt;p&gt;1.input_sklibrary&lt;/p&gt;
&lt;p&gt;2.model_tag&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Examples of the inputs are&lt;/p&gt;
&lt;p&gt;input_sklibrary = sklearn.linear_model.LinearRegression(Full model specification)
model_tag = any name which you want the tag the model instance like LinReg1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This Version of Scikit-learn service accepts csv files in UTF-8 format only.It is the user responsibility to make
sure the files are in UTF-8 format.It is the user responsibility to split the data in to train and test datasets.
Split data functionality is not currently supported.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;scikit-learn uses numpydoc format in the docstring so the scraping of the parameters and docstrings
are done using docscrape from numpydoc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;All the templates used in the code are based on X and y inputs scikit-learn takes and also based on the
return type&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pytests-for-scikit-learn-tests&#34;&gt;Pytests for Scikit learn tests.&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The below pytest generates the .py file used by generator to do a OPENAPI specification.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/tests/Scikitlearn-tests/test_06c_sklearngeneratortest.py&#34;&gt;Pytestcode&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt; pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/Scikitlearn_tests/test_06c_sklearngeneratortest.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The below pytest tests the methods generated .&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/tests/Scikitlearn-tests/test_06d_sklearngeneratortest.py&#34;&gt;Pytestcode&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/Scikitlearn_tests/test_06d_sklearngeneratortest.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/deprecated/openapi/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/deprecated/openapi/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;openapi-function-generator&#34;&gt;Openapi Function generator&lt;/h1&gt;
&lt;h2 id=&#34;activity-log&#34;&gt;Activity Log&lt;/h2&gt;
&lt;h2 id=&#34;week-of-mar-9---mar-16&#34;&gt;Week of Mar 9 - Mar 16&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Andrew Goldfarb&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Worked with Ishan and Jonathan to finalize the start stop
functionality.&lt;/li&gt;
&lt;li&gt;Added functionality to delete the process entry from the
registry upon stop command.&lt;/li&gt;
&lt;li&gt;Debugged weird start error for my personal machine where the
start functionality was running two bash terminals causing the
start function to fail.&lt;/li&gt;
&lt;li&gt;Met with Professor to discuss proper implementation of the
start/stop and how to tie into registry functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;week-prior-to-mar-9th&#34;&gt;Week prior to Mar 9th&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;bkgerreis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Jonathan Beckford&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prateek&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Andrew Goldfarb&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Edited the stop function to take process PID and use os.kill to
stop the process based on the name of the python file. However,
according to Ishan this is still not working.&lt;/li&gt;
&lt;li&gt;Resolved conflicts between main and our working branch&lt;/li&gt;
&lt;li&gt;Began work on assigning a default name if the user does not provide
one for server start. Potetially, a function to assign an alias
name to the whole process to amke it easier to reference.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;install-for-development&#34;&gt;Install for development&lt;/h2&gt;
&lt;p&gt;cloudmesh-installer git pull analytics&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd cloudmesh-openapi
pip install -e .
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;keep-up-to-date&#34;&gt;Keep up to date&lt;/h2&gt;
&lt;p&gt;explain how to set up and use upstream sync&lt;/p&gt;
&lt;h3 id=&#34;project-meeting&#34;&gt;Project Meeting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://iu.zoom.us/rec/share/4dIpJZ-p8ztIHpH_q1HAZ6wzL6iiaaa8h3QX8_YMzRkn8tBfY_mRIe8z3j-3cZ_9?startTime=1581987567000&#34;&gt;Mon 17 Feb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://iu.zoom.us/rec/share/_8ZLKK7Z6zpLb53f73_UW4EFBY_iX6a8gydM_vVbzRu2MhrC_sUCKhChUkLzgEK8?startTime=1582591839000&#34;&gt;Mon 24 Feb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;basic-function-generator&#34;&gt;Basic Function Generator&lt;/h3&gt;
&lt;h4 id=&#34;prateek-shaw----code-link&#34;&gt;Prateek Shaw -  code link.&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-229/tree/main/cloudmesh-openapi&#34;&gt;https://github.com/cloudmesh-community/sp20-516-229/tree/main/cloudmesh-openapi&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;created a basic function that will return the OpenAPI YAML file
of given python function including parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sp20-516-237----jonathan-beckford&#34;&gt;SP20-516-237 &amp;ndash; Jonathan Beckford&lt;/h4&gt;
&lt;p&gt;I created a class that generates the OpenAPI yaml file. I also created
a sample program that defines an example function, instantiates my
OpenAPI generator class and passes in the sample function as input. I
figured this would make things really easy to just paste any new
sample function for testing purposes. I also included the parameters
as was requested. I also ran my output yaml through the swagger
validator (&lt;a href=&#34;https://editor.swagger.io/&#34;&gt;https://editor.swagger.io/&lt;/a&gt;) to make sure it was compliant
and it was.
&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-237/tree/main/projectAI/generateOpenAPI&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;sp20-516-231---brian-kegerreis&#34;&gt;sp20-516-231 - Brian Kegerreis&lt;/h4&gt;
&lt;p&gt;I created a function to generate an OpenAPI spec including a rough
attempt at response types (only supports text/plain media types at
this point)
&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-231/blob/main/openapi-exercises/example_echo.py&#34;&gt;https://github.com/cloudmesh-community/sp20-516-231/blob/main/openapi-exercises/example_echo.py&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;server-start&#34;&gt;Server Start&lt;/h3&gt;
&lt;h4 id=&#34;andrew-goldfarb---sp20-516-234&#34;&gt;Andrew Goldfarb - SP20-516-234&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-234/tree/open-api-exercise/openAPI&#34;&gt;https://github.com/cloudmesh-community/sp20-516-234/tree/open-api-exercise/openAPI&lt;/a&gt;
I have created a basic function that returns the IP address of the
server running the function to tell if it is running on the device
itself or connected to the internet running while running the
function.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/docker/ubuntu19.10/todo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/docker/ubuntu19.10/todo/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;
&lt;p&gt;make clean: only delete the artifacts created here, the clean wipes
currently everything&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;when using this in consecutive order, would cms init not wipe out the data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;should we not mount the .cloudmesh and other data dire into the conatiner.
This way we can use the host system for developments. Maybe we need to&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;support both ways&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;leverage cmsd
we have told the class that we have cmsd taht starts up cloudmesh in
a container. Develop a new directory docker-cmsd and use that&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/docker/ubuntu20.04-sklearn/todo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/docker/ubuntu20.04-sklearn/todo/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;
&lt;p&gt;THIS IS JUST THE SKELETON AND HAS NOT BEEN RUN ONCE IT HAS BUGS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;THIS HAS NOT YET THE SKLERAN START STOP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;make clean: only delete the artifacts created here, the clean wipes
currently everything&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;when using this in consecutive order, would cms init not wipe out the data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;should we not mount the .cloudmesh and other data dire into the conatiner.
This way we can use the host system for developments. Maybe we need to&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;support both ways&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;leverage cmsd
we have told the class that we have cmsd taht starts up cloudmesh in
a container. Develop a new directory docker-cmsd and use that&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/docker/ubuntu20.04/todo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/docker/ubuntu20.04/todo/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;
&lt;p&gt;THIS IS JUST THE SKELETON AND HAS NOT BEEN RUN ONCE IT HAS BUGS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;make clean: only delete the artifacts created here, the clean wipes
currently everything&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;when using this in consecutive order, would cms init not wipe out the data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;should we not mount the .cloudmesh and other data dire into the conatiner.
This way we can use the host system for developments. Maybe we need to&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;support both ways&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;leverage cmsd
we have told the class that we have cmsd taht starts up cloudmesh in
a container. Develop a new directory docker-cmsd and use that&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/project_review/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/project_review/</guid>
      <description>
        
        
        &lt;h1 id=&#34;project-review&#34;&gt;Project Review&lt;/h1&gt;
&lt;h2 id=&#34;team-members&#34;&gt;Team members:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Jonathan Beckford&lt;/li&gt;
&lt;li&gt;Brian Kegerreis&lt;/li&gt;
&lt;li&gt;Prateek Shaw&lt;/li&gt;
&lt;li&gt;Jagadeesh Kandimalla&lt;/li&gt;
&lt;li&gt;Ishan Mishra&lt;/li&gt;
&lt;li&gt;Andrew G&lt;/li&gt;
&lt;li&gt;Falconi&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;project-documentation&#34;&gt;Project Documentation:&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-openapi/index.html&#34;&gt;https://cloudmesh.github.io/cloudmesh-openapi/index.html&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;contributors-based-on-git-tracking&#34;&gt;Contributors based on Git tracking&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;NOTE:&lt;/strong&gt;&lt;/em&gt; This is not completely accurate because some did not have git config done correctly.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/graphs/contributors&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/graphs/contributors&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-breakdown&#34;&gt;Code Breakdown&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;cms command:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/command/openapi.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/command/openapi.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; all team&lt;/p&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms generate - to generate server yaml&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;executor&lt;/strong&gt; that parses parameters and calls generator:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/function/executor.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/function/executor.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt;  Brian, Professor&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;generator&lt;/strong&gt; that generates the server yaml:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/function/generator.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/function/generator.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt;  Brian, Jonathan, Prateek&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms server - to start and stop server&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/function/server.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/function/server.py&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Contributors:&lt;/strong&gt;  Jonathan, Andrew, Prateek, Ishan&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms registry - register the server and cache model&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;registry&lt;/strong&gt; - registers server&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/registry/Registry.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/registry/Registry.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Falconi, Praful, Professor&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;cache&lt;/strong&gt; - cache serialized model locally&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/registry/cache.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/registry/cache.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Jonathan&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;fileoperation&lt;/strong&gt; - upload input files&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/registry/fileoperation.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/registry/fileoperation.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Prateek, Brian&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms scikitlearn - generate sklearn functions&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/scikitlearn/SklearnGeneratorFile.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/cloudmesh/openapi/scikitlearn/SklearnGeneratorFile.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Jagadeesh&lt;/p&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms image processing&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Falconi, Ishan&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms text analysis&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contirbutor:&lt;/strong&gt; Andrew Goldfarb&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/tree/main/tests/generator-natural-lang&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/tree/main/tests/generator-natural-lang&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;deployment-steps&#34;&gt;Deployment steps&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-openapi/README.html#installation&#34;&gt;https://cloudmesh.github.io/cloudmesh-openapi/README.html#installation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-openapi/README.html#quick-steps-to-generate-start-and-stop-cpu-sample-example&#34;&gt;https://cloudmesh.github.io/cloudmesh-openapi/README.html#quick-steps-to-generate-start-and-stop-cpu-sample-example&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;pytests&#34;&gt;Pytests&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-openapi/README.html#pytests&#34;&gt;https://cloudmesh.github.io/cloudmesh-openapi/README.html#pytests&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Integration of openapi with cms allows for running locally only.  Cloud integration was not fully completed although team did create a way to setup openapi in a VM using a remote script for &lt;a href=&#34;https://github.com/cloudmesh/get/blob/main/openapi/ubuntu18.04/index.html&#34;&gt;openstack&lt;/a&gt; and &lt;a href=&#34;https://github.com/cloudmesh/get/blob/main/openapi/google/index.html&#34;&gt;google&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The generator only supports creating arrays of number data type.  This limitation is due to the bug documented below in &lt;em&gt;&lt;strong&gt;Bugs&lt;/strong&gt;&lt;/em&gt; section.  So manual changes are required to the output yaml to allow for other data types until another work around is found or the bug is resolved.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;bugs&#34;&gt;Bugs&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;reported a bug to Connexion and documented it in github for future reference:
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/issues/60&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/issues/60&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;additional-artifacts-produced&#34;&gt;Additional artifacts produced:&lt;/h2&gt;
&lt;h3 id=&#34;openstack-vm-set-up-script&#34;&gt;Openstack VM set up script&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/get/blob/main/openapi/ubuntu18.04/index.html&#34;&gt;OPENSTACK&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/get/blob/main/openapi/google/index.html&#34;&gt;GOOGLE&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Jonathan Beckford, Andrew Goldfarb&lt;/p&gt;
&lt;h3 id=&#34;openapi-project-readme-generator&#34;&gt;Openapi project readme generator&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/tree/main/sphinx&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/tree/main/sphinx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Jonathan Beckford, Professor&lt;/p&gt;
&lt;h3 id=&#34;chapters&#34;&gt;Chapters&lt;/h3&gt;
&lt;h5 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h5&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-231/blob/main/chapter/k8s-kubernetes-scheduler.md&#34;&gt;https://github.com/cloudmesh-community/sp20-516-231/blob/main/chapter/k8s-kubernetes-scheduler.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt;  Jonathan Beckford, Brian Kegerreis, Ashok Singam&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/readme-scikitlearn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/readme-scikitlearn/</guid>
      <description>
        
        
        &lt;h1 id=&#34;cloudmesh-openapi-scikit-learn&#34;&gt;Cloudmesh OpenAPI Scikit-learn&lt;/h1&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We use recommend Python 3.8.2 Python or newer.&lt;/li&gt;
&lt;li&gt;We recommend pip version 20.0.2 or newer&lt;/li&gt;
&lt;li&gt;We recommend that you use a venv (see developer install)&lt;/li&gt;
&lt;li&gt;MongoDB installed as regular program not as service&lt;/li&gt;
&lt;li&gt;Please run cim init command to start mongodb server&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We have not checked if it works on older versions.&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;Make sure to follow the instruction for &lt;code&gt;cms openapi&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;When getting started using the &lt;code&gt;openapi&lt;/code&gt;, please first call &lt;code&gt;cms help openapi&lt;/code&gt; to see the available functions and options. For your
convenience we include the manual page later on in this document.&lt;/p&gt;
&lt;h2 id=&#34;scikit-learn-documentation&#34;&gt;Scikit-learn Documentation&lt;/h2&gt;
&lt;p&gt;Scikit-learn is a Machine learning library in Python.We can choose a
ML algorithm like LinearRegression and cloudmesh will be able to spin
up OPENAPI specification for the library we choose.  We can interact
with the Scikit-learn library using either CURL commands or through
GUI.&lt;/p&gt;
&lt;p&gt;This Version of Scikit-learn service accepts csv files in UTF-8 format
only.It is the user responsibility to make sure the files are in UTF-8
format.It is the user responsiblity to split the data in to train and
test datasets.  Split data functionality is not currently supported.&lt;/p&gt;
&lt;h3 id=&#34;setting-up-scikit-learn-service&#34;&gt;Setting up Scikit-learn service&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Please complete the basic installation of
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi&#34;&gt;cloudmesh-openapi&lt;/a&gt;,
To make set up easy the same steps are even referenced at the
Developer Installation section in the document.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can find Scikit-learn documentation in
&lt;a href=&#34;https://scikit-learn.org/dev/modules/classes.html&#34;&gt;Scikit-learn&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The following packages needs to be installed to access Scikit-learn&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;p&gt;pip install pandas
pip install Scikit-learn&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;./cloudmesh-openapi&lt;/code&gt; directory on your machine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Utilize the Scikit-learn generate command to create the python file
which will used to generate OpenAPI spec&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi sklearnreadfile sklearn.linear_model.LinearRegression Linregpytest
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sample generated file can be viewed at
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/tree/main/tests/generator&#34;&gt;tests/generator&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Utilize the generate command to generate OpenAPI spec with upload functionality enabled&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate --filename=./tests/generator/LinearRegression.py --all_functions --enable_upload
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the server after the yaml file is generated ot the same directory as the .py file&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server start ./tests/generator/LinearRegression.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Access the REST service using
&lt;a href=&#34;http://localhost:8080/cloudmesh/ui/&#34;&gt;http://localhost:8080/cloudmesh/ui/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to upload the
testfiles.&lt;/p&gt;
&lt;p&gt;Place your test files in
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/tree/main/tests/Scikitlearn-data&#34;&gt;Scikitlearn-data&lt;/a&gt;
We are testing with X_SAT.csv(SAT Scores of students),y_GPA(GPA of
students)&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST &amp;quot;http://localhost:8080/cloudmesh/upload&amp;quot; \
     -H &amp;quot;accept: text/plain&amp;quot; \
     -H &amp;quot;Content-Type: multipart/form-data&amp;quot; \
     -F &amp;quot;upload=@tests/Scikitlearn-data/X_SAT.csv;type=text/csv&amp;quot;


curl -X POST &amp;quot;http://localhost:8080/cloudmesh/upload&amp;quot; \
     -H &amp;quot;accept: text/plain&amp;quot; \
     -H &amp;quot;Content-Type: multipart/form-data&amp;quot; \
     -F &amp;quot;upload=@tests/Scikitlearn-data/y_GPA.csv;type=text/csv&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to verify fit
method in Scikit-learn using the uploaded files&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/LinearRegression_upload-enabled/fit?X=X_SAT&amp;amp;y=y_GPA&amp;quot; -H &amp;quot;accept: */*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to run the
Predict method.&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/LinearRegression_upload-enabled/predict?X=X_SAT&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to run the Score method.&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/LinearRegression_upload-enabled/score?X=X_SAT&amp;amp;y=y_GPA&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;   
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop the server&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server stop LinearRegression
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;cloudmesh-openapi-service-generator&#34;&gt;Cloudmesh OpenAPI Service Generator&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The README.md page is outomatically generated, do not edit it.
To modify  change the content in
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/README-source.md&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/README-source.md&lt;/a&gt;
Curley brackets must use two in README-source.md&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/cloudmesh-openapi/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/cloudmesh-openapi.svg&#34; alt=&#34;image&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://pypi.python.org/pypi/cloudmesh-openapi&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/cloudmesh-openapi.svg&#34; alt=&#34;Python&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache%202.0-blue.svg&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://pypi.python.org/pypi/cloudmesh-openapi&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/format/cloudmesh-openapi.svg&#34; alt=&#34;Format&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://pypi.python.org/pypi/cloudmesh-openapi&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/status/cloudmesh-openapi.svg&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://travis-ci.com/cloudmesh/cloudmesh-openapi&#34;&gt;&lt;img src=&#34;https://travis-ci.com/cloudmesh/cloudmesh-openapi.svg?branch=main&#34; alt=&#34;Travis&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We recommend Python 3.8.2 Python or newer.&lt;/li&gt;
&lt;li&gt;We recommend pip version 20.0.2 or newer&lt;/li&gt;
&lt;li&gt;We recommend that you use a venv (see developer install)&lt;/li&gt;
&lt;li&gt;MongoDB installed as regular program not as service, which can
easily be done with cloudmesh on macOS, Linux, and Windows.&lt;/li&gt;
&lt;li&gt;Please run &lt;code&gt;cms gui quick&lt;/code&gt; to initialize the password for the mongodb
server&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: On windows you can use &lt;a href=&#34;https://gitforwindows.org/&#34;&gt;gitbash&lt;/a&gt;
so you can use bash and can use the same commands as on Linux or
macOS. Otherwise, please use the appropriate backslashes to access
the path.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;The installation is rather simple  and is documented next.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python -m venv ~/ENV3
source ~/ENV3/bin/activate 
mkdir cm
cd cm
pip install cloudmesh-installer
cloudmesh-installer get openapi 
cms help
cms gui quick
# fill out mongo variables
# make sure autinstall is True
cms config set cloudmesh.data.mongo.MONGO_AUTOINSTALL=True
cms admin mongo install --force
# Restart a new terminal to make sure mongod is in your path
cms init
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you like to know more about the installation of cloudmesh, please
visit the &lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/installation/install.html&#34;&gt;Cloudmesh
Manual&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;command-overview&#34;&gt;Command Overview&lt;/h2&gt;
&lt;p&gt;When getting started using cloudmes &lt;code&gt;openapi&lt;/code&gt;, please first call to
get familiar with the options you have:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms help openapi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We include the manual page later on in this document.&lt;/p&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;Next we provide a very simple quickstart guide to steps to generate a
simple microservice that returns the CPU information of your computer.
We demonstrate how to generate, start, and stop the servive.&lt;/p&gt;
&lt;p&gt;Navigate to &lt;code&gt;~/cm/cloudmesh-openapi&lt;/code&gt; folder. In this folder you will
have a file called &lt;code&gt;cpu.py&lt;/code&gt; from which we will generate the server.&lt;/p&gt;
&lt;p&gt;First, generate an OpenAPI YAML file with the convenient command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate get_processor_name \
    --filename=./tests/server-cpu/cpu.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will create the file &lt;code&gt;cpu.yaml&lt;/code&gt; that contains the OpenAPI
specification. To start the service from this specification simply use
the command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server start ./tests/server-cpu/cpu.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now that the service is up and running, you can issue a request for
example via the commandline with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/get_processor_name&amp;quot; \
     -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To view the automatically generated documentation, you can go to your
browser and open the link&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:8080/cloudmesh/ui&#34;&gt;http://localhost:8080/cloudmesh/ui&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;images/openapi-ui.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;You can also look at the status of the server with the command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server list
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;images/openapi-info.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once yo no longer need the service, you can stop it with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server stop cpu
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;quickstart-to-creating-your-own-microservice&#34;&gt;Quickstart to Creating your own Microservice&lt;/h2&gt;
&lt;p&gt;Cloudmesh uses introspection to generate an OpenAPI compliant YAML
specification that will allow your Python code to run as a web
service. For this reason, any code you write must conform to a set of
guidelines.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The parameters and return values of any functions you write must use
python typing&lt;/li&gt;
&lt;li&gt;Your functions must include docstrings&lt;/li&gt;
&lt;li&gt;If a function uses or returns a class, that class must be defined as
a dataclass in the same file&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next we demonstrate how to create your own microservice.
We provide two examples. One in which we return a float,
te other one in which the return value is wrapped in a
json object.&lt;/p&gt;
&lt;h3 id=&#34;returning-a-float&#34;&gt;Returning a Float&lt;/h3&gt;
&lt;p&gt;We define a function that adds tow values.  Note how x,
y, and the return value are all typed. In this case they are all
&lt;code&gt;float&lt;/code&gt;, but other types are supported. The description in the
docstring will be added to your YAML specification to help describe
what the function does.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def add(x: float, y: float) -&amp;gt; float:
    &amp;quot;&amp;quot;&amp;quot;
    adding float and float.
    :param x: x value
    :type x: float
    :param y: y value
    :type y: float
    :return: result
    :return type: float
    &amp;quot;&amp;quot;&amp;quot;
    result = x + y

    return result
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To generate, start, retrieve a result, and stop the service you can use the
following command sequence:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate add --filename=./tests/add-float/add.py
cms openapi server start ./tests/add-float/add.yaml 
curl -X GET &amp;quot;http://localhost:8080/cloudmesh/add?x=1&amp;amp;y=2&amp;quot; -H  &amp;quot;accept: text/plain&amp;quot;
# This command returns
&amp;gt; 3.0
cms openapi server stop add
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;returning-a-json-object&#34;&gt;Returning a Json Object&lt;/h3&gt;
&lt;p&gt;Often we like to wrap the return value into a json string object, which can easily be
done by modifying the previous example as showcased next.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from flask import jsonify

def add(x: float, y: float) -&amp;gt; str:
    &amp;quot;&amp;quot;&amp;quot;
    adding float and float.
    :param x: x value
    :type x: float
    :param y: y value
    :type y: float
    :return: result
    :return type: float
    &amp;quot;&amp;quot;&amp;quot;
    result = {&amp;quot;result&amp;quot;: x + y}

    return jsonify(result)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To generate, start, retrieve a result, and stop the service you can use the
following command sequence:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate add --filename=./tests/add-json/add.py
cms openapi server start ./tests/add-json/add.yaml 
curl -X GET &amp;quot;http://localhost:8080/cloudmesh/add?x=1&amp;amp;y=2&amp;quot; -H  &amp;quot;accept: text/plain&amp;quot;
# This command returns
&amp;gt; {&amp;quot;result&amp;quot;:3.0}
cms openapi server stop add
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As usual in both cases the web browser can be used to inspect the documentation as well as to test running the
example, by filling out the form.&lt;/p&gt;
&lt;h2 id=&#34;details-of-the-cms-openapi-command&#34;&gt;Details of the &lt;code&gt;cms openapi&lt;/code&gt; command&lt;/h2&gt;
&lt;p&gt;The gaol as stated earlier is to transform a simple python function as a service&lt;/p&gt;
&lt;h3 id=&#34;generating-openapi-specification&#34;&gt;Generating OpenAPI specification&lt;/h3&gt;
&lt;p&gt;Once you have a Python function you would like to deploy as a web
service, you can generate the OpenAPI specification. Navigate to your
.py file&amp;rsquo;s directory and generate the YAML. This will print
information to your console about the YAML file that was generated.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate [function_name] --filename=[filename.py]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you would like to include more than one function in your web
service, like addition and subtraction, use the &lt;code&gt;--all_functions&lt;/code&gt;
flag. This will ignore functions whose names start with &amp;lsquo;_&amp;rsquo;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate --filename=[filename.py] --all_functions
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can even write a class like Calculator that contains functions for
addition, subtraction, etc. You can generate a specification for an
entire class by using the &lt;code&gt;--import_class&lt;/code&gt; flag.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate [ClassName] --filename=[filename.py] --import_class
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;starting-a-server&#34;&gt;Starting a server&lt;/h3&gt;
&lt;p&gt;Once you have generated a specification, you can start the web service
on your localhost by providing the path to the YAML file. This will
print information to your console about the server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server start ./[filename.yaml]

  Starting: [server name]
  PID:      [PID]
  Spec:     ./[filename.py]
  URL:      http://localhost:8080/cloudmesh
  Cloudmesh UI:      http://localhost:8080/cloudmesh/ui
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;sending-requests-to-the-server&#34;&gt;Sending requests to the server&lt;/h3&gt;
&lt;p&gt;Now you have two options to interact with the web service. The first
is to navigate the the Cloudmesh UI and click on each endpoint to test
the functionality. The second is to use curl commands to submit
requests.&lt;/p&gt;
&lt;p&gt;We have already shown you earlier in our quickstart how to apply this to a
service such as our add service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ curl -X GET &amp;quot;http://localhost:8080/cloudmesh/add?x=1.2&amp;amp;y=1.5&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&amp;gt;   2.7
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;stopping-the-server&#34;&gt;Stopping the server&lt;/h3&gt;
&lt;p&gt;Now you can stop the server using the name of the server. If you
forgot the name, use &lt;code&gt;cms openapi server ps&lt;/code&gt; to get a list of server
processes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cms openapi server stop [server name]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;basic-auth&#34;&gt;Basic Auth&lt;/h3&gt;
&lt;p&gt;To use basic http authentication with a user password for the
generated API, add the following flag at the end of a &lt;code&gt;cms openapi generate&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--basic_auth=&amp;lt;username&amp;gt;:&amp;lt;password&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We plan on supporting more security features in the future. Example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate get_processor_name \
    --filename=./tests/server-cpu/cpu.py \
    --basic_auth=admin:secret
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;manual-page&#34;&gt;Manual Page&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;openapi generate [FUNCTION] --filename=FILENAME
                         [--serverurl=SERVERURL]
                         [--yamlfile=YAML]
                         [--import_class]
                         [--all_functions]
                         [--enable_upload]
                         [--verbose]
                         [--basic_auth=CREDENTIALS]
openapi server start YAML [NAME]
              [--directory=DIRECTORY]
              [--port=PORT]
              [--server=SERVER]
              [--host=HOST]
              [--verbose]
              [--debug]
              [--fg]
              [--os]
openapi server stop NAME
openapi server list [NAME] [--output=OUTPUT]
openapi server ps [NAME] [--output=OUTPUT]
openapi register add NAME ENDPOINT
openapi register filename NAME
openapi register delete NAME
openapi register list [NAME] [--output=OUTPUT]
openapi TODO merge [SERVICES...] [--dir=DIR] [--verbose]
openapi TODO doc FILE --format=(txt|md)[--indent=INDENT]
openapi TODO doc [SERVICES...] [--dir=DIR]
openapi sklearn FUNCTION MODELTAG
openapi sklearnreadfile FUNCTION MODELTAG
openapi sklearn upload --filename=FILENAME

Arguments:
  FUNCTION  The name for the function or class
  MODELTAG  The arbirtary name choosen by the user to store the Sklearn trained model as Pickle object
  FILENAME  Path to python file containing the function or class
  SERVERURL OpenAPI server URL Default: https://localhost:8080/cloudmesh
  YAML      Path to yaml file that will contain OpenAPI spec. Default: FILENAME with .py replaced by .yaml
  DIR       The directory of the specifications
  FILE      The specification

Options:
  --import_class         FUNCTION is a required class name instead of an optional function name
  --all_functions        Generate OpenAPI spec for all functions in FILENAME
  --debug                Use the server in debug mode
  --verbose              Specifies to run in debug mode
                         [default: False]
  --port=PORT            The port for the server [default: 8080]
  --directory=DIRECTORY  The directory in which the server is run
  --server=SERVER        The server [default: flask]
  --output=OUTPUT        The outputformat, table, csv, yaml, json
                         [default: table]
  --srcdir=SRCDIR        The directory of the specifications
  --destdir=DESTDIR      The directory where the generated code
                         is placed

Description:
This command does some useful things.

openapi TODO doc FILE --format=(txt|md|rst) [--indent=INDENT]
    Sometimes it is useful to generate teh openaopi documentation
    in another format. We provide fucntionality to generate the
    documentation from the yaml file in a different formt.

openapi TODO doc --format=(txt|md|rst) [SERVICES...]
    Creates a short documentation from services registered in the
    registry.

openapi TODO merge [SERVICES...] [--dir=DIR] [--verbose]
    Merges tow service specifications into a single servoce
    TODO: do we have a prototype of this?


openapi sklearn sklearn.linear_model.LogisticRegression
    Generates the .py file for the Model given for the generator

openapi sklearnreadfile sklearn.linear_model.LogisticRegression
Generates the .py file for the Model given for the generator which supports reading files

openapi generate [FUNCTION] --filename=FILENAME
                             [--serverurl=SERVERURL]
                             [--yamlfile=YAML]
                             [--import_class]
                             [--all_functions]
                             [--enable_upload]
                             [--verbose]
                             [--basic_auth=CREDENTIALS]
    Generates an OpenAPI specification for FUNCTION in FILENAME and
    writes the result to YAML. Use --import_class to import a class
    with its associated class methods, or use --all_functions to 
    import all functions in FILENAME. These options ignore functions
    whose names start with &#39;_&#39;. Use --enable_upload to add file
    upload functionality to a copy of your python file and the
    resulting yaml file.

    For optional basic authorization, we support (temporarily) a single user
    credential. CREDENTIALS should be formatted as follows:

    user:password

    Example: --basic_auth=admin:secret

openapi server start YAML [NAME]
                  [--directory=DIRECTORY]
                  [--port=PORT]
                  [--server=SERVER]
                  [--host=HOST]
                  [--verbose]
                  [--debug]
                  [--fg]
                  [--os]
    starts an openapi web service using YAML as a specification
    TODO: directory is hard coded as None, and in server.py it
      defaults to the directory where the yaml file lives. Can
      we just remove this argument?

openapi server stop NAME
    stops the openapi service with the given name
    TODO: where does this command has to be started from

openapi server list [NAME] [--output=OUTPUT]
    Provides a list of all OpenAPI services in the registry

openapi server ps [NAME] [--output=OUTPUT]
    list the running openapi service

openapi register add NAME ENDPOINT
    Openapi comes with a service registry in which we can register
    openapi services.

openapi register filename NAME
    In case you have a yaml file the openapi service can also be
    registerd from a yaml file

openapi register delete NAME
    Deletes the names service from the registry

openapi register list [NAME] [--output=OUTPUT]
    Provides a list of all registerd OpenAPI services
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;basic-examples&#34;&gt;Basic Examples&lt;/h2&gt;
&lt;p&gt;Please follow &lt;a href=&#34;tests/README.md&#34;&gt;Pytest Information&lt;/a&gt; document for
pytests related information&lt;/p&gt;
&lt;p&gt;We have included a significant number of tests that aso serve as examples&lt;/p&gt;
&lt;h3 id=&#34;example-one-function-in-a-python-file&#34;&gt;Example: One function in a python file&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Please check &lt;a href=&#34;tests/server-cpu/cpu.py&#34;&gt;Python file&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run below command to generate yaml file and start server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate get_processor_name --filename=./tests/server-cpu/cpu.py
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;example-multiple-functions-in-python-file&#34;&gt;Example: Multiple functions in python file&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Please check &lt;a href=&#34;tests/generator-calculator/calculator.py&#34;&gt;Python file&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run below command to generate yaml file and start server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate --filename=./tests/generator-calculator/calculator.py --all_functions
cms openapi generate server start ./tests/generator-calculator/calculator.py
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;example-functions-in-python-class-file&#34;&gt;Example: Function(s) in python class file&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Please check &lt;a href=&#34;tests/generator-testclass/calculator.py&#34;&gt;Python file&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run below command to generate yaml file and start server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate Calculator \
    --filename=./tests/generator-testclass/calculator.py \
    --import_class&amp;quot;
cms openapi server start ./tests/generator-testclass/calculator.yaml
curl -X GET &amp;quot;http://localhost:8080/cloudmesh/Calculator/multiplyint?x=1&amp;amp;y=5&amp;quot;
cms openapi server stop Calculator
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;example-uploading-data&#34;&gt;Example: Uploading data&lt;/h3&gt;
&lt;p&gt;Code to handle uploads is located in
&lt;code&gt;cloudmesh-openapi/tests/generator-upload&lt;/code&gt;. The code snippet in
uploadexample.py and the specification in uploadexample.yaml can be
added to existing projects by adding the &lt;code&gt;--enable_upload&lt;/code&gt; flag to the
&lt;code&gt;cms openapi generate&lt;/code&gt; command. The web service will be able to
retrieve the uploaded file from &lt;code&gt;~/.cloudmesh/upload-file/&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;upload-example&#34;&gt;Upload example&lt;/h4&gt;
&lt;p&gt;This example shows how to upload a CSV file and how the web service
can retrieve it.&lt;/p&gt;
&lt;p&gt;First, generate the OpenAPI specification and start the server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate print_csv2np \
    --filename=./tests/generator-upload/csv_reader.py \
    --enable_upload
cms openapi server start ./tests/generator-upload/csv_reader.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, navigate to localhost:8080/cloudmesh/ui. Click to open
the /upload endpoint, then click &amp;lsquo;Try it out.&amp;rsquo; Click to choose a file
to upload, then upload &lt;code&gt;tests/generator-upload/np_test.csv&lt;/code&gt;. Click
&amp;lsquo;Execute&amp;rsquo; to complete the upload.&lt;/p&gt;
&lt;p&gt;The uploaded file will be located at
&lt;code&gt;~/.cloudmesh/upload-file/[filename]&lt;/code&gt;. The file
&lt;code&gt;tests/generator-upload/csv_reader.py&lt;/code&gt; contains some example code to
retrieve the array in the uploaded file. To see this in action, click
to open the /print_csv2np endpoint, then click &amp;lsquo;Try it out.&amp;rsquo; Enter
&amp;ldquo;np_test.csv&amp;rdquo; in the field that prompts for a filename, and then click
Execute to view the numpy array defined by the CSV file.&lt;/p&gt;
&lt;h3 id=&#34;example-pipeline-anova-svm-example&#34;&gt;Example: Pipeline Anova SVM Example&lt;/h3&gt;
&lt;p&gt;This example is based on the sklearn example
&lt;a href=&#34;https://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection_pipeline.html#sphx-glr-auto-examples-feature-selection-plot-feature-selection-pipeline-py&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this example, we will upload a data set to the server, tell the
server to train the model, and utilize said model for predictions.&lt;/p&gt;
&lt;p&gt;Firstly, ensure we are in the correct directory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pwd
~/cm/cloudmesh-openapi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let us generate the yaml file from our python file to generate the proper specs for our service.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cms openapi generate PipelineAnovaSVM \
      --filename=./tests/Scikitlearn-experimental/sklearn_svm.py \
      --import_class --enable_upload
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now let us start the server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cms openapi server start ./tests/Scikitlearn-experimental/sklearn_svm.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The server should now be active. Navigate to
&lt;code&gt;http://localhost:8080/cloudmesh/ui&lt;/code&gt;. We now have a nice user inteface
to interact with our newly generated API. Let us upload the data
set. We are going to use the iris data set in this example. We have
provided it for you to use. Simply navigate to the &lt;code&gt;/upload&lt;/code&gt; endpoint
by clicking on it, then click &lt;code&gt;Try it out&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We can now upload the file. Click on &lt;code&gt;Choose File&lt;/code&gt; and upload the data
set located at &lt;code&gt;~./tests/Scikitlearn-experimental/iris.data&lt;/code&gt;.  Simply
hit &lt;code&gt;Execute&lt;/code&gt; after the file is uploaded. We should then get a return
code of 200 (telling us that everything went ok).&lt;/p&gt;
&lt;p&gt;The server now has our dataset. Let us now navigate to the &lt;code&gt;/train&lt;/code&gt;
endpoint by, again, clicking on it. Similarly, click &lt;code&gt;Try it out&lt;/code&gt;.
The parameter being asked for is the filename. The filename we are
interested in is &lt;code&gt;iris.data&lt;/code&gt;. Then click &lt;code&gt;execute&lt;/code&gt;.  We should get
another 200 return code with a Classification Report in the Response
Body.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-CLASSIFICATION_REPORT:&#34; data-lang=&#34;CLASSIFICATION_REPORT:&#34;&gt;
           0       1.00      1.00      1.00         8
           1       0.85      1.00      0.92        11
           2       1.00      0.89      0.94        19

    accuracy                           0.95        38
   macro avg       0.95      0.96      0.95        38
weighted avg       0.96      0.95      0.95        38
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Our model is now trained and stored on the server. Let us make a
prediction now. As we have done, navigate to the &lt;code&gt;/make_prediction&lt;/code&gt;
endpoint.  The information we need to provide is the name of the model
we have trained as well as some test data. The name of the model will
be the same as the name of the data-file (ie. iris). So type in &lt;code&gt;iris&lt;/code&gt;
into the &lt;code&gt;model_name&lt;/code&gt; field. Finally for params, let us use the
example &lt;code&gt;5.1, 3.5, 1.4, 0.2&lt;/code&gt; as the model expects 4 values
(attributes). After clicking execute, we should received a response
with the classification the model has made given the parameters.&lt;/p&gt;
&lt;p&gt;The response received should be as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;Classification: [&#39;Iris-setosa&#39;]&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can make as many predictions as we like. When finished, we can shut down the server.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cms openapi server stop sklearn_svm
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;example-to-run-ai-services-in-the-cloud&#34;&gt;Example to Run AI Services in the Cloud&lt;/h2&gt;
&lt;h3 id=&#34;google&#34;&gt;Google&lt;/h3&gt;
&lt;p&gt;After you create your google cloud account, it is recommended to
download and install Google&amp;rsquo;s &lt;a href=&#34;https://cloud.google.com/sdk/docs/quickstarts&#34;&gt;Cloud
SDK&lt;/a&gt;.  This will
enable CLI. Make sure you enable all the required services.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcloud services enable servicemanagement.googleapis.com
gcloud services enable endpoints.googleapis.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and any other services you might be using for your specific Cloud API
function.&lt;/p&gt;
&lt;p&gt;To begin using the tests for any of the Google Cloud Platform AI
services you must first set up a Google account (set up a free tier
account): &lt;a href=&#34;https://cloud.google.com/billing/docs/how-to/manage-billing-account&#34;&gt;Google Account
Setup&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;After you create your google cloud account, it is recommended to
download and install Google&amp;rsquo;s &lt;a href=&#34;https://cloud.google.com/sdk/docs/quickstarts&#34;&gt;Cloud
SDK&lt;/a&gt;.  This will
enable CLI. Make sure you enable all the required services.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcloud services enable servicemanagement.googleapis.com
gcloud services enable servicecontrol.googleapis.com
gcloud services enable endpoints.googleapis.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and any other services you might be using for your specific Cloud API
function.&lt;/p&gt;
&lt;p&gt;It is also required to install the cloudmesh-cloud package, if not
already installed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cloudmesh-installer get cloud
cloudmesh-installer install cloud
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will allow you automatically fill out the cloudmesh yaml file
with your credentials once you generate the servcie account JSON file.&lt;/p&gt;
&lt;p&gt;After you have verified your account is created you must then give your account access to the proper APIs and create a
project in the Google Cloud Platform(GCP) console.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Go to the &lt;a href=&#34;console.cloud.google.com/projectselector2/home/&#34;&gt;project
selector&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow directions from Google to create a project linked to your
account&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;quickstart-google-python-api&#34;&gt;Quickstart Google Python API&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;For quickstart in using Google API for Python visit &lt;a href=&#34;https://developers.google.com/docs/api/quickstart/python&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;setting-up-your-google-account&#34;&gt;Setting up your Google account&lt;/h3&gt;
&lt;p&gt;Before you generate the service account JSON file for your account you
will want to enable a number of services in the GCP console.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google Compute&lt;/li&gt;
&lt;li&gt;Billing&lt;/li&gt;
&lt;li&gt;Cloud Natural Language API&lt;/li&gt;
&lt;li&gt;Translate API&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To do this you will need to click the menu icon in the Dashboard
navigation bar. Ensure you are in the correct porject.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once that menu is open hover over the &amp;ldquo;APIs and Services&amp;rdquo; menu item
and click on &amp;ldquo;Dashboard&amp;rdquo; in the submenu.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At the dashboard click on the &amp;ldquo;+ Enable APIs and Services&amp;rdquo; button
at the top of the dashboard&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Search for &lt;strong&gt;cloud natural language&lt;/strong&gt; to find the API in the search
results and click the result&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once the page opens click &amp;ldquo;Enable&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do the same for the &lt;strong&gt;translate&lt;/strong&gt; API to enable that as well&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do the same for the &lt;strong&gt;compute engine API&lt;/strong&gt; to enable that as well&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You must now properly set up the account roles to ensure you will have
access to the API. Follow the directions from Google to &lt;a href=&#34;https://cloud.google.com/natural-language/docs/setup#auth&#34;&gt;set up proper
authentication&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Make you account an owner for each of the APIs in the IAM tool as
directed in the authentication steps for the natural language API.
This makes your service account have proper access to the required
APIs and once the private key is downloaded those will be stored
there.&lt;/p&gt;
&lt;p&gt;It is VERY important that you create a service account and download
the private key as described in the directions from Google.  If you do
not the cms google commands will not work properly.&lt;/p&gt;
&lt;p&gt;Once you have properly set up your permissions please make sure you
download your JSON private key for the service account that has
permissions set up for the required API services. These steps to
download are found
&lt;a href=&#34;https://cloud.google.com/natural-language/docs/setup#sa-create&#34;&gt;here&lt;/a&gt;.
Please take note of where you store the downloaded JSON and copy the
path string to a easily accessible location.&lt;/p&gt;
&lt;p&gt;The client libraries for each API are included in teh requirements.txt file for the openapi proejct and should be isntalled when the
package is installed. If not, follow directions outlined by google install each package:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;google-cloud-translate
google-cloud-language
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To pass the information from your service account private key file ot
the cloudmesh yaml file run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms register update --kind=google --service=compute --filename=GOOGLE_JSON_FILE
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;running-the-google-natural-language-and-translate-rest-services&#34;&gt;Running the Google Natural Language and Translate REST Services&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;~/.cloudmesh&lt;/code&gt; repo and create a cache directory
for your text examples you would like to analyze.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir text-cache
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add any plain text files your would like to analyze to this
directory with a name that has no special characters or spaces.
You can copy the files at this location,
&lt;code&gt;./cloudmesh-openapi/tests/textanaysis-example-text/reviews/&lt;/code&gt; into
the text-cache if you want to use provided examples.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;./cloudmesh-openapi&lt;/code&gt; directory on your machine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Utilize the generate command to create the OpenAPI spec&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate TextAnalysis --filename=./tests/generator-natural-lang/natural-lang-analysis.py --all_functions
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the server after the yaml file is generated ot the same
directory as the .py file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapie start server ./tests/generator-natural-lang/natural-lang-analysis.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to verify it
returns a result as expected.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sample text file name is only meant to be the name of the file
not the full path.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://127.0.0.1:8080/cloudmesh/analyze?filename=SAMPLE_TEXT_FILENAME&amp;amp;cloud=google&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This is currently only ready to translate a single word through
the API.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://127.0.0.1:8080/cloudmesh/translate_text?cloud=google&amp;amp;text=WORD_TO_TRANSLATE&amp;amp;lang=LANG_CODE&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop the server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server stop natural-lang-analysis
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;example-using-aws&#34;&gt;Example using AWS&lt;/h3&gt;
&lt;p&gt;Sign up for AWS&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go to &lt;a href=&#34;https://portal.aws.amazon.com/billing/signup&#34;&gt;https://portal.aws.amazon.com/billing/signup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Follow online instructions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Create an IAM User&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For instructions, see
&lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_create-admin-group.html&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Set up AWS CLI and AWS SDKs&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To download and instructions to install AWS CLI, see
&lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Install Boto 3&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install boto3
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;For quickstart, vist &lt;a href=&#34;https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As long as you enable all the services you need for using AWS AI APIs you should be able to write your functions for OpenAPI&lt;/p&gt;
&lt;h3 id=&#34;example-using-azure&#34;&gt;Example using Azure&lt;/h3&gt;
&lt;h4 id=&#34;setting-up-azure-sentiment-analysis-and-translation-services&#34;&gt;Setting up Azure Sentiment Analysis and Translation Services&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create an Azure subscription. If you do not have one, create a
&lt;a href=&#34;https://azure.microsoft.com/try/cognitive-services/&#34;&gt;free account&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;a href=&#34;https://portal.azure.com/#create/Microsoft.CognitiveServicesTextAnalytics&#34;&gt;Text Analysis resource&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This link will require you to be logged in to the Azure portal&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account?tabs=multiservice%2Cwindows&#34;&gt;Translation Resource&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The microsoft packages are included in the openapi package
requirements file so they should be installed. If they are not,
install the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install msrest 
pip install azure-ai-textanalytics
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;~/.cloudmesh&lt;/code&gt; repo and create a cache directory for your text examples you would like to analyze.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir text-cache
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add any plain text files your would like to analyze to this
directory with a name that has no special characters or spaces.
You can copy the files at this location,
&lt;code&gt;./cloudmesh-openapi/tests/textanaysis-example-text/reviews/&lt;/code&gt; into
the text-cache if you want to use provided examples.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;./cloudmesh-openapi&lt;/code&gt; directory on your machine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Utilize the generate command to create the OpenAPI spec&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate TextAnalysis --filename=./tests/generator-natural-lang/natural-lang-analysis.py --all_functions
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the server after the yaml file is generated ot the same
directory as the .py file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapie start server ./tests/generator-natural-lang/natural-lang-analysis.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to verify it
returns a result as expected.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sample text file name is only meant to be the name of the file not the full path.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://127.0.0.1:8080/cloudmesh/analyze?filename=&amp;lt;&amp;lt;sample text file name&amp;gt;&amp;gt;&amp;amp;cloud=azure&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This is currently only ready to translate a single word through the API.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Available language tags are described in the &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/cognitive-services/translator/reference/v3-0-languages&#34;&gt;Azure docs&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://127.0.0.1:8080/cloudmesh/translate_text?cloud=azure&amp;amp;text=&amp;lt;&amp;lt;word to translate&amp;gt;&amp;gt;&amp;amp;lang=&amp;lt;&amp;lt;lang code&amp;gt;&amp;gt;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop the server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server stop natural-lang-analysis
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The natural langauge analysis API can be improved by allowing for full
phrase translation via the API. If you contribute to this API there is
room for improvement to add custom translation models as well if
preferred to pre-trained APIs.&lt;/p&gt;
&lt;h4 id=&#34;setting-up-azure-computervision-ai-services&#34;&gt;Setting up Azure ComputerVision AI services&lt;/h4&gt;
&lt;h5 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h5&gt;
&lt;p&gt;Using the Azure Computer Vision AI service, you can describe, analyze
and/ or get tags for a locally stored image or you can read the text
from an image or hand-written file.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Azure subscription. If you do not have one, create a &lt;a href=&#34;https://azure.microsoft.com/try/cognitive-services/&#34;&gt;free
account&lt;/a&gt; before
you continue further.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a Computer Vision resource and get the
&lt;code&gt;COMPUTER_VISION_SUBSCRIPTION_KEY&lt;/code&gt; and
&lt;code&gt;COMPUTER_VISION_ENDPOINT&lt;/code&gt;. Follow
&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account?tabs=singleservice%2Cunix&#34;&gt;instructions&lt;/a&gt;
to get the same.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install following Python packages in your virtual environment:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install requests
pip install Pillow
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install Computer Vision client library&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install --upgrade azure-cognitiveservices-vision-computervision
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;steps-to-implement-and-use-azure-ai-image-and-text-rest-services&#34;&gt;Steps to implement and use Azure AI image and text &lt;em&gt;REST-services&lt;/em&gt;&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Go to &lt;code&gt;./cloudmesh-openapi&lt;/code&gt; directory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run following command to generate the YAML files&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate AzureAiImage --filename=./tests/generator-azureai/azure-ai-image-function.py --all_functions --enable_upload
cms openapi generate AzureAiText --filename=./tests/generator-azureai/azure-ai-text-function.py --all_functions --enable_upload
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify the &lt;em&gt;YAML&lt;/em&gt; files created in &lt;code&gt;./tests/generator-azureai&lt;/code&gt; directory&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;azure-ai-image-function.yaml
azure-ai-text-function.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the REST service by running following command in &lt;code&gt;./cloudmesh-openapi&lt;/code&gt; directory&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server start ./tests/generator-azureai/azure-ai-image-function.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The default port used for starting the service is 8080. In case you
want to start more than one REST service, use a different port in
following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server start ./tests/generator-azureai/azure-ai-text-function.yaml --port=&amp;lt;**Use a different port than 8080**&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Access the REST service using &lt;a href=&#34;http://localhost:8080/cloudmesh/ui/&#34;&gt;http://localhost:8080/cloudmesh/ui/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After you have started the azure-ai-image-function or azure-ai-text-function on default port 8080, run following command to upload the image or text_image file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST &amp;quot;http://localhost:8080/cloudmesh/upload&amp;quot; -H  &amp;quot;accept: text/plain&amp;quot; -H  &amp;quot;Content-Type: multipart/form-data&amp;quot; -F &amp;quot;upload=@tests/generator-azureai/&amp;lt;image_name_with_extension&amp;gt;;type=image/jpeg&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Keep your test image files at &lt;code&gt;./tests/generator-azureai/&lt;/code&gt; directory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;em&gt;azure-ai-text-function&lt;/em&gt; started on port=8080, in order to test the azure ai function for text detection in an image, run following command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/azure-ai-text-function_upload-enabled/get_text_results?image_name=&amp;lt;image_name_with_extension_uploaded_earlier&amp;gt;&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;em&gt;azure-ai-image-function&lt;/em&gt; started on port=8080, in order to
test the azure ai function for describing an image, run following
command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/azure-ai-image-function_upload-enabled/get_image_desc?image_name=&amp;lt;image_name_with_extension_uploaded_earlier&amp;gt;&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;em&gt;azure-ai-image-function&lt;/em&gt; started on port=8080, in order to
test the azure ai function for analyzing an image, run following
command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/azure-ai-image-function_upload-enabled/get_image_analysis?image_name=&amp;lt;image_name_with_extension_uploaded_earlier&amp;gt;&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;em&gt;azure-ai-image-function&lt;/em&gt; started on port=8080, in order to
test the azure ai function for identifying tags in an image, run
following command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/azure-ai-image-function_upload-enabled/get_image_tags?image_name=&amp;lt;image_name_with_extension_uploaded_earlier&amp;gt;&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the running REST services using following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server ps
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop the REST service using following command(s):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server stop azure-ai-image-function
cms openapi server stop azure-ai-text-function
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-of-tests&#34;&gt;List of Tests&lt;/h2&gt;
&lt;p&gt;The following table lists the different test we have, we provide additional
information for the tests in the test directory in a README file. Summaries
are provided below the table&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Test&lt;/th&gt;
&lt;th&gt;Short Description&lt;/th&gt;
&lt;th&gt;Link&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Generator-calculator&lt;/td&gt;
&lt;td&gt;Test to check if calculator api is generated correctly. This is to test multiple function in one python file&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/tests/generator-calculator/test_01_generator.py&#34;&gt;test_01_generator.py&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Generator-testclass&lt;/td&gt;
&lt;td&gt;Test to check if calculator api is generated correctly. This is to test multiple function in one python class file&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/tests/generator-testclass/test_02_generator.py&#34;&gt;test_02_generator.py&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Server-cpu&lt;/td&gt;
&lt;td&gt;Test to check if cpu api is generated correctly. This is to test single function in one python file and function name is different than file name&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/tests/server-cpu/test_03_generator.py&#34;&gt;test_03_generator.py&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Server-cms&lt;/td&gt;
&lt;td&gt;Test to check if cms api is generated correctly. This is to test multiple function in one python file.&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/tests/server-cms/test_04_generator.py&#34;&gt;test_04_generator.py&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Registry&lt;/td&gt;
&lt;td&gt;test_001_registry.py - Runs tests for registry. Description is in tests/README.md&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/tests/README.md&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Image-Analysis&lt;/td&gt;
&lt;td&gt;image_test.py - Runs benchmark for text detection for Google Vision API and AWS Rekognition. Description in image-analysis/README.md&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/tests/image-analysis/README.md&#34;&gt;image&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For more information about test cases ,please check &lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/main/tests/README.md&#34;&gt;tests info&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_001_registry.py&#34;&gt;test_001_registry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_003_server_manage_cpu.py&#34;&gt;test_003_server_manage_cpu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_010_generator.py&#34;&gt;test_010_generator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_011_generator_cpu.py&#34;&gt;test_011_generator_cpu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_012_generator_calculator.py&#34;&gt;test_012_generator_calculator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_015_generator_azureai.py&#34;&gt;test_015_generator_azureai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_020_server_manage.py&#34;&gt;test_020_server_manage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_server_cms_cpu.py&#34;&gt;test_server_cms_cpu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that there a many more tests that you can explore.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/add-float/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/add-float/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;readme&#34;&gt;README&lt;/h1&gt;
&lt;p&gt;please see the README in the root dir of this repository&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/add-json/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/add-json/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;readme&#34;&gt;README&lt;/h1&gt;
&lt;p&gt;please see the README in the root dir of this repository&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/generator-natural-lang/googlecloudvmset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/generator-natural-lang/googlecloudvmset/</guid>
      <description>
        
        
        &lt;h1 id=&#34;steps&#34;&gt;Steps:&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Setup a google account with Google Cloud&lt;/li&gt;
&lt;li&gt;Create a project&lt;/li&gt;
&lt;li&gt;Set permission for create on compute engine in the project&lt;/li&gt;
&lt;li&gt;create a service account file and link to json in cloudmesh yaml file
&lt;a href=&#34;https://cloud.google.com/docs/authentication/production?hl=en_US&#34;&gt;https://cloud.google.com/docs/authentication/production?hl=en_US&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Create a storage location using google storage
&lt;a href=&#34;https://cloud.google.com/storage/docs/creating-buckets#storage-create-bucket-code_samples&#34;&gt;https://cloud.google.com/storage/docs/creating-buckets#storage-create-bucket-code_samples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install the google cloud sdk
&lt;a href=&#34;https://cloud.google.com/compute/docs/tutorials/python-guide&#34;&gt;https://cloud.google.com/compute/docs/tutorials/python-guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install the google cloud api client library
&lt;a href=&#34;https://cloud.google.com/apis/docs/client-libraries-explained&#34;&gt;https://cloud.google.com/apis/docs/client-libraries-explained&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Write a startup script for your vm&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;azure&#34;&gt;Azure&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal&#34;&gt;https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal&lt;/a&gt;
Credentials:
app-name: vm-creation-example
auth url:https://andyvmcreateexample.com/auth&lt;/p&gt;
&lt;p&gt;app (client) ID: 8db85342-7efd-433c-aeba-d175ae4d4404
directory (tenant) id: 398e5475-e850-4239-ba0d-62ddc3e644ff
object ID: 38224a7e-79e0-4642-b765-2bf731d296ad
client-secret: w[f7o=[dKKeSn?VxF3iNoZDW3ctMmd3G
subscription id:4513afc9-4159-49d0-aa1d-0a2a0ab9933c&lt;/p&gt;
&lt;p&gt;when creating a vm in the portal the network interface is set up for you
but if you do it programmatically you have to set it up.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/gregor/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/gregor/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;test-it-yourself&#34;&gt;Test it yourself&lt;/h1&gt;
&lt;p&gt;cd to &lt;code&gt;cloudmesh-openapi&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Start the service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapii server start ./tests/server-cpu.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Stop the service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapii3 server stop cpu
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;urls&lt;/p&gt;
&lt;p&gt;cloudmesh/ui&lt;/p&gt;
&lt;p&gt;cloudmesh/cpu&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/image-analysis/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/image-analysis/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;test-it-yourself&#34;&gt;Test it yourself&lt;/h1&gt;
&lt;h2 id=&#34;in-cloudmesh-openapi&#34;&gt;In cloudmesh-openapi&lt;/h2&gt;
&lt;p&gt;Start server&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cms openapi server start ./tests/image-analysis/image.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Get Response Google Vision&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -sL http://127.0.0.1:8080/cloudmesh/image/detect_text_google
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Get Response AWS Rekognition&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -sL http://127.0.0.1:8080/cloudmesh/image/detect_text_aws
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Stop server&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cms openapi server stop image
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;urls&lt;/p&gt;
&lt;p&gt;cloudmesh/image/detect_text_google&lt;/p&gt;
&lt;p&gt;cloudmesh/image/detect_text_aws&lt;/p&gt;
&lt;h2 id=&#34;image_testpy&#34;&gt;image_test.py&lt;/h2&gt;
&lt;p&gt;How to run test&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/image-analysis/image_test.py 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;image_test.py has 7 tests&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Uses generate command to generate new yaml file&lt;/li&gt;
&lt;li&gt;Check yaml syntax&lt;/li&gt;
&lt;li&gt;Starts server&lt;/li&gt;
&lt;li&gt;Does a curl call for google vision api response&lt;/li&gt;
&lt;li&gt;Does a curl call for aws rekognition api response&lt;/li&gt;
&lt;li&gt;Stops the server&lt;/li&gt;
&lt;li&gt;Prints benchmark&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;how-to-write-and-run-test-case-for-openapi&#34;&gt;How to write and run test case for OpenAPI&lt;/h1&gt;
&lt;h2 id=&#34;this-document-will-explain-how-to-validate-if-openapi-is-generated-correctly-and-server-start-and-stop-working-correctly&#34;&gt;This document will explain how to validate if openapi is generated correctly and server start and stop working correctly&lt;/h2&gt;
&lt;h3 id=&#34;we-have-create-a-framework-class-which-has-below-basic-test-case-functions&#34;&gt;We have create a framework class which has below basic test case functions&lt;/h3&gt;
&lt;p&gt;Framework file is present under tests/lib named as generator_test.py&lt;/p&gt;
&lt;h4 id=&#34;below-test-cases-are-related-to-generator-api&#34;&gt;Below test cases are related to generator API&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Create a build folder and copy py file into it. Build sub folder will created where test py file present.&lt;/li&gt;
&lt;li&gt;It will call generator generate function to generate Yaml file inside build folder&lt;/li&gt;
&lt;li&gt;It will check if generated YMAL file syntax is correct or not.&lt;/li&gt;
&lt;li&gt;It will check if number of function generated in YMAL is same as py file.&lt;/li&gt;
&lt;li&gt;Delete the build folder.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;two-test-cases-are-related-to-server-api&#34;&gt;Two test cases are related to server API&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;It will start server&lt;/li&gt;
&lt;li&gt;It will stop server&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;how-to-create-test-case&#34;&gt;How to create test case&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;If you creating new Open API , then inside tests folder you have to commit your working py and yaml files.&lt;/li&gt;
&lt;li&gt;Create new function for test case where py and yaml located. Example (test_01_generator)&lt;/li&gt;
&lt;li&gt;We have already created test cases function file for generator-calculator name as test_01_generator.py. Please check this file.&lt;/li&gt;
&lt;li&gt;Copy the contains of test_01_generator.py and paste inside your test py file.&lt;/li&gt;
&lt;li&gt;Change startservercommand and filename variables value accordingly to your use case.&lt;/li&gt;
&lt;li&gt;Change some of parameters of constructor of GeneratorBaseTest class.&lt;/li&gt;
&lt;li&gt;if your py file has a class then.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt; &lt;span style=&#34;color:#000&#34;&gt;gen&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; GeneratorBaseTest&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;filename,False,True&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;if your py file has functions then&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt; &lt;span style=&#34;color:#000&#34;&gt;gen&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; GeneratorBaseTest&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;filename,True,False&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;First boolean flag in GeneratorBaseTest for &amp;ndash;all_functions and second flag is for &amp;ndash;import_class&lt;/li&gt;
&lt;li&gt;If you need to write more test cases based on your requirement, check order of test case and write accordingly.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;how-to-run-test-case&#34;&gt;How to run test case&lt;/h3&gt;
&lt;p&gt;Below command can use to run your case. Make sure your current directory is cloudmesh-openapi.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ how &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;do&lt;/span&gt; you call this you can add -x to stop pytest when first &lt;span style=&#34;color:#204a87&#34;&gt;test&lt;/span&gt; failed
pytest -v  --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/generator-calculator/test_01_generator.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;run-test-case-with-csv-command-enabled&#34;&gt;Run test case with CSV command enabled&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ how &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;do&lt;/span&gt; you call this , you can add -x to stop pytest when first &lt;span style=&#34;color:#204a87&#34;&gt;test&lt;/span&gt; failed
pytest -v  --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/generator-calculator/test_01_generator.py  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; fgrep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;# cvs&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;below-are-test-case-files&#34;&gt;Below are test case files&lt;/h2&gt;
&lt;p&gt;Generator-calculator and file name is test_01_generator.py&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pytest -v  --capture=no tests/generator-calculator/test_01_generator.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Generator-testclass and file name is test_02_generator.py&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pytest -v --capture=no tests/generator-testclass/test_02_generator
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Server-cpu and file name is test_03_generator.py&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pytest -v  --capture=no tests/server-cpu/test_03_generator
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Server-cms and file name is test_04_generator.py&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pytest -v  --capture=no tests/server-cms/test_04_generator
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Generator and file name is test_05_generator.py&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pytest -v --capture=no tests/generator/test_05_generator
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Azure AI Image Function is test_06_generator.py&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/generator_azureai/test_06_generator
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Azure AI Text Function is test_07_generator.py&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/generator_azureai/test_07_generator
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Natural Language Analysis Generator Tests are run from test_generator_natural_language.py&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no  ./tests/test_generator_natural_language.py::TestGenerator
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This test will generate an OpenAPI spec for the natural-lang-analysis.py file located in the generator-natural-lang
directory. If the above command is copied and pasted to run in the terminal it will do the following.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generate a yaml file&lt;/li&gt;
&lt;li&gt;Verify the spec has all the functions that are available in the natural-lang-analysis.py file&lt;/li&gt;
&lt;li&gt;Start a server hosting the openAPI spec&lt;/li&gt;
&lt;li&gt;Run a call against the sentiment analysis and translation endpoint for each available cloud service (Google/Azure) and verify it was successful.&lt;/li&gt;
&lt;li&gt;Stop the service&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Results for Natural Language Tests&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Attribute&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;cpu_count&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.active&lt;/td&gt;
&lt;td&gt;2.0 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.available&lt;/td&gt;
&lt;td&gt;2.1 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.free&lt;/td&gt;
&lt;td&gt;148.8 MiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.inactive&lt;/td&gt;
&lt;td&gt;2.0 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.percent&lt;/td&gt;
&lt;td&gt;73.2 %&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.total&lt;/td&gt;
&lt;td&gt;8.0 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.used&lt;/td&gt;
&lt;td&gt;4.8 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.wired&lt;/td&gt;
&lt;td&gt;2.8 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;platform.version&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;python&lt;/td&gt;
&lt;td&gt;3.8.1 (v3.8.1:1b293b6006, Dec 18 2019, 14:08:53)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;[Clang 6.0 (clang-600.0.57)]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;python.pip&lt;/td&gt;
&lt;td&gt;20.0.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;python.version&lt;/td&gt;
&lt;td&gt;3.8.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sys.platform&lt;/td&gt;
&lt;td&gt;darwin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.machine&lt;/td&gt;
&lt;td&gt;x86_64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.node&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.processor&lt;/td&gt;
&lt;td&gt;i386&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.release&lt;/td&gt;
&lt;td&gt;18.2.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.system&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.version&lt;/td&gt;
&lt;td&gt;Darwin Kernel Version 18.2.0: Fri Oct  5 19:41:49 PDT 2018; root:xnu-4903.221.2~2/RELEASE_X86_64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Status&lt;/th&gt;
&lt;th&gt;Time&lt;/th&gt;
&lt;th&gt;Start&lt;/th&gt;
&lt;th&gt;tag&lt;/th&gt;
&lt;th&gt;Node&lt;/th&gt;
&lt;th&gt;User&lt;/th&gt;
&lt;th&gt;OS&lt;/th&gt;
&lt;th&gt;Version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/copy_py_file&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;0.003&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:47&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/generate&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;2.601&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:47&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/read_spec&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;0.012&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:49&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/start_service&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;1.864&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:49&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;test_generator_natural_language/test_run_analyze_google&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;0.67&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:51&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;test_generator_natural_language/test_run_analyze_azure&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;0.58&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:52&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/stop_server&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;2.095&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:52&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/delete_file&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;0.002&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:54&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;todo-describe-what-they-do&#34;&gt;TODO DESCRIBE WHAT THEY DO&lt;/h2&gt;
&lt;p&gt;cache-scikitlearn
deprecated
examples
generator
generator-azureai
generator-calculator
generator-printerclass
generator-testclass
generator-upload
image-analysis
lib
Scikit-learntestfiles
Scikitlearn_tests
server-cms
server-cms-simple
server-cpu
server-sample
server-sampleFunction
test_mlperf
textanalysis-example-text
&lt;strong&gt;init&lt;/strong&gt;.py
README.md
test_001_registry.py
test_03_generator.py
test_010_generator.py
test_011_generator_cpu.py
test_012_generator_calculator.py
test_015_generator_azureai.py
test_020_server_manage.py
test_server_cms_cpu.py
util.py&lt;/p&gt;
&lt;p&gt;THIS WAS HERE BEFORE&lt;/p&gt;
&lt;h2 id=&#34;test_001_registrypy&#34;&gt;test_001_registry.py&lt;/h2&gt;
&lt;p&gt;This test has 5 test functions&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;test_registry_add&lt;/li&gt;
&lt;li&gt;test_registry_list_name&lt;/li&gt;
&lt;li&gt;test_registry_list&lt;/li&gt;
&lt;li&gt;test_registry_delete&lt;/li&gt;
&lt;li&gt;test_benchmark&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Test 1 calls registry and adds to the registry. If successful prints &amp;lsquo;PASSED&amp;rsquo;&lt;/p&gt;
&lt;p&gt;Test 2 calls registry and prints ONLY the server specified in filename.&lt;/p&gt;
&lt;p&gt;Test 3 calls registry and print list for ALL servers in registry.&lt;/p&gt;
&lt;p&gt;Test 4 calls registry and deletes entry for filename.&lt;/p&gt;
&lt;p&gt;Test 5 runs benchmark test on registry.&lt;/p&gt;
&lt;h3 id=&#34;how-to-call-this&#34;&gt;How to call this&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cms &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;filename&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;./tests/server-cpu/cpu.yaml&amp;#34;&lt;/span&gt;
pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/test_001_registry.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;deprecated
examples
generator
generator-calculator
generator-printerclass
generator-testclass
server-class
server-cms
server-cms-simple
server-cpu
server-sample
server-sampleFunction
textanalysis-example-text
&lt;strong&gt;init&lt;/strong&gt;.py
README.md
test_001_registry.py  Falconi
test_03_generator.py  jonthan
test_010_generator.py jonthan
test_011_generator_cpu.py prateek
test_012_generator_calculator.py prateek
test_020_server_manage.py ishan
test_server_cms_cpu.py andrew&amp;ndash;&amp;gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/server-cpu/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/server-cpu/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;test-it-yourself&#34;&gt;Test it yourself&lt;/h1&gt;
&lt;p&gt;cd to &lt;code&gt;cloudmesh-openapi&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Start the service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapii server start ./tests/server-cpu.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Stop the service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapii3 server stop cpu
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;urls&lt;/p&gt;
&lt;p&gt;cloudmesh/ui&lt;/p&gt;
&lt;p&gt;cloudmesh/cpu&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/test_mlperf/readme-source/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/test_mlperf/readme-source/</guid>
      <description>
        
        
        &lt;h1 id=&#34;mlperf-tests&#34;&gt;MLPerf Tests&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;http://mlperf.org&#34;&gt;MLperf&lt;/a&gt; [@www-mlperf] provides &amp;ldquo;fair and useful benchmarks for measuring
training and inference performance of ML hardware, software, and
services&amp;rdquo;&lt;/p&gt;
&lt;p&gt;In this benchmark we will&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Deploy MLPerf on the system&lt;/li&gt;
&lt;li&gt;Use functions that run a number of tests as inout to the OpenAPI Gnerator&lt;/li&gt;
&lt;li&gt;From these functions we run our OpenAPI generator to create a service
that allows to run the MLperf examples through a Web service with
http calls&lt;/li&gt;
&lt;li&gt;Test out the created functions by running selected example invocations&lt;/li&gt;
&lt;li&gt;Report the time it takes to run these examples&lt;/li&gt;
&lt;li&gt;Provide a Makefile or python script that allows us to conveniently
cun these tests&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;
&lt;p&gt;Describe how to deploy&lt;/p&gt;
&lt;h3 id=&#34;reports-for-running-the-tests-on-machines&#34;&gt;Reports for running the tests on Machines&lt;/h3&gt;
&lt;p&gt;Provide summary information about teh runtime
Provide details do checked in results in the &lt;a href=&#34;results&#34;&gt;results&lt;/a&gt; directory&lt;/p&gt;
&lt;h3 id=&#34;local-output&#34;&gt;Local Output&lt;/h3&gt;
&lt;p&gt;All output is written into a &lt;code&gt;~/.cloudmesh/dest/benchmark/mlperf&lt;/code&gt; folder
which can be removed after the test is completed. In the results folder
we also find a copy of the OpenAPI YAML file that is generated with the
cenerator. This file can also be used to compare the generated output.&lt;/p&gt;
&lt;h2 id=&#34;selected-benchmarks&#34;&gt;Selected Benchmarks&lt;/h2&gt;
&lt;p&gt;Describe which benchmarks were selected&lt;/p&gt;
&lt;h2 id=&#34;functions&#34;&gt;Functions&lt;/h2&gt;
&lt;p&gt;Short description aboutthe functions that have been defined&lt;/p&gt;
&lt;h2 id=&#34;opeanapi&#34;&gt;OpeanAPI&lt;/h2&gt;
&lt;p&gt;Describe where to find the generated functions
Link th=o wher ethe open api is created in the&lt;/p&gt;
&lt;h2 id=&#34;how-to-run-individual-tests&#34;&gt;How to run individual tests&lt;/h2&gt;
&lt;p&gt;Describe how to run indific=dual Tests&lt;/p&gt;
&lt;h2 id=&#34;benchmarks&#34;&gt;Benchmarks&lt;/h2&gt;
&lt;p&gt;Links to benchmarks that are listed in the &lt;a href=&#34;results&#34;&gt;results&lt;/a&gt; directory&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/test_mlperf/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/test_mlperf/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;mlperf-tests&#34;&gt;MLPerf Tests&lt;/h1&gt;
&lt;p&gt;According to &lt;a href=&#34;https://mlperf.org/&#34;&gt;https://mlperf.org/&lt;/a&gt; MLPerf provides &amp;quot; Fair and useful
benchmarks for measuring training and inference performance of ML
hardware, software, and services&amp;rdquo; [@www-mlperf]&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/test_mlperf/results/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/test_mlperf/results/readme/</guid>
      <description>
        
        
        &lt;p&gt;put your result files here&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/timeseries-example/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/timeseries-example/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;time-series-forecast-using-multi-cloud-ai-services&#34;&gt;Time Series Forecast using Multi Cloud AI Services&lt;/h1&gt;
&lt;p&gt;Prafull Porwal, &lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-255/blob/main/Cloudmesh-OpenAPI/Readme.md&#34;&gt;sp20-516-255&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-255/graphs/contributors&#34;&gt;Contributors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/fa19-516-147/pulse&#34;&gt;Insights&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-255/tree/main/Cloudmesh-OpenAPI/AWSForecast&#34;&gt;Project Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;objective&#34;&gt;Objective&lt;/h2&gt;
&lt;p&gt;Develop Open API for time series forecasting on multiple clouds&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Many cloud providers have introduced machine learning capabilities on their infrastructure. The project aims to provide an open API for timeseries forecasting for AWS using Forecast Services and S3&lt;/p&gt;
&lt;h3 id=&#34;aws-ai-service--forecast-open-api-service-features&#34;&gt;AWS AI Service : Forecast Open API Service Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Upload the data file to ./cloudmesh/upload-file location&lt;/li&gt;
&lt;li&gt;Upload the json schema file to ./cloudmesh/upload-file location&lt;/li&gt;
&lt;li&gt;Validate the data for missing and less than 0 values&lt;/li&gt;
&lt;li&gt;Split the dataset into Train and test by specifying split percentge.&lt;/li&gt;
&lt;li&gt;Provide list of Multi Cloud supported for Timeseries Forecasting&lt;/li&gt;
&lt;li&gt;Initialize the cloud service&lt;/li&gt;
&lt;li&gt;Create a Dataset Group&lt;/li&gt;
&lt;li&gt;Create a Target Time Series Dataset&lt;/li&gt;
&lt;li&gt;Import data into Forecast from AWS Storage S3&lt;/li&gt;
&lt;li&gt;Create a Predictor&lt;/li&gt;
&lt;li&gt;Generate Forecast&lt;/li&gt;
&lt;li&gt;Query the Forecast&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;additional-features&#34;&gt;Additional Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Multiple instance of the process supported&lt;/li&gt;
&lt;li&gt;Data Validation and missing values checks&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;environment-configuration&#34;&gt;Environment Configuration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Python 3.8.2 Python or newer.&lt;/li&gt;
&lt;li&gt;Use a venv (see developer install)&lt;/li&gt;
&lt;li&gt;MongoDB installed as regular program not as service&lt;/li&gt;
&lt;li&gt;AWS boto3 library&lt;/li&gt;
&lt;li&gt;Open API package installed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Make sure that cloudmesh is properly installed on your machine and you have mongodb setup to work with cloudmesh.
More details can be found in the &lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/installation/install.html&#34;&gt;Cloudmesh Manual&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;openapi-package-installation&#34;&gt;OpenAPI package installation&lt;/h3&gt;
&lt;p&gt;Make sure you use a python venv before installing. Users can install the code with&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ pip install cloudmesh-openapi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;pre-requisites-&#34;&gt;Pre Requisites :&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;add below parameter to cloudmesh.yaml for forecast service to work&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bucket_name : awsforecastassignnment&lt;/li&gt;
&lt;li&gt;region_name : us-east-1&lt;/li&gt;
&lt;li&gt;forecast_srv : forecast&lt;/li&gt;
&lt;li&gt;forecastquery_srv : forecastquery&lt;/li&gt;
&lt;li&gt;s3_srv : s3&lt;/li&gt;
&lt;li&gt;iam_role_arn: XXXXXX&lt;/li&gt;
&lt;li&gt;algorithmArn: arn:aws:forecast:::algorithm/Deep_AR_Plus&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Data Format : The data should be in csv file format and must have&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;item_id : reference column for which time series forecast is required&lt;/li&gt;
&lt;li&gt;target_value : the column which need to be predicted, data type integer&lt;/li&gt;
&lt;li&gt;timestamp : timestamp of data samples&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/forecast/latest/dg/API_CreateDataset.html&#34;&gt;AWS Time Series Forecast&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Json Schema : Json Schema file with name schema.json&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;quick-forecast-api-reference-commands&#34;&gt;Quick Forecast API reference Commands&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Start the open API server for the forecast service&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cms openapi server start .//forecast.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check for supported AI services&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://localhost:8080/cloudmesh/forecast
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;e.g. output:
&amp;ldquo;model&amp;rdquo;: &amp;ldquo;Supported Time Series Forecast Services AWS : Forecast &amp;quot;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Upload file to the server from location (
File path should be the location on server where file is located.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;http://localhost:8080/cloudmesh/forecast/upload&amp;#34;&lt;/span&gt; -F &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;upload=@&amp;lt;file_path&amp;gt;\countries-aggregated.csv&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;e.g. output:
countries-aggregated.csv uploaded successfully&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Validate data file&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;http://localhost:8080/cloudmesh/forecast/validate_data&amp;#34;&lt;/span&gt; -F &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;upload=@&amp;lt;file_path&amp;gt;\countries-aggregated.csv&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;e.g. output:
countries-aggregated.csv validated successfully&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Split the data into test and train. Data should be validated first before splitting&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://localhost:8080/cloudmesh/forecast/split_data?split_pct&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;output: &amp;ldquo;Please validate the data first&amp;rdquo;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://localhost:8080/cloudmesh/forecast/split_data?split_pct&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;output: &amp;ldquo;Data split successfully&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Initialize aws parameters&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;http://localhost:8080/cloudmesh/forecast/aws&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;e.g. output:
{&amp;ldquo;model&amp;rdquo;:&amp;ldquo;AWS AI Service initialized successfully&amp;rdquo;}&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create Forecast, this is a multistep process, it cretes datasetgroup, dataset, import job, predictor and forecast&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://localhost:8080/cloudmesh/forecast/create_forecast?country&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;Austrailia
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This api expects cloud services to be already initialized if not it will request to initialize
output:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Please initialize cloud service&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;output: &amp;ldquo;Forecast generated successfully&amp;rdquo;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lookup a Forecast&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://localhost:8080/cloudmesh/forecast/lookupForecast?countryName&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;Austrailia
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;output :
shows &lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-255/blob/main/Cloudmesh-OpenAPI/AWSForecast/sampleOutput&#34;&gt;ouput&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Delete Data Stack for the current project
This API should be executed at the end of the session to delete all the resources created for the analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;http://localhost:8080/cloudmesh/forecast/deletestack&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;algorithm-details&#34;&gt;Algorithm details&lt;/h2&gt;
&lt;p&gt;The AWS Forecast service supports following pre-defined algortithms&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Autoregressive Integrated Moving Average (ARIMA) Algorithm - arn:aws:forecast:::algorithm/ARIMA&lt;/li&gt;
&lt;li&gt;DeepAR+ Algorithm - arn:aws:forecast:::algorithm/Deep_AR_Plus&lt;/li&gt;
&lt;li&gt;Exponential Smoothing (ETS) - arn:aws:forecast:::algorithm/ETS&lt;/li&gt;
&lt;li&gt;Non-Parametric Time Series (NPTS) Algorithm - arn:aws:forecast:::algorithm/NPTS&lt;/li&gt;
&lt;li&gt;Prophet Algorithm - arn:aws:forecast:::algorithm/Prophet&lt;/li&gt;
&lt;li&gt;Supports hyperparameter optimization (HPO)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/forecast/latest/dg/forecast.dg.pdf&#34;&gt;AWS Time Series Forecast&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Requires data file with mandatory colums item_id, target_value and timestamp&lt;/li&gt;
&lt;li&gt;Requires a schema file schema.json to be provided by the user&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/forecast/latest/dg/forecast.dg.pdf&#34;&gt;https://docs.aws.amazon.com/forecast/latest/dg/forecast.dg.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/aws-samples/amazon-forecast-samples&#34;&gt;https://github.com/aws-samples/amazon-forecast-samples&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-301/assignment6/assignment6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-301/assignment6/assignment6/</guid>
      <description>
        
        
        &lt;h1 id=&#34;assignment-6&#34;&gt;Assignment 6&lt;/h1&gt;
&lt;h1 id=&#34;health-and-medicine--artificial-intelligence-influence-on-ischemic-stroke-imaging&#34;&gt;Health and Medicine â€“ Artificial Intelligence Influence on Ischemic Stroke Imaging&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Gavin Hemmerlein, fa20-523-301&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-301/blob/master/assignment6/assignment6.md&#34;&gt;Edit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; convolutional neural network, random forest learning, Computer Tomography Scan, CT Scan, stroke, artificial intelligence, deep learning, machine learning, large vessel occlusions&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;The Computer Tomography Scan (CT Scan) is a medical procedure that involves multiple x-rays analyzed using computer aided techniques. The CT Scanâ€™s creation was credited to Allan M. Cormack and Godfrey N. Hounsfield for which both individuals were awarded the 1979 Nobel Prize in Physiology or Medicine &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. The OECD estimates that there are a total of 42.64 million scanners located in the United States; the fourth most of any country &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. This prevalence is extremely important when discussing a diagnosis for stroke victims. In the 1980s, the identification techniques were generally done through a process called computer-aided diagnosis (CAD). â€œCAD usually relies on a combination of interpretation of medical images through computational algorithms and the physiciansâ€™ evaluation of the medical images &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;â€.&lt;/p&gt;
&lt;p&gt;The goal of researchers and medical practitioners is to improve upon detection rates to ensure that more lives are saved by early detection. According to Johns Hopkins Medical Department the faster medical precautions can be given to a victim, the better the prognosis is for the individual &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. The brain requires a constant supply of blood and oxygen. When it is starved of these nutrients, the brain tissue begins to die.&lt;/p&gt;
&lt;h2 id=&#34;2-assisting-researchers-with-artificial-intelligence&#34;&gt;2. Assisting Researchers with Artificial Intelligence&lt;/h2&gt;
&lt;p&gt;According to an article in Radiology Business, automated detection of stroke anomalies is improving. As stated in a review in the article, â€œthe team found convolutional neural networks beat random forest learning (RFL) on sensitivity, 85% to 68% &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.â€ This improvement is an excellent improvement by switching the algorithm that is used to train the model. A convolutional neural network (CNN) is a deep learning technique while a random forest is a modified decision tree. By modifying approaches from a decision tree to a deep learning technique, there is a very high likelihood that more lives could be saved. Strokes account for nearly 140,000 deaths a year and are one of the leading causes of permanent disability in the United States &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;A RFL algorithm is a form of decision tree supervised learning. Decision trees are unique because they can also be used to solve regression and classification problems; which is unique to supervised learning methods. The RFL uses many decision trees that build upon one another. Where the CNN algorithm differs is that it is a form of deep learning that performs unsupervised learning. Each layer in the CNN understands its inputs and outputs while passing the output on to the next layer. A CNN can pass this information forward through a number of layers, but there is also a diminishing return given the amount of processing needed for each layer.&lt;/p&gt;
&lt;p&gt;After reviewing the literature from the Radiology Business article, the most common avenue for early detection appears to be the RFL as stated above. A meta analysis reviewing PubMed articles from January 2014 to February 2019 found that the RFL was the highest performer for predictive measures &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;. For large vessel occlusions (LVO), the best approach was to use a CNN. CNNâ€™s use little pre-processing and rely moreso on the filters with the data. This results in a more dynamic approach to the data as opposed to the harder developed structure of a decision tree.&lt;/p&gt;
&lt;h2 id=&#34;3-future-work&#34;&gt;3. Future Work&lt;/h2&gt;
&lt;p&gt;Upon examining the cited sources, there are some future areas to look research. To improve on current understanding, a standardization of metrics for to evaluate the fidelity of the models &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;, continued development of automative image analysis software &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;, and leveraging emerging techniques to develop even more effective algorithms to detect large vessel occlusion &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;. As of 2019, the advantage of CNNâ€™s over conventional detection methods was only 7.6% &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;. The percentage may seem marginal, but when expanded out to the 140,000 strokes per year the amount of strokes identified could be as much as 10,000 individuals.&lt;/p&gt;
&lt;p&gt;These areas are only a few of the many improvements that could be made in the world of stroke detection. It is not a far stretch to imagine detecting vessels that are becoming clogged or brittle. If detection of these medical issues could become prevalent, even more lives could be saved by predicting strokes before they even occur.&lt;/p&gt;
&lt;h2 id=&#34;4-references&#34;&gt;4. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Nobel Prizes &amp;amp; Laureates, &amp;ldquo;The Nobel Prize in Physiology or Medicine 1979,&amp;rdquo; &lt;em&gt;The Nobel Prize,&lt;/em&gt; [Online]. Available:
&lt;a href=&#34;https://www.nobelprize.org/prizes/medicine/1979/summary/&#34;&gt;https://www.nobelprize.org/prizes/medicine/1979/summary/&lt;/a&gt; [Accessed Oct. 16, 2020]. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;OECD, &amp;ldquo;Computed tomography (CT) scanners,&amp;rdquo; &lt;em&gt;OECD Data,&lt;/em&gt; [Online]. Available:
&lt;a href=&#34;https://data.oecd.org/healtheqt/computed-tomography-ct-scanners.htm&#34;&gt;https://data.oecd.org/healtheqt/computed-tomography-ct-scanners.htm&lt;/a&gt; [Accessed Oct. 16, 2020]. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Y. Mokli, J. Pfaff, D. Pinto dos Santos, C. Herweh, and S. Nagel &amp;ldquo;Computer-aided imaging analysis in acute ischemic stroke â€“ background and clinical applications&amp;rdquo;, &lt;em&gt;Neurological Research and Practice&lt;/em&gt;, p. 1-13. 2020 [Online serial]. Available:  &lt;a href=&#34;https://neurolrespract.biomedcentral.com/track/pdf/10.1186/s42466-019-0028-y&#34;&gt;https://neurolrespract.biomedcentral.com/track/pdf/10.1186/s42466-019-0028-y&lt;/a&gt; [Accessed Oct. 13, 2020]. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;A. Pruski, â€œStroke Recovery Timeline,â€ &lt;em&gt;John Hopkins Medical,&lt;/em&gt; [Online]. Available: &lt;a href=&#34;https://www.hopkinsmedicine.org/health/conditions-and-diseases/stroke/stroke-recovery-timeline&#34;&gt;https://www.hopkinsmedicine.org/health/conditions-and-diseases/stroke/stroke-recovery-timeline&lt;/a&gt; [Accessed Oct. 16, 2020]. &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;D. Pearson, &amp;ldquo;AI helps bust stroke, identify occlusions,&amp;rdquo; &lt;em&gt;Radiology Business,&lt;/em&gt; [Online]. Available:
&lt;a href=&#34;https://www.radiologybusiness.com/topics/artificial-intelligence/ai-helps-bust-stroke-identify-occlusions&#34;&gt;https://www.radiologybusiness.com/topics/artificial-intelligence/ai-helps-bust-stroke-identify-occlusions&lt;/a&gt; [Accessed Oct. 13, 2020]. &lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;The Internet Stroke Center, &amp;ldquo;About Strokes,&amp;rdquo; &lt;em&gt;Stroke Statistics,&lt;/em&gt; [Online]. Available:
&lt;a href=&#34;http://www.strokecenter.org/patients/about-stroke/stroke-statistics/#:~:text=More%20than%20140%2C000%20people%20die,and%20185%2C000%20are%20recurrent%20attacks&#34;&gt;http://www.strokecenter.org/patients/about-stroke/stroke-statistics/#:~:text=More%20than%20140%2C000%20people%20die,and%20185%2C000%20are%20recurrent%20attacks&lt;/a&gt; [Accessed Oct. 16, 2020]. &lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;N. Murray, &amp;ldquo;Artificial intelligence to diagnose ischemic stroke and identify large vessel occlusions: a systematic review,&amp;rdquo; &lt;em&gt;Journal of NeuroInterventional Surgery&lt;/em&gt;, vol. 12, no. 2, p. 156-164. 2020 [Online serial]. Available: &lt;a href=&#34;https://jnis.bmj.com/content/12/2/156&#34;&gt;https://jnis.bmj.com/content/12/2/156&lt;/a&gt; [Accessed Oct. 13, 2020]. &lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;M. Stib, J. Vasquez, M. Dong, Y. Kim, S. Subzwari, H. Triedman, A. Wang, H. Wang, A. Yao, M. Jayaraman, J. Boxerman, C. Eickhoff, U. Cetintemel, G. Baird, and R. McTaggart, &amp;ldquo;Detecting Large Vessel Occlusion at Multiphase CT Angiography by Using a Deep Convolutional Neural Network&amp;rdquo;, &lt;em&gt;Original Research Neuroradiology&lt;/em&gt;, Sep 29, 2020. [Online serial]. Available: &lt;a href=&#34;https://pubs.rsna.org/doi/full/10.1148/radiol.2020200334&#34;&gt;https://pubs.rsna.org/doi/full/10.1148/radiol.2020200334&lt;/a&gt; [Accessed Oct. 13, 2020]. &lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;J. Tuan, &amp;ldquo;How AI is able to Predict and Detect a Stroke&amp;rdquo;, &lt;em&gt;Referral MD&lt;/em&gt;. [Online]. Available: &lt;a href=&#34;https://getreferralmd.com/2019/10/how-ai-is-able-to-predict-and-detect-a-stroke/&#34;&gt;https://getreferralmd.com/2019/10/how-ai-is-able-to-predict-and-detect-a-stroke/&lt;/a&gt; [Accessed Oct. 13, 2020]. &lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-301/project/misc_files/blank/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-301/project/misc_files/blank/</guid>
      <description>
        
        
        &lt;h1 id=&#34;blank&#34;&gt;Blank&lt;/h1&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-301/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-301/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;nba-performance-and-injury&#34;&gt;NBA Performance and Injury&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Gavin Hemmerlein, fa20-523-301&lt;/li&gt;
&lt;li&gt;Chelsea Gorius, fa20-523-344&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-301/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Abstract to be added when content is finalized.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-dataset&#34;&gt;3. Dataset&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-methodology&#34;&gt;4. Methodology&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#41-development-of-models&#34;&gt;4.1 Development of Models&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-inference&#34;&gt;5. Inference&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-conclusion&#34;&gt;6. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#71-work-breakdown&#34;&gt;7.1 Work Breakdown&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#8-references&#34;&gt;8. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; basketball, NBA, injury, performance, salary, rehabilitation, artificial intelligence, convolutional neural network.&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;The topic to be investigated is basketball player performance as it relates to injury. The topic of injury and recovery is a multi-billion dollar industry.  The Sports Medicine field is expected to reach $7.2 billion dollars by 2025 &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.  The scope of this effort is to explore National Basketball Association(NBA) teams, but the additional uses of a topic such as this could expand into other realms such as the National Football League, Major League Baseball, the Olympic Committees, and many other avenues.  For leagues with salaries, projecting an expected return on the investment can assist in contract negotiations and cater expectations.  Competing at such a high level of intensity puts these players at a greater risk to injury than the average athlete because of the intense and constant strain on their bodies.  The overall valuation of the NBA in recent years is over 2 billion dollars, meaning each team is spending millions of dollars in the pursuit of a championship every season.  Injuries to players can cost teams not only wins but also significant profits.  Ticket sales alone for a single NBA finals game have reported greater than 10 million dollars in profit for the home team, if a team&amp;rsquo;s star player gets injured just before the playoffs and the team does not succeed, that is a lot of money lost.  These injuries can have an effect no matter the time of year, regular season ticket sales have been known to fluctuate with injuries from the team&amp;rsquo;s top performers.  Besides ticket sales these injuries can also influence viewrship, TV or streaming, and potentially lead to a greater loss in profits.  With the health of the players and so much money at stake NBA team organizations as a whole do their best to take care of their players and keep them injury free.&lt;/p&gt;
&lt;h2 id=&#34;2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/h2&gt;
&lt;p&gt;The assumptions were made based on current literature as well. The injury return and limitations upon return of Anterior Cruciate Ligament (ACL) rupture (ACLR) are well documented and known. Interesting enough, forty percent of the players in the study occured during the fourth quarter &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. This leads some credence to the idea that fatigue is a major factor in the occurrence of these injuries.&lt;/p&gt;
&lt;p&gt;The current literature also shows that a second or third injury can occur more frequently due to minor injuries. &amp;ldquo;When an athlete is recovering from an injury or surgery, tissue is already compromised and thus requires far more attention despite the recovery of joint motion and strength. Moreover, injuries and surgical procedures can create detraining issues that increase the likelihood of further injury&amp;rdquo; &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;3-dataset&#34;&gt;3. Dataset&lt;/h2&gt;
&lt;p&gt;To compare performance and injury, a minimum of two datasets will be needed. The first is a dataset of injuries for players &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. This dataset will create the samples necessary for review.&lt;/p&gt;
&lt;p&gt;Once the controls for injuries are established, the next requirement will be to establish  pre-injury performance parameters and post-injury parameters.  These areas will be where the feature engineering will take place.  The datasets needed must dive into appropriate basketball performance stats to establish a metric to encompass a playerâ€™s performance. One example that ESPN has tried in the past is the Player Efficiency Rating (PER).  To accomplish this, it will be important to review player performance within games such as in the â€œNBA games dataâ€ &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; dataset.  There is a potential to pull more data from other datasets such as the â€œNBA Enhanced Box Score and Standings (2012 - 2018)â€ &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.  It is important to use the in depth data from the â€œNBA games dataâ€ &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. dataset because of how it will allow us to see how the player was performing throughout the season, and not just their average stats across the year.  With in depth information about each game of the season, and not just the teams and players aggregated stats, added to the data provided from the injury dataset &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; we will be able to compose new metrics to understand how these injuries are actually affecting the players performance.&lt;/p&gt;
&lt;p&gt;Along the way we look forward to discovering if there is also a causal relationship to the severity of some of the injuries, based on how the player was performing just before the injury.  The term â€œload managementâ€ has become popular in recent years to describe players taking rest periodically throughout the season in order to prevent injury from overplaying.  This new practice has received both support for the player safety it provides and also criticism around players taking too much time off.  Of course not all injuries are entirely based on the recent strain under the players body, but a better understanding about how that affects the injury as a whole could give better insight into avoiding more injuries.  It is important to remember though that any pattern identification would not lead to an elimination of all injuries, any contact sport will continue to have injuries, especially one as high impact as the NBA.  There is value to learn from why some players are able to return from certain injuries more quickly and why some return to almost equivalent or better playing performance than before the injury.  This comparison of performance will be made by deriving metrics based on varying ranges of games immediately leading up to injury and then immediately after returning from injury.  In addition to that we will perform comparisons to the players known peak performance to better understand how the injury affected them.  Another factor it will be important to include is the length of time recovering from the injury. Different players take differing amounts of time off, sometimes even with similar injuries.  Something will be said about the playerâ€™s dedication to recovery and determination to remain at peak performance, even through injury, when looking at how severe their injury was, how much time was taken for recovery, and how they performed upon returning.&lt;/p&gt;
&lt;p&gt;These datasets were chosen because they allow for a review of individual game performance, for each team, throughout each season in the recent decade.  Aggregate statistics such as points per game (ppg) can be deceptive because duration of the metric is such a large period of time.  The large sample of 82 games can lead to a perception issue when reviewing the data.  These datasets include more variables to help us determine effects to player injury, such as minutes per game (mpg) to understand how strenuous the pre-injury performance or how fatigue may have played a factor in the injury.  Understanding more of the variables such as fouls given or drawn can help determine if the player or other team seemed to be the primary aggressor before any injury.&lt;/p&gt;
&lt;h2 id=&#34;4-methodology&#34;&gt;4. Methodology&lt;/h2&gt;
&lt;p&gt;The objective of this project is to develop performance indicators for injured players returning to basketball in the NBA.  It is unreasonable to expect a player to return to the same level of play post injury immediately upon starting back up after recovery.  It often takes a player months if not years to return to the same level of play as pre-injury, especially considering the severity of the injuries.  In order to successfully analyse this information from the datasets, a predictive model will need to be created using a large set of the data to train.&lt;/p&gt;
&lt;p&gt;From this point, a test run will be used to gauge the validity and accuracy of the model compared to some of the data set aside.  The model created will be able to provide feature importance to give a better understanding of which specific features are the most crucial when it comes to determining how bad the effects of an injury may or may not be on player performance.  Feature engineering will be performed prior to training the model in order to improve the chances of higher accuracy from the predictions.  This model could be used to keep an eye out for how a player&amp;rsquo;s performance intensity and the engineered features could affect how long a player takes to recover from injury, if there are any warning signs prior to an injury, and even how well they perform when returning.&lt;/p&gt;
&lt;h3 id=&#34;41-development-of-models&#34;&gt;4.1 Development of Models&lt;/h3&gt;
&lt;p&gt;The initial model that was used was a Logistic Regression model. This model produced results of &lt;em&gt;X&lt;/em&gt;. These results&lt;/p&gt;
&lt;p&gt;After running a Logistic Regression model, the decision was made to try multiple models to see what gives the best results. The team decided to use a Linear Regression model.&lt;/p&gt;
&lt;p&gt;Another algorithm chosen was a Light Gradient Boost Machine (LightGBM) model. LightGBM is known for it&amp;rsquo;s lightweight and resource sparse abilities. The model is built from decision tree algorithms and used for ranking, classification, and other machine learning tasks. By choosing LightGBM data scientists are able to analyze larger data a faster approach. LightGBM  can often over fit a model if the data is too small, but fortunately for the purpose of this assignment the data available for NBA injuries and stats is extremely large. Availability of data allowed for smooth operation of the LightGBM model.&lt;/p&gt;
&lt;p&gt;The final model attempted was a Keras model. A few runs of different layers and epochs were chosen. The models sequentially ran through the test layers to refine the model. When this is done, each predecessor layer acts as an input to the next layer&amp;rsquo;s model. The results can produce accurate results while using unsupervised learning.&lt;/p&gt;
&lt;h2 id=&#34;5-inference&#34;&gt;5. Inference&lt;/h2&gt;
&lt;p&gt;With the data available, some conclusions can be made. Not all injuries are of the same severity. By treating an ACL tear in the same manner as a bruise, the team doctors would take terrible approaches to rehab. The severity of the injury is a part of the approach to therapy.&lt;/p&gt;
&lt;p&gt;Another aspect to come to a conclusion is that not every player recovers in the same timetable as another. Genetics, diet, and mental health can all harm or reinforce the efforts from the medical staff. These areas are hard to capture in the data and cannot be appropriately reviewed.&lt;/p&gt;
&lt;p&gt;It is also difficult to indicate where a previous injury may have contributed to a current injury. The kinetic chain is a structure of the musculoskeletal system that moves the body using the muscles and bones. If one portion of the chain is compromised, the entire chain will need to be modified to continue movement. This modification can result in more injuries. The data cannot provide this information.&lt;/p&gt;
&lt;h2 id=&#34;6-conclusion&#34;&gt;6. Conclusion&lt;/h2&gt;
&lt;p&gt;This section will be addressed upon project completion.&lt;/p&gt;
&lt;p&gt;After reviewing the results, performance does indeed appear to degrade over time.&lt;/p&gt;
&lt;p&gt;These results are consistent with the current scientific literature &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Initial Project Report - Gorius, Hemmerlein
Predictive Model - breakdown udetermined at this time&lt;/p&gt;
&lt;h2 id=&#34;7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/h2&gt;
&lt;p&gt;The author would like to thank Dr. Gregor Von Laszewski, Dr. Geoffrey Fox, and the associate instructors in the &lt;em&gt;FA20-BL-ENGR-E534-11530: Big Data Applications&lt;/em&gt; course (offered in the Fall 2020 semester at Indiana University, Bloomington) for their continued assistance and suggestions with regard to exploring this idea and also for their aid with preparing the various drafts of this article.&lt;/p&gt;
&lt;h3 id=&#34;71-work-breakdown&#34;&gt;7.1 Work Breakdown&lt;/h3&gt;
&lt;p&gt;For the effort developed, the team split tasks between each other to cover more ground. The requirements for the investigation required a more extensive effort for the teams in the ENGR-E 534 class. To accomplish the requirements, the task was expanded by addressing multiple datasets within the semester and building in multiple models to display the results. The team members were responsible for committing in Github multiple times throughout the semester. The tasks were divided as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Chelsea Gorius
&lt;ul&gt;
&lt;li&gt;Exploratory Data Analysis&lt;/li&gt;
&lt;li&gt;Feature Engineering&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Gavin Hemmerlein
&lt;ul&gt;
&lt;li&gt;Organization of items&lt;/li&gt;
&lt;li&gt;Model Development&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Both
&lt;ul&gt;
&lt;li&gt;All outstanding items&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;8-references&#34;&gt;8. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;A. Mehra, &lt;em&gt;Sports Medicine Market worth $7.2 billion by 2025&lt;/em&gt;, Markets and Markets.
&lt;a href=&#34;https://www.marketsandmarkets.com/PressReleases/sports-medicine-devices.asp&#34;&gt;https://www.marketsandmarkets.com/PressReleases/sports-medicine-devices.asp&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;J. Harris, B. Erickson, B. Bach Jr, G. Abrams, G. Cvetanovich, B. Forsythe, F. McCormick, A. Gupta, B. Cole,
&lt;em&gt;Return-to-Sport and Performance After Anterior Cruciate Ligament Reconstruction in National Basketball Association Players&lt;/em&gt;, Sports Health. 2013 Nov;5(6):562-8. doi: 10.1177/1941738113495788. [Online serial]. Available: &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/24427434/&#34;&gt;https://pubmed.ncbi.nlm.nih.gov/24427434/&lt;/a&gt;  [Accessed Oct. 24, 2020]. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;W. Kraemer, C. Denegar, and S. Flanagan, &lt;em&gt;Recovery From Injury in Sport: Considerations in the Transition From Medical Care to Performance Care&lt;/em&gt;, Sports Health. 
2009 Sep; 1(5): 392â€“395.[Online serial]. Available: &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3445177/&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3445177/&lt;/a&gt;   [Accessed Oct. 24, 2020]. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;R. Hopkins, &lt;em&gt;NBA Injuries from 2010-2020&lt;/em&gt;, Kaggle. &lt;a href=&#34;https://www.kaggle.com/ghopkins/nba-injuries-2010-2018&#34;&gt;https://www.kaggle.com/ghopkins/nba-injuries-2010-2018&lt;/a&gt; &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;N. Lauga, &lt;em&gt;NBA games data&lt;/em&gt;, Kaggle.  &lt;a href=&#34;https://www.kaggle.com/nathanlauga/nba-games?select=games_details.csv&#34;&gt;https://www.kaggle.com/nathanlauga/nba-games?select=games_details.csv&lt;/a&gt; &lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;P. Rossotti, &lt;em&gt;NBA Enhanced Box Score and Standings (2012 - 2018)&lt;/em&gt;, Kaggle. &lt;a href=&#34;https://www.kaggle.com/pablote/nba-enhanced-stats&#34;&gt;https://www.kaggle.com/pablote/nba-enhanced-stats&lt;/a&gt; &lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-301/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-301/test/</guid>
      <description>
        
        
        &lt;h2 id=&#34;gavin-hemmerlein&#34;&gt;Gavin Hemmerlein&lt;/h2&gt;
&lt;h2 id=&#34;ghemmer&#34;&gt;ghemmer&lt;/h2&gt;
&lt;h2 id=&#34;engr-e-534&#34;&gt;ENGR-E 534&lt;/h2&gt;
&lt;p&gt;This is a test MarkDown file to ensure I have write privileges.&lt;/p&gt;
&lt;h1 id=&#34;test-typing&#34;&gt;Test Typing&lt;/h1&gt;
&lt;p&gt;This appears to be &lt;em&gt;working.&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;table&#34;&gt;Table&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Col1&lt;/th&gt;
&lt;th&gt;Col2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Row 1&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Row 2&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;22&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;images&#34;&gt;Images&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://assets.iu.edu/brand/3.2.x/trident-large.png&#34; alt=&#34;Image of IU Logo&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-304/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-304/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;using-big-data-to-eliminate-racial-bias-in-healthcare&#34;&gt;Using Big Data to Eliminate Racial Bias in Healthcare&lt;/h1&gt;
&lt;p&gt;Robert Neubauer, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-304/&#34;&gt;fa20-523-304&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-304/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Missing&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; Missing&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;Missing&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-304/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-304/test/</guid>
      <description>
        
        
        &lt;h1 id=&#34;header&#34;&gt;Header&lt;/h1&gt;
&lt;h2 id=&#34;sub-header-with&#34;&gt;Sub Header with&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bulleted&lt;/li&gt;
&lt;li&gt;lists&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sub-header-with-1&#34;&gt;Sub Header with&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Numbered&lt;/li&gt;
&lt;li&gt;Lists&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-305/homework3/cody_harris_hw3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-305/homework3/cody_harris_hw3/</guid>
      <description>
        
        
        &lt;h1 id=&#34;square-kilometer-array-ska-use-case&#34;&gt;Square Kilometer Array (SKA) Use Case&lt;/h1&gt;
&lt;p&gt;The SKA is an unprecedented, international, engineering endeavor to create the largest radio telescope in the world. Completion of this project requires the use of state-of-the-art technologies to facilitate the massive amount of data that will be captured [1]. Once this data is captured, it will require advanced high-performance computing centers to make sense of the data and gain valuable insight. While there are many innovative ideas involved with the SKA, this use case will only examine the technologies and processes involved with the solutions directly related to the SKAâ€™s big data needs.&lt;/p&gt;
&lt;h1 id=&#34;what-is-a-radio-telescope&#34;&gt;What is a radio telescope?&lt;/h1&gt;
&lt;p&gt;Before understanding the data needs of the SKA, it is important to understand what a radio telescope is. Many people are familiar with a regular telescope that uses a series of lenses to amplify light waves from distant places to create an image. A radio telescope is similar in the fact that it collects weak electromagnetic radiation from far distances, and then amplifies it so that it can be analyzed. Another application could be to send radio waves towards a direction and then record the reflection off celestial bodies. In any case, the signalâ€™s that astronomers are interested in are extremely weak. Many earthly sources of electro-magnetic radiation are many times greater in strength. There are multiple ways to combat this noise from earth-based radiation, and some of it could be done using hardware, or software, but there are also other ways to combat this that the SKA is utilizing.
Modern radio telescopes accept a wide range of radio frequencies, and then computationally split the frequencies into up to many thousands of channels. To further complicate things, while increasing the efficacy of the radio telescopes, generally more than one telescope is used. This allows multiple positions on the ground to receive the same radio signal, but at slightly different times and slightly different phases of the waveform. This variation allows for more complex analysis of the radio signal. Obviously, this adds another step in the computational work, but having a large array of radio telescopes is imperative to accomplish most modern astronomical research goals [2].&lt;/p&gt;
&lt;h1 id=&#34;science-goals&#34;&gt;Science Goals&lt;/h1&gt;
&lt;p&gt;The vast size of the SKA project allows the exploration of a variety of burning questions that not only intrigue astrophysicists, but nearly everyone on the planet. One overreaching design goal of the SKA is to have a design flexible enough that it can be used as a â€œdiscovery machineâ€ for the â€œexploration of the unknownâ€. With that said, there are five broad research goals of the SKA [3].&lt;/p&gt;
&lt;h2 id=&#34;galaxy-evolution-and-dark-energy&#34;&gt;Galaxy Evolution and Dark Energy&lt;/h2&gt;
&lt;p&gt;As a central goal of the SKA, this is quite a broad question that requires a great deal of study to fully understand. With the data gathered, researchers how to understand fundamental questions about how galaxies change over the course of their lifetimes. One problem with studying this, is that most galaxies nearest to us are so far along in their evolution that it is hard to know what happens in the early years of the galaxy. We can overcome this challenge with SKA, due to its â€œsensitivity and resolutionâ€. The SKA will be able to focus on younger galaxies that are much earlier in their evolution to study what our galaxy was like shortly after the big bang.
To gain an understanding of the creation and evolution of galaxies, a study of dark energy must be done. While this mysterious energy has made headlines in the past decade, it is still the subject of a lot of speculation. As gravity is a main driving factor in the evolution of cosmic objects, understanding dark energy is needed to gain a full picture of what is happening in galactical evolution. Currently our fundamental physical theories, derived by Einstein, suggest that universal expansion should be slowing, but it is not. This is where dark energy plays a part in the formation of our universe [4].&lt;/p&gt;
&lt;h2 id=&#34;was-einsteins-theory-of-relativity-correct&#34;&gt;Was Einsteinâ€™s theory of relativity, correct?&lt;/h2&gt;
&lt;p&gt;It is a tall order to question the most influential physicist in history. Technology is catching up with our theoretical understanding of physics so that we can test fundamental theories that we have held true for many years. The SKA hopes to use its incredible sensitivity to investigate gravitational waves from extremely powerful sources of gravity such as black holes. While Einsteinâ€™s theories are very likely to be mostly true, they might not be fully complete and that is what SKA hopes to find out [1].&lt;/p&gt;
&lt;h2 id=&#34;what-are-the-sources-of-large-magnetic-fields-in-space&#34;&gt;What are the sources of large magnetic fields in space?&lt;/h2&gt;
&lt;p&gt;We know that our earth creates a magnetic field that is imperative for life to exist. For the most part we understand that this is due to the composition and actions of the core of the planet. When it comes to the origin of magnetic fields in space, we are not completely sure what creates all the fields. The study of these magnetic fields will allow further study of the evolution of galaxies and our universe [5].&lt;/p&gt;
&lt;h2 id=&#34;what-are-the-origins-of-our-universe&#34;&gt;What are the origins of our universe?&lt;/h2&gt;
&lt;p&gt;This is a burning question that we have some theories about, but still have a great deal of exploration to do on the topic. The prevailing theory relies on the big bang, but the SKA hopes to further study the eras shortly after the big bang to gain insight into the origins of our universe. The SKA hopes to do this by once again using its sensitivity to give the most accurate measurements of the initial light sources in our universe [6]. As long this question remains unsolved, humans will always want to understand where we all came from.&lt;/p&gt;
&lt;h2 id=&#34;as-living-beings-are-we-alone-in-the-universe&#34;&gt;As living beings, are we alone in the universe?&lt;/h2&gt;
&lt;p&gt;Using Drakeâ€™s equation, and new exoplanet information, scientists are extremely optimistic that life exists somewhere in our universe. In some estimates, what has happened on our planet, could have happened about â€œ10 billion other times over in cosmic history!â€ [7].  One way that SKA can look for extraterrestrial life is by searching for radio signals sent out by advanced civilizations such as ours. Another way that SKA could look for extraterrestrial life is by looking for signs of the building blocks of life. One of these building blocks are amino acids, which can be identified by the SKA.&lt;/p&gt;
&lt;h1 id=&#34;current-progress&#34;&gt;Current Progress&lt;/h1&gt;
&lt;p&gt;The SKA telescopes reside in two separate locations. One location is in Western Australia and will be focused on low frequencies. The second location is in South Africa and will have two arrays, one for mid frequencies, and one for mid to high frequency [8].&lt;/p&gt;
&lt;h2 id=&#34;south-africa&#34;&gt;South Africa&lt;/h2&gt;
&lt;p&gt;Design and preparations for the final SKA implementation are still on-going. Currently there are two arrays named KAT7 and MeerKAT that are installed and functioning and will be the precursor to the SKA arrays in South Africa.&lt;/p&gt;
&lt;h2 id=&#34;australia&#34;&gt;Australia&lt;/h2&gt;
&lt;p&gt;This site also has a precursor to SKA already operating named ASKAP. It is currently located in the same location that the SKAâ€™s major components will eventually occupy, so this will give insights into the performance of this location for radio telescopes. Also, in Australia, as recent as in the past year, prototype antennas are being setup in smaller arrays to capture data and run tests before the design is used in the final array [10].&lt;/p&gt;
&lt;h1 id=&#34;big-data-challenges-and-solutions&#34;&gt;Big Data Challenges and Solutions&lt;/h1&gt;
&lt;p&gt;The SKA presents many big data challenges, from preprocessing to long-term storage of data. The estimated output of all the telescopes is around 700 PB per year [12].&lt;/p&gt;
&lt;h2 id=&#34;raw-data-and-preprocessing&#34;&gt;Raw Data and Preprocessing&lt;/h2&gt;
&lt;p&gt;The data comes in the form of an analog radio signals that are collected over a vast geographical area. At some point, to do analytics on the data, the data needs to be converted from analog to digital. While this is usually done via hardware, and is not on computational machines, this is still a data processing step that must be done at scale.
There is also some preprocessing of the data, that must happen constantly as data is collected. While this could be done once reaching the supercomputer, it is a repetitive task that could be done using FPGAs. The benefit of using a FGPA is that it can parallel process in many more threads and do repetitive algorithms faster and with less power as normal CPUs [12].&lt;/p&gt;
&lt;h2 id=&#34;storage-and-access&#34;&gt;Storage and Access&lt;/h2&gt;
&lt;p&gt;As mentioned previously, the estimated data output of the telescope at peak is 700 PB. The initiative also hopes to save all data for the lifetime of the project which is around 50 years. This ends up being in the realm of needing to eventually store 35 EB of data. For more immediate storage, the SKA team plans to use a buffer system. The way this works is by having a large array of fast read and write storage devices such as SSDs and NVMe (a specialized SSD). This buffer will immediately take in the data as it is coming in at rates that require write speeds that are not as prevalent with traditional spinning disks. After being written to this buffer, they will slowly move the data onto more affordable solutions, that have slower read/write speeds.
While the team could use SSDs for the entire storage, the cost would be enormous. It is much more cost effective to have most of the data stored on hard disk. When it comes to long-term storage of data, even cheaper sources of data such as tape drives could be utilized. After a certain time from data collection, the data will be opened up to the public, this means that the data will likely not end up in a cold storage system [12].&lt;/p&gt;
&lt;h2 id=&#34;processing-of-data&#34;&gt;Processing of data&lt;/h2&gt;
&lt;p&gt;Currently, the processing of data will be done at a large network of sites that will be made up of a variety of technologies. Mostly, no new high-performance computing centers will be created. Existing infrastructures, including public clouds will be used for the processing of data. Along with using FPGAs for pre-processing and possibly more processing afterwards, the SKA team plans to use GPU accelerators to allow for efficient processing.
Each team of researchers will have various goals that they will want from the data. This means that they will have a variety of processing needs, which will be carried out in SKA Regional Centers (SRCs). This might mean machine learning programs to get insights from the data, all the way to other mathematical operations to make the data ready for study. In any case, it is the expectation that this additional data is preserved as well, leading to even more data needing to be managed [12].&lt;/p&gt;
&lt;h2 id=&#34;other-challenges&#34;&gt;Other Challenges&lt;/h2&gt;
&lt;p&gt;While this data is not the most sensitive data on the planet, it is important that security is considered. The SKA team is planning on creating a sort of firewall between users and the actual HPC centers by using an AAAI (authorization, access, authentication, and identification) system. Security of proprietary data will be a concern that will have to be addressed. As there is a large team working on the project, as well as many external actors, security becomes extremely complex, especially the more access points there are to the data [12].
A project this large and versatile requires the use of many software tools. These software tools generally need some level or automatic communication if they are used together in a project. With a large number of tools, there becomes a complex IT infrastructure that needs to be managed, and constantly monitored. It is possible for one tool to receive a critical update, and then cause issues with integration of other software systems.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &amp;ldquo;Square Kilometre Array - ICRAR&amp;rdquo;, ICRAR, 2020. [Online]. Available: &lt;a href=&#34;https://www.icrar.org/our-research/ska/&#34;&gt;https://www.icrar.org/our-research/ska/&lt;/a&gt;. [Accessed: 23- Sep- 2020].&lt;br&gt;
[2] &amp;ldquo;What are Radio Telescopes? - National Radio Astronomy Observatory&amp;rdquo;, National Radio Astronomy Observatory, 2020. [Online]. Available:                                              &lt;a href=&#34;https://public.nrao.edu/telescopes/radio-telescopes/&#34;&gt;https://public.nrao.edu/telescopes/radio-telescopes/&lt;/a&gt;. [Accessed: 23- Sep- 2020].&lt;br&gt;
[3] &amp;ldquo;SKA Science - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available: &lt;a href=&#34;https://www.skatelescope.org/science/&#34;&gt;https://www.skatelescope.org/science/&lt;/a&gt;. [Accessed: 24-      Sep- 2020].&lt;br&gt;
[4] &amp;ldquo;Galaxy Evolution, Cosmology and Dark Energy - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available:      &lt;a href=&#34;https://www.skatelescope.org/galaxyevolution/&#34;&gt;https://www.skatelescope.org/galaxyevolution/&lt;/a&gt;. [Accessed:      24- Sep- 2020].&lt;br&gt;
[5] &amp;ldquo;Cosmic Magnetism - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available: &lt;a href=&#34;https://www.skatelescope.org/magnetism/&#34;&gt;https://www.skatelescope.org/magnetism/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[6] &amp;ldquo;Probing the Cosmic Dawn - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available: &lt;a href=&#34;https://www.skatelescope.org/cosmicdawn/&#34;&gt;https://www.skatelescope.org/cosmicdawn/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[7] L. Sierra, &amp;ldquo;Are we alone in the universe? Revisiting the Drake equation&amp;rdquo;, Exoplanet Exploration: Planets Beyond our Solar System, 2020. [Online]. Available: &lt;a href=&#34;https://exoplanets.nasa.gov/news/1350/are-we-alone-in-the-universe-revisiting-the-drake-equation/&#34;&gt;https://exoplanets.nasa.gov/news/1350/are-we-alone-in-the-universe-revisiting-the-drake-equation/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[8] &amp;ldquo;Design - ICRAR&amp;rdquo;, ICRAR, 2020. [Online]. Available: &lt;a href=&#34;https://www.icrar.org/our-research/ska/design/&#34;&gt;https://www.icrar.org/our-research/ska/design/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[9] &amp;ldquo;Africa - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available: &lt;a href=&#34;https://www.skatelescope.org/africa/&#34;&gt;https://www.skatelescope.org/africa/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[10] Square Kilometre Array, Building a giant telescope in the outback - part 2. 2020.&lt;br&gt;
[11] &amp;ldquo;Australia - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available: &lt;a href=&#34;https://www.skatelescope.org/australia/&#34;&gt;https://www.skatelescope.org/australia/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[12] Filled in Use Case Survey for SKA&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-305/homework6/cody_harris_hw6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-305/homework6/cody_harris_hw6/</guid>
      <description>
        
        
        &lt;h1 id=&#34;applying-computer-vision-to-medical-imaging&#34;&gt;Applying Computer Vision to Medical Imaging&lt;/h1&gt;
&lt;p&gt;Computer vision technology has made great strides in the past decade. The most obvious proof of this statement comes from looking at early consumer image classification programs. Early programs from the early 2010s struggled to find the difference between a cat and a person. Now, consumer image classification programs can accurately tell the difference between two cats. With these improvements, there are great applications for computer vision to aid with radiology.&lt;/p&gt;
&lt;h2 id=&#34;specific-application-areas&#34;&gt;Specific Application Areas&lt;/h2&gt;
&lt;p&gt;The five most common modalities of medical imaging are: X-Rays, CT scans, MRI, ultrasound, and PET scan [1]. Within these major modalities, there are various special types of each imaging technique such as an fMRI, which is called a functional MRI. Then there are the more niche imaging techniques that are used. For example, Diffusion Tensor Imaging (DTI) is a technique that allows visualization of the white matter in the brain. One application of this imaging technique is coming up with a way to diagnose certain mental illness from imaging [2]. Seeing as mental health issues are typically tougher to diagnose, this would be a major breakthrough.&lt;/p&gt;
&lt;p&gt;Oncology seems to be a major area of study for computer vision in medical imaging. Logically this makes sense as cancers seems to create anomalies that can be seen in medical imaging. Thoracic imaging focuses on looking at the lungs, and computer vision could aid with finding anomalies that could lead to the early detection of cancer which in turn creates a better prognosis. An application that is only based on analyzing normal images or video, is analyzing a colonoscopy. Certain structures in the colon can create colorectal cancer if not correctly identified and classified as benign or malignant. Another imaging technique that can be rather difficult to analyze correctly are mammograms, and correctly identifying the various anomalies that are present as either malignant or benign [3].&lt;/p&gt;
&lt;h2 id=&#34;how-computer-vision-can-be-used-in-medical-imaging&#34;&gt;How Computer Vision can be used in Medical Imaging&lt;/h2&gt;
&lt;p&gt;In a perfect world, a sufficiently advanced AI could be the only entity to ever examine a certain medical image before providing a prognosis. In reality our technology is far from achieving this lofty goal. In the meantime, AI can still be used to improve radiologist workflows. In some studies, it was found that a radiologist would have to look at one image every three to four seconds to stay caught up with their workload in an 8-hour day. It is obvious why this could cause issues with accuracy. Now think about having the same time to look at an image, but instead of a raw image, the image comes with suggestions of diagnosis, and points to specific areas for the radiologist to focus on. This would improve the effectiveness of radiologists without relying completely on the AI model to be 100% accurate [3].&lt;/p&gt;
&lt;h2 id=&#34;modeling-techniques&#34;&gt;Modeling Techniques&lt;/h2&gt;
&lt;p&gt;There are two main techniques that are currently being employed to work with computer vision and medical imaging. The first technique is extra certain features from the image based on qualifications that are input to the system. For example, the user of the system might put in to extract the texture and shape of anomalies in the lower left lobe of the lungs as one of the features. Once all of these features are collected, they are fed into an expert system that selects the most promising features that could help with diagnosis. These selected features are fed into a machine learning classifier system that then sends its insights along with the image to the radiologist [3]. This system has itâ€™s draw backs that are typical of expert systems. First off, setting the system up and giving it the parameters for the expert system is extremely complicated, and incorrect parameters in the system could heavily affect the output.&lt;/p&gt;
&lt;p&gt;The second technique employs deep learning. Over the years, deep learning has become a widely used method to gain insights from data, and computer vision is no exception. The deep learning models have the benefit of not requiring any setup or expert systems. Really the biggest challenge is getting a good enough training data such that the deep learning model accurately predicts in the same way that a radiologist would. Some studies have been done on testing the accuracy of such methods and they found that â€œdeep learning technologies are on par with radiologistsâ€™ performance for both detection and segmentation tasks in ultrasonography and MRI, respectivelyâ€ [3].&lt;/p&gt;
&lt;h2 id=&#34;special-considerations&#34;&gt;Special Considerations&lt;/h2&gt;
&lt;p&gt;While deep learning seems to be the best method to create these systems, experts still need to be involved with the creation of these systems. One example of this is having expert radiologists evaluate training data. Just because there might be 30 years worth of data, that doesnâ€™t mean it all can be used. The medical field is constantly evolving and making sure that the data you train your model is relevant is an important part of creating any model. Also using radiologists to shape the software that is used by radiologists would always improve the end product [4]. Too often software is built by software engineers and data scientists and doesnâ€™t use enough advice from experts in the field, and this almost always is a detriment to the software.&lt;/p&gt;
&lt;p&gt;Radiologists using these deep learning tools, will require a great deal of training with these tools. They know that the AI model is not always going to be correct, and it is important that the radiologists understand how the software works so that they can make a determination of whether their opinion should be trusted over the output from the software, especially early on with newer technology [4].&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &amp;ldquo;Different Imaging Tests Explained | UVA Radiology&amp;rdquo;, UVA Radiology and Medical Imaging Blog for Patients, 2019. [Online]. Available: &lt;a href=&#34;https://blog.radiology.virginia.edu/different-imaging-tests-explained/&#34;&gt;https://blog.radiology.virginia.edu/different-imaging-tests-explained/&lt;/a&gt;. [Accessed: 20- Oct- 2020].&lt;/p&gt;
&lt;p&gt;[2] &amp;ldquo;Diffusion Tensor Imaging (DTI) | Psychiatry Neuroimaging Laboratory&amp;rdquo;, Pnl.bwh.harvard.edu, 2020. [Online]. Available: &lt;a href=&#34;http://pnl.bwh.harvard.edu/portfolio-item/diffusion-tensor-imaging-dti/&#34;&gt;http://pnl.bwh.harvard.edu/portfolio-item/diffusion-tensor-imaging-dti/&lt;/a&gt;. [Accessed: 20- Oct- 2020].&lt;/p&gt;
&lt;p&gt;[3] A. Hosny, C. Parmar, J. Quackenbush, L. Schwartz and H. Aerts, &amp;ldquo;Artificial intelligence in radiology&amp;rdquo;, Nature Reviews Cancer, vol. 18, no. 8, pp. 500-510, 2018. Available: 10.1038/s41568-018-0016-5 [Accessed 20 October 2020].&lt;/p&gt;
&lt;p&gt;[4] &amp;ldquo;AI and the Future of Radiology&amp;rdquo;, Diagnostic Imaging, 2020. [Online]. Available: &lt;a href=&#34;https://www.diagnosticimaging.com/view/ai-and-future-radiology&#34;&gt;https://www.diagnosticimaging.com/view/ai-and-future-radiology&lt;/a&gt;. [Accessed: 20- Oct- 2020].&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-305/project/old_project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-305/project/old_project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;how-big-data-technologies-can-improve-indoor-agriculture&#34;&gt;How Big Data Technologies Can Improve Indoor Agriculture&lt;/h1&gt;
&lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt;
&lt;h1 id=&#34;harrcodyiuedu&#34;&gt;Cody Harris
&lt;a href=&#34;mailto:harrcody@iu.edu&#34;&gt;harrcody@iu.edu&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Cody Harris, &lt;a href=&#34;mailto:harrcody@iu.edu&#34;&gt;harrcody@iu.edu&lt;/a&gt;, fa20-523-305&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;TBD&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#team&#34;&gt;Team&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;

  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#topic-discussion&#34;&gt;Topic Discussion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#dataset&#34;&gt;Dataset&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#getting-a-good-grade&#34;&gt;Getting a Good Grade&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#data-storage-and-streaming&#34;&gt;Data Storage and Streaming&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#analytics&#34;&gt;Analytics&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#hardware&#34;&gt;Hardware&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#novel-ideas&#34;&gt;Novel Ideas&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#extensions&#34;&gt;Extensions&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; agriculture&lt;/p&gt;
&lt;h2 id=&#34;topic-discussion&#34;&gt;Topic Discussion&lt;/h2&gt;
&lt;p&gt;The overall topic of the project will include investigating how a host of Big Data technologies could be leveraged to improve multiple facets of the growing and distribution process for indoor farmers. One of the biggest benefits of growing indoors is the ability to precisely control the growing environment. From the light intensity and spectrum, to the nutrients given to the plant, there is an optimal combination of variables that produce the best results. Each farmer has priorities, whether those are yield, produce quality or a combination of various factors, it is a complex system that requires experimentation and robust tools to see the best results. There are a host of IoT sensors and controllers that can be employed to help monitor and control the growing environment, these all produce vast amounts of data that must be sifted through to extract insights. For sizeable farms, this produces big data problems that must be overcome.&lt;/p&gt;
&lt;p&gt;While some insights from the data can come during or directly after the growing â€œseasonâ€, some requires the produce to hit the shelves or to be used to create various food products. This means monitoring continues through the logistics process, and this data is integral when it comes to the end result of the produce. All this data allows for traceability in the food supply chain as well, in which big data technologies are perfect to handle.&lt;/p&gt;
&lt;p&gt;The end goal is to investigate and implement a scalable solution that follows the farmers crops from seed to consumers tables and optimizes the process along the way. Although indoor farms allow for great control, it is important to understand that there are many costs that are not associated with traditional farms. This means that to make the farming endeavor sustainable, optimization is important.&lt;/p&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;There are not any publicly available data sources that meet the needs of this project. In order to accomplish the goal of building an analytics platform for an indoor farm and the related logistics, simulation data will be created. The simulation data will encompass many different situations that could be encountered and labeled by these issues. Along with possible issues, the data will include mostly satisfactory situations, as this is what the farmer is most likely to encounter.&lt;/p&gt;
&lt;p&gt;The majority of the data being worked with will be streaming sensor data. The sensors will include: PAR (Photosynthetically Active Radiation), temperature, humidity, pH of grow medium, and CO2. Along with these streaming measurements, other data points about the specific grow area will be taken. A grow area could be as small as a row of ten plants, all the way to thousands of plants. These datapoints could be things such as phenotype, light spectrum, light cycle, feeding schedule, or any other labels that could be beneficial in determining the end attributes of the given produce.&lt;/p&gt;
&lt;p&gt;Variance in the data will come in a variety of forms. As completely identical data is not analogous to real life, it can be for certain measurements. For example, in an indoor growing environment equipped with HVAC, the temperature might only fluctuate a few percent all day, and then have a rapid change as the lights are turned off. With this in mind, certain simulation measurements should not have a great deal of noise in them unless trying to simulate an adverse event.&lt;/p&gt;
&lt;p&gt;As this data is streaming, the dataset will be a time series that needs to be handled in the sense of streaming as well as in a postmortem capacity. The size of the data should be large enough to properly simulate a large farm over the course of a grow cycle. This data set will simulate an experiment, in which a variety of conditions or phenotypes will be compared to a control. Within the realm of the experiment the simulation data might include adverse events, such as a power outage, that could actually occur during an experiment and these adverse events must be accounted for in the end conclusion.&lt;/p&gt;
&lt;h2 id=&#34;getting-a-good-grade&#34;&gt;Getting a Good Grade&lt;/h2&gt;
&lt;p&gt;As I am a graduate student, I am expected to not only write a report, but also create a software component. For the software, it will be a proof of concept to show that a scalable solution could be built to use open source big data technologies. The report will detail the work done in the solution being built, as well as exploring ideas that cannot be built but are required for the full solution to be implemented.&lt;/p&gt;
&lt;h3 id=&#34;data-storage-and-streaming&#34;&gt;Data Storage and Streaming&lt;/h3&gt;
&lt;p&gt;With a focus on open source platforms, Apache has solutions that can be leveraged to handle many aspects of big data streaming and storage in a distributed computing environment. While more investigation needs to be done on the exact software that will be used, Hadoop, Spark, or the combination of the two will be used to handle the large amount of data, whether that is for longer term storage or real time streaming. Another Apache system that will be evaluated is Kafka, but again, there are many possibly solutions to be used. The goal is to stay within the Apache environment as it is widely used in industry as well as is an open source platform.&lt;/p&gt;
&lt;h3 id=&#34;analytics&#34;&gt;Analytics&lt;/h3&gt;
&lt;p&gt;The analytics component of this project is diverse. While all goals might not be able to be achieved in the proof of work, all of the data needs that are required for the growing and logistics processes of an indoor farm will be evaluated and explained in the final report. There are two main components to the analytics: real time analytics and historic data analysis. While some models are being fine tuned for the specific farm, the real time analytics will likely be mostly monitoring at the beginning. As grow seasons go by and metrics are collected on the harvest, the real time analytics will be informed by the historic data using some sort of machine learning processes. These analytic goals can likely be completed using tools within Spark, using MLlib. If this cannot be accomplished, then another library will be used such as sci-kit learn.&lt;/p&gt;
&lt;h3 id=&#34;hardware&#34;&gt;Hardware&lt;/h3&gt;
&lt;p&gt;It is important that the proof of concept is designed for a distributed computing environment. The goal is to create open source software that can be used by small farms that sell solely at farmers markets, all the way to large commercial operations. When designing in this way, growing pains in the future can be minimized. For the hardware being used, multiple solutions are being evaluated. The first possible idea is using a commercial cloud application such as AWS, Azure, Google Cloud, etc. Secondly, personal local hardware could be used to create a virtual distributed computing environment. There are two options for local hardware. Either a personal computer with multiple virtual machines, or an array of Raspberry Piâ€™s will be used.&lt;/p&gt;
&lt;h3 id=&#34;novel-ideas&#34;&gt;Novel Ideas&lt;/h3&gt;
&lt;p&gt;Everything that has already been explained has more or less been attempted or implemented successfully. The innovation comes by trying to implement some ideas that are fresh by borrowing ideas and implementing them in the context of an indoor produce farm. The first big deviation from the norm is using a blockchain backbone to store immutable data. This idea is used in some niche farming scenarios but is yet to be adopted by produce farmers. Blockchain could be used to hold the logistical data to establish immutable custody data, but also to store the data from the growing process, pesticides tests, chemical makeup tests, genetic markers and more. Next, in the spirit of providing transparency there will be a public blockchain that could be explored by consumers or businesses that buy the farmers produce. In todayâ€™s world, we always wonder if we are paying some premium for products in order to just have a special label on that product. For this example, the label is: organic, GMO free, pesticide free, etc. Transparency goes a long way to prove to consumers that you are doing more for them to provide a good product, which allows for a greater amount that people are willing to spend. Some data might be proprietary, such as the exact genome of the phenotypes being used, or the specific growing protocols, so this information must stay off the blockchain.&lt;/p&gt;
&lt;h3 id=&#34;extensions&#34;&gt;Extensions&lt;/h3&gt;
&lt;p&gt;Not everything can be built or examined completely within the time constraints. Part of the project will be planning future updates or technologies that could improve the solution. One immediate future plan would be to incorporate cameras and computer vision to monitor the crops. Using images of plants, certain diseases, pests, or nutrient deficiencies can be seen as soon as they start to develop, giving the farmer the best odds at reversing the issue without effecting the harvest. Many of these issues cannot be greatly noticed with sensor data alone, which requires a farmer to constantly visually inspect crops. While this might not be terribly hard in some cases, some vertical grows might require large ladders to see all levels of the crop. This improvement could lead to less staff being required, which can allow more farmers to grow more for less money.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-305/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-305/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;estimating-soil-moisture-content-using-sensor-and-weather-data&#34;&gt;Estimating Soil Moisture Content Using Sensor and Weather Data&lt;/h1&gt;
&lt;p&gt;Cody Harris, &lt;a href=&#34;mailto:harrcody@iu.edu&#34;&gt;harrcody@iu.edu&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-305&#34;&gt;fa20-523-305&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-305/edit/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;As the world is gripped with finding solutions to problems such as food and water shortages, the study of agriculture could improve where we stand with both of these problems. By integrating weather and sensor data, a model could be created to estimate soil moisture based on on weather data. While some farmers could afford to have many moisture sensors and monitor them, many would not have the funds or resources to keep track of the soil moisture long term. A solution would be to allow farmers to contract out a limited study of their land using sensors and then this model would be able to predict soil moistures from weather data.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#topic-discussion&#34;&gt;Topic Discussion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#datasets&#34;&gt;Datasets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#data-cleaning-and-aggregation&#34;&gt;Data Cleaning and Aggregation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#pipeline-for-preprocessing&#34;&gt;Pipeline for Preprocessing&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#loading-and-joining-data&#34;&gt;Loading and Joining Data&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#feature-engineering&#34;&gt;Feature Engineering&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#generic-pipeline&#34;&gt;Generic Pipeline&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#multiple-models-for-multiple-soil-depths&#34;&gt;Multiple Models for Multiple Soil Depths&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#splitting-data-into-train-and-test&#34;&gt;Splitting Data into Train and Test&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#preliminary-analysis-and-eda&#34;&gt;Preliminary Analysis and EDA&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#initial-model-testing-regressor&#34;&gt;Initial Model Testing (Regressor)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#model-testing-classifier&#34;&gt;Model Testing (Classifier)&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#plan-for-the-rest-of-the-semseter&#34;&gt;Plan for the rest of the Semseter&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#november-9&#34;&gt;November 9&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#november-16&#34;&gt;November 16&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; agriculture, soil moisture, IoT&lt;/p&gt;
&lt;h2 id=&#34;topic-discussion&#34;&gt;Topic Discussion&lt;/h2&gt;
&lt;p&gt;Maintaining correct soil moisture throughout the plant growing process can result in better yeilds, and less overall problems with the crop. Water deficiencies or surplus at various stages of growth have different effects, or even negligable effects&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. It is important to have an idea of how your land consumes and stores water, which could be very different based on the plants being used, and variation of elevation and geography.&lt;/p&gt;
&lt;p&gt;For hundreds of years, farmers have done something similar to this model. The difference is the precision that we can gain by using real data. For the past few hundred years, farmers had to rely on mostly experience and touch to know the moisture of their soil. While many farmers were successful, in the sense that they produced crops, there were ways they could have better optimized their crops to produce better. The water avaliable to the plants is not the only variable that effects yeilds, but this project seeks to create an accessible model to which farmers can have predicted values of soil moisture without needing to buy and deploy expensive sensors.&lt;/p&gt;
&lt;p&gt;The model created could be used in various ways. The first main use is to be able to monitor what is currently happening in the soil so that changes can be made to correct the issue if there is one. Secondly, a farmer could evaluate historical data and compare it to yeilds or other results of the harvest and use this analytical information to inform future descions.&lt;/p&gt;
&lt;p&gt;This project specifically seeks to see the effect of weather on a particular piece of land in Washington state. This process could be done all over the world to obtain benchmarks. These benchmarks could be a cheap option for a farmer that does not have the funds to support a full study of water usage on their land. Instead, they could look for a model that has land that has similar soil and or geographical features, and then use their own weather data to estimate their soil moisture content.&lt;/p&gt;
&lt;h2 id=&#34;datasets&#34;&gt;Datasets&lt;/h2&gt;
&lt;p&gt;The first data set comes from NOAA and contains daily summary data in regards to various measurments such as temperature, percipitation, wind speed, etc. For this project, only data that came from the closest station to the field will be used &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. In this case, that is the Pullman station at the Pullman-Moscow airport. Below is an image showing the weather data collection location, and the red pin is at the longitude and lattitude of one of the sensors in the field. This data is in csv format (see Figure 1).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-305/master/project/images/distance_map.png&#34; alt=&#34;Figure 1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Estimated distance from weather reports to the crop fields. Distance is calculated using Google Maps&lt;/p&gt;
&lt;p&gt;The second dataset comes from the USDA. This dataset consits of &amp;ldquo;hourly and daily measurements of volumetric water content, soil temperature, and bulk electrical conductivity, collected at 42 monitoring locations and 5 depths (30, 60, 90, 120, and 150 cm)&amp;rdquo; at a farm in Washington state &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. Mainly, the daily temperature and water conent are the measurements of interest. There are multiple files that have data that corresponds to what plants are being grown in specific places, and the make up of the soil at each sensor cite. This auxilary information could be used in later models once the base model has been completed. This data is in tab delimited files.&lt;/p&gt;
&lt;p&gt;Within the data, there are GIS file types that can be imported into Google Maps desktop to visualize the locations of the sensors and other geographical information. Below is an example of the sensor locations plotted on the sattelite image (see Figure 2).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-305/master/project/images/sensor_locations.png&#34; alt=&#34;Figure 2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; Location of sensors within the test field&lt;/p&gt;
&lt;h2 id=&#34;data-cleaning-and-aggregation&#34;&gt;Data Cleaning and Aggregation&lt;/h2&gt;
&lt;p&gt;The first step is to get the soil moisture data into a combined format, currently it is in one file per sensor, and there are 42 sensors. See the data_cleaning_aggregation.ipynb file to see how this was done. After aggregation, some basic information can be checked about the data. For instance, there is quite a bit of NAs in the data. These NAs are just instances where there was no measurement on that day. There is about 45% NAs in the measurement columns. To further clean the data, any row that has only NAs for the measurements will be removed.&lt;/p&gt;
&lt;p&gt;Next, the weather data needs some small adjustments. This is mostly in the form of removing columns that either are empty or have redundant data such as elevation.&lt;/p&gt;
&lt;p&gt;Once the data is sufficiently clean, some choices have to be made on joining the data. The simplist route would be to join the weather measurements directly with the same day the soil measurement, however, the previous days weather is likely to also have an impact on the moisture. In the same fashion, the weather for the 5 previous days might all have a large impact on the moisture. So simply joining the two data sets right now is likely not the correct course of action until further analysis is made.&lt;/p&gt;
&lt;h2 id=&#34;pipeline-for-preprocessing&#34;&gt;Pipeline for Preprocessing&lt;/h2&gt;
&lt;p&gt;Before feeding the data through a machine learning algorithm, the data needs to be manipulated in such a way that it is ready to be directly fed into an algorithm. This includes joining the two data sets, feature engineering, and other tasks that prepare the data. This will need to be done every time a new dataset is being used, so this must be built in a repeatable way. The machine learning library scikit-learn incoroporates something called &amp;ldquo;pipelines&amp;rdquo; that can allow processed to be sequentially done to a dataframe. For purposes of this project two pipelines will be built, one will be used for feature engineering and joining the data, the other will be used to handle preparation of numerical, categorical, and date data.&lt;/p&gt;
&lt;h3 id=&#34;loading-and-joining-data&#34;&gt;Loading and Joining Data&lt;/h3&gt;
&lt;p&gt;This is the first step of the entire pipeline. This is where both the weather, and the soil moisture data are read in from csv files in their raw fromat. The soil moisture data is found in many different files, and these all need to be combined. After combining the fies, any lines that are full of NAs for the measurements are dropped. Next the weather data is loaded in. Both files have a date field which is the field they will be joined on. To make things consistent, both of these fields need to set be date format.&lt;/p&gt;
&lt;p&gt;When it comes to joining the data, each row should include the moisture content at various depths, as well as the weather information from the past ten days. While this creates a great deal of redundant data, the data is small enough that this is not an issue. Experiments will be done to evaluate just how many days of prior weather data are needed to form accurate results, while trying to minimize the number of the days.&lt;/p&gt;
&lt;h3 id=&#34;feature-engineering&#34;&gt;Feature Engineering&lt;/h3&gt;
&lt;p&gt;Currently only one feature is added, and this is a boolean flag that says whether it rained or not on a certain day. The thought behind this is, that for some days prior to the current measurement, the amount of rain might be needed, but for other days, such as 10 days prior, it might be more important to just know if there was rain or not. This feature is engineered within the pipeline.&lt;/p&gt;
&lt;p&gt;A future feature will be to use the months as categorical variables. While the date might be helpful, it probably is more accurate to consider the month then the specific day.&lt;/p&gt;
&lt;h3 id=&#34;generic-pipeline&#34;&gt;Generic Pipeline&lt;/h3&gt;
&lt;p&gt;After doing operations that are specific to the current dataset, some built in processors from sk-learn are used to make sure the data can be used in a machine learning model. This means that for numerical data types, the pipeline will fill in missing values with 0 instead of leaving them as NaN. There might be experiements to decide how to deal with missing measurements. Also the various numerical fields must be standardized, this is important for models such as linear regression so one large variable isn&amp;rsquo;t dominating the model.&lt;/p&gt;
&lt;p&gt;As far as text and categorical features, the imputer will be used to fill in missing data as well. Then a process called one hot encoding will be used to handle the categorical variables so that they can be read into sk-learns estimators.&lt;/p&gt;
&lt;p&gt;Lastly the date pipeline will take datetimes and convert them to integers that represent how many seconds it has been since 1970. This will allow dates to be handled as numerical values if they are used as an estimator instead of being used as a categorical feature as there would be many categories.&lt;/p&gt;
&lt;h2 id=&#34;multiple-models-for-multiple-soil-depths&#34;&gt;Multiple Models for Multiple Soil Depths&lt;/h2&gt;
&lt;p&gt;There are a few different approaches for modeling for this particular problem. The issue is that we have multiple things we would like to predict with the same predictors. It is unlikely that the model that predicts for a depth of 30 cm, would accurately predict for a depth of 150 cm. In order to adjust the models, a seperate model will be created for each depth, with that said, the predictors are all the same for each depth, but the trained output is different. To accomplish this, five different datasets were constructed, each one representing a depth. All rows in which the predicted value is not avaliable for that depth were pruned from the dataset.&lt;/p&gt;
&lt;h2 id=&#34;splitting-data-into-train-and-test&#34;&gt;Splitting Data into Train and Test&lt;/h2&gt;
&lt;p&gt;In order to test any model created, there must be a split between test and training data. This is done by using a function in sk-learn. In this case, there are about 76k rows in the data set. For the training data, 80% of the total data will be used, or about 60.8k records. The split is done after shuffling the rows so that it does not just pick the top 80% everytime. Lastly the data is split using a stratified method. As we want to have models that take the specific area of the field into account, that means that we need to have the different areas of the field represented equally in both the training and testing dataset. This means that if 10% of the data came from sensor CAF0003, then roughly 10% of the training data will come from CAF0003 as well as 10% of the test data will be from this location.&lt;/p&gt;
&lt;h2 id=&#34;preliminary-analysis-and-eda&#34;&gt;Preliminary Analysis and EDA&lt;/h2&gt;
&lt;p&gt;Before building a machine learning model, it is important to get a general idea of how the data looks, to see if any insights can be made right away.&lt;/p&gt;
&lt;p&gt;The first two visualizations are grids that show the entire distribution of measurements across each sensor. The first grid is the volume of water at 30 cm, and the second grid is the water volume at 150 cm. Each chart could be looked at and examined on it&amp;rsquo;s own, but what is most important to note is the variability of the measures from location to location. These different sensors are not that far away, but show that different areas of the farm do retain water in different ways.&lt;/p&gt;
&lt;p&gt;The third and fourth grid shows the temperature at 150 cm, the results are what would logically be expected. The different sensors do not show much variance from location to location.&lt;/p&gt;
&lt;p&gt;A simple bar chart is used to get a quick overview of the percipitation values over the same time period to see the overall trends. The most interesting part of this analysis is from the end of 2009 to nearly 2012. There is very little percipitation in this time period. Which initially looks like an issue with the data, but when it is compared to the water volume charts, a correlation can be seen. It isn&amp;rsquo;t perfect, but in many of the sensors that have data in this period, the moisture seems rather constant.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: After doing this analysis using the Altair library in python, the notebook became way too big due to the size of the data. As a quick remedy for this, I saved the visualizations as PNG and saved them in the images folder. They are named: one, two, three, and four, for the order that they are mentioned in the above section. I will remove the eda notebook from the repo.&lt;/p&gt;
&lt;h2 id=&#34;initial-model-testing-regressor&#34;&gt;Initial Model Testing (Regressor)&lt;/h2&gt;
&lt;p&gt;Once the pipelines were setup, the first model could be tested for accuracy. As the output data is continuous in nature, the easiest machine learning algoritm to test to make sure everything is correct, was a linear regression model. It seems fairly likely that a linear regression model would do rather well with this data. The weather is the driving factor in soil moisture in a non-irrigated field, so this test is a litmus test to make sure that the data is good and provide a baseline measurment for future models. The experiment log below shows the returned values from the test that was run. Over the course of experimentation, a log such as this will be kept.&lt;/p&gt;
&lt;p&gt;The results are as follows:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Experiment&lt;/th&gt;
&lt;th&gt;Depth&lt;/th&gt;
&lt;th&gt;Fit_Time&lt;/th&gt;
&lt;th&gt;Pred_Time&lt;/th&gt;
&lt;th&gt;r2_score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;First Linear Reg&lt;/td&gt;
&lt;td&gt;30cm&lt;/td&gt;
&lt;td&gt;58.701572&lt;/td&gt;
&lt;td&gt;0.238179&lt;/td&gt;
&lt;td&gt;0.890208&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;First Linear Reg&lt;/td&gt;
&lt;td&gt;60cm&lt;/td&gt;
&lt;td&gt;58.847758&lt;/td&gt;
&lt;td&gt;0.169551&lt;/td&gt;
&lt;td&gt;0.898520&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;First Linear Reg&lt;/td&gt;
&lt;td&gt;90cm&lt;/td&gt;
&lt;td&gt;54.927837&lt;/td&gt;
&lt;td&gt;0.172255&lt;/td&gt;
&lt;td&gt;0.882179&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;First Linear Reg&lt;/td&gt;
&lt;td&gt;120cm&lt;/td&gt;
&lt;td&gt;64.877650&lt;/td&gt;
&lt;td&gt;0.197685&lt;/td&gt;
&lt;td&gt;0.884033&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;First Linear Reg&lt;/td&gt;
&lt;td&gt;150cm&lt;/td&gt;
&lt;td&gt;63.256277&lt;/td&gt;
&lt;td&gt;0.170247&lt;/td&gt;
&lt;td&gt;0.876900&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;These results show that the data is pretty well correlated and that there is reason to believe that we could predict soil moisture from weather alone. Although an r^2 of around 0.87-0.89 are pretty good, with such highly related predictors, there is definitely room for model improvement.&lt;/p&gt;
&lt;h2 id=&#34;model-testing-classifier&#34;&gt;Model Testing (Classifier)&lt;/h2&gt;
&lt;p&gt;While the output is continuous, there is an argument to use a categorical classifier model. For a specific plant, an optimal moisture range could be studied. For example sake, the range could be 0.2-0.4 units. Then it would not matter if the soil is 0.2 or 0.3, both would be in the acceptable range. With this in mind, certain levels could be created to alert the farmer of which category they could be experienecing. For example there might be five levels: too dry, acceptable dryness, optimal, acceptable wetness, and too wet. The training data could be adjusted to fit into these categories.&lt;/p&gt;
&lt;p&gt;Further experimentation will be required to decide if this is truly the best route for the model. This idea seems promising as predicting the exact moisture content is not as important as understanding the toleraable ranges.&lt;/p&gt;
&lt;h2 id=&#34;plan-for-the-rest-of-the-semseter&#34;&gt;Plan for the rest of the Semseter&lt;/h2&gt;
&lt;p&gt;The following is a plan for the rest of the semester, using the due dates for Assignments 8-11 as milestone dates&lt;/p&gt;
&lt;h3 id=&#34;november-9&#34;&gt;November 9&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Tune Hyper-parameters&lt;/li&gt;
&lt;li&gt;Test various models&lt;/li&gt;
&lt;li&gt;Further tune and tweak models&lt;/li&gt;
&lt;li&gt;Start analyzing various models and techniques to find the most accurate model&lt;/li&gt;
&lt;li&gt;Update report&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;november-16&#34;&gt;November 16&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Build a library/program that can pull weather data from NOAA and takes sensor input and outputs predictions of soil moisture by area&lt;/li&gt;
&lt;li&gt;Finalize report and findings&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;O. Denmead and R. Shaw, &amp;ldquo;The Effects of Soil Moisture Stress at Different Stages of Growth on the Development and Yield of Corn 1&amp;rdquo;, Agronomy Journal, vol. 52, no. 5, pp. 272-274, 1960. Available: 10.2134/agronj1960.00021962005200050010x. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;N. (NCEI), &amp;ldquo;Climate Data Online (CDO) - The National Climatic Data Center&amp;rsquo;s (NCDC) Climate Data Online (CDO) provides free access to NCDC&amp;rsquo;s archive of historical weather and climate data in addition to station history information. | National Climatic Data Center (NCDC)&amp;rdquo;, Ncdc.noaa.gov, 2020. [Online]. Available: &lt;a href=&#34;https://www.ncdc.noaa.gov/cdo-web/&#34;&gt;https://www.ncdc.noaa.gov/cdo-web/&lt;/a&gt;. [Accessed: 19- Oct- 2020]. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&amp;ldquo;Data from: A field-scale sensor network data set for monitoring and modeling the spatial and temporal variation of soil moisture in a dryland agricultural field&amp;rdquo;, USDA: Ag Data Commons, 2020. [Online]. Available: &lt;a href=&#34;https://data.nal.usda.gov/dataset/data-field-scale-sensor-network-data-set-monitoring-and-modeling-spatial-and-temporal-variation-soil-moisture-dryland-agricultural-field&#34;&gt;https://data.nal.usda.gov/dataset/data-field-scale-sensor-network-data-set-monitoring-and-modeling-spatial-and-temporal-variation-soil-moisture-dryland-agricultural-field&lt;/a&gt;. [Accessed: 19- Oct- 2020]. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-305/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-305/test/</guid>
      <description>
        
        
        &lt;p&gt;Testing if I have write access to this repo.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-307/assignment6/assignment6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-307/assignment6/assignment6/</guid>
      <description>
        
        
        &lt;h1 id=&#34;ai-in-precision-medicine&#34;&gt;AI in Precision Medicine&lt;/h1&gt;
&lt;p&gt;In recent years, precision medicine has started to become the new standard when it comes to healthcare. This is moving us from a one size fits all approach to a more personal, data-driven approach that allows hospitals and treatment centers to spend more efficiently and have a higher patient outcome. Precision medicine is using knowledge that is specific to one patient, such as biomarkers, rather than the generic approach to an issue. The overall goal is to &amp;quot;design and optimize the pathway for diagnosis and prognosis through the use of large multidimensional biological datasets that capture different variables such as genes&amp;quot; [1].&lt;/p&gt;
&lt;p&gt;Artificial intelligence (AI) has been increasingly growing in business, society and now is emerging in healthcare. The potential that AI has can completely transform patient care. These technologies can perform to or exceed human capability when it comes to different medical tasks such as cancer diagnosis or disease diagnosis as well as patient engagement and administration tasks. AI has the potential to offer automated care to individuals by providing precision medicine.&lt;/p&gt;
&lt;p&gt;Precision medicine enables patients to not only recover from illnesses faster but to also stay healthy longer. However, with the increased use of precision medicine new challenges arise such as the increasing amount of data, a lack of specialists and ever increasing drug development costs. &amp;quot;Healthcare data is projected to grow by 43 percent by 2020, to roughly 2.3 zettabytes. The size of the data is not the only problem; it&#39;s the kind of data as well. Eighty percent of it is unstructured and mostly unlabeled, making it hard to extract value from the datasets&amp;quot; [2].&lt;/p&gt;
&lt;p&gt;Artificial intelligence (AI) has helped reshape how precision medicine is distributed. AI is able to solve many of the problems that have arisen. For big data challenges, AI methods are able to clear up obstacles that large and unstructured data present. In medical imaging, machine learning can be introduced to help classify what type of issue is present by training a model over thousands of images and predicting on the patient&#39;s image. Neural networks have also been able to make predictions when it comes to precision medicine.&lt;/p&gt;
&lt;p&gt;Neural networks are a more advanced form of AI. The uses in precision medicine is for categorisation applications such as the likelihood of a patient developing a disease. Neural networks look at problems from inputs, outputs, and weights of features to try and associate inputs with the corresponding outputs. &amp;quot;It has been likened to the way that neurons process signals, but the analogy to the brain&#39;s function is relatively weak&amp;quot; [3].&lt;/p&gt;
&lt;p&gt;Deep learning is one of the most complex forms of AI. This involves hundreds or thousands of models with numerous levels of features that are needed to predict the outcomes. Precision medicine takes advantage of this technology through the &amp;quot;recognition of potentially cancerous lesions in radiology images&amp;quot; [4]. Deep learning is able to be applied to fields such as radiomics. This is the practice of detecting features in image data that cannot be detected with the human eye. &amp;quot;Their combination appears to promise greater accuracy in diagnosis than the previous generation of automated tools for image analysis, known as computer-aided detection or CAD&amp;quot; [4].&lt;/p&gt;
&lt;p&gt;AI plays a pivotal role in the future of healthcare. In the development of precision medicine, it is one of the primary components in order to advance care for patients. Efforts to help classify medical imagery more quickly and accurately have proven more effective with the amount of data used to train such models. A big challenge that AI is facing in precision medicine is whether or not this technology will be widely adopted. These systems will need to have some regulations in order to have a universal standard. This will allow doctors and medical personnel to train with this technology so they will be able to provide the care their patients deserve. AI will never replace the human aspect of precision medicine but over time AI will be able to make the jobs and lives of the doctors and patients better and healthier.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] M. Uddin, Y. Wang, and M. Woodbury-Smith, &amp;quot;Artificial intelligence for precision medicine in neurodevelopmental disorders,&amp;quot; &lt;em&gt;Nature News&lt;/em&gt;, 21-Nov-2019. [Online]. Available: &lt;a href=&#34;https://www.nature.com/articles/s41746-019-0191-0&#34;&gt;https://www.nature.com/articles/s41746-019-0191-0&lt;/a&gt;. [Accessed: 11-Oct-2020].&lt;/p&gt;
&lt;p&gt;[2] H. Chamraj, &amp;quot;Powering Precision Medicine with Artificial Intelligence,&amp;quot; &lt;em&gt;Intel&lt;/em&gt;. [Online]. Available: &lt;a href=&#34;https://www.intel.com/content/www/us/en/artificial-intelligence/posts/powering-precision-medicine-artificial-intelligence.html&#34;&gt;https://www.intel.com/content/www/us/en/artificial-intelligence/posts/powering-precision-medicine-artificial-intelligence.html&lt;/a&gt;. [Accessed: 12-Oct-2020].&lt;/p&gt;
&lt;p&gt;[3] T. Davenport and R. Kalakota, &amp;quot;The potential for artificial intelligence in healthcare,&amp;quot; &lt;em&gt;Future healthcare journal&lt;/em&gt;, Jun-2019. [Online]. Available: &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6616181/&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6616181/&lt;/a&gt;. [Accessed: 12-Oct-2020].&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-307/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-307/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;analysis-of-financial-markets-based-on-president-trumps-tweets&#34;&gt;Analysis of Financial Markets based on President Trump&amp;rsquo;s Tweets&lt;/h1&gt;
&lt;p&gt;Alex Baker, fa20-523-307, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-307/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;In behavioral economics, it is said that emotions have an effect on individual&amp;rsquo;s behavior and their choice in their decision making process. This can be true for a society at large but can this apply to the leader of the free world? Here we will investigate the collective mood of President Trump&amp;rsquo;s tweets are correlated to the value of the Nasdaq Stock Market (NASDAQ). The applications of sentiment analysis and machine learning methods will help find the correlation that we are looking for. President Trump&amp;rsquo;s tweets will be used to predict the mood and the NASDAQ movements.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-datasets&#34;&gt;2. DataSets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#data-cleaning-and-preprocessing&#34;&gt;Data Cleaning and Preprocessing&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#twitter-data&#34;&gt;Twitter Data&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#stock-data&#34;&gt;Stock Data&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-methodologyprocess&#34;&gt;3. Methodology/Process&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#preliminary-analysis-and-eda&#34;&gt;Preliminary Analysis and EDA&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#twitter-data-1&#34;&gt;Twitter Data&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#stock-data-1&#34;&gt;Stock Data&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#outline-of-plan&#34;&gt;Outline of plan&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-technologies-used&#34;&gt;4. Technologies used&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-references&#34;&gt;5. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; analysis, finance, stock markets prediction, twitter, politics&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;Financial markets have been an area of research in both academia and business. Predictions of the market has been growing in its accuracy with an every increasing amount of data used to test these models. &amp;ldquo;The Efficient Market Hypothesis (EMH) states that stock market prices are largely driven by &lt;em&gt;new&lt;/em&gt; information and follow a random walk pattern&amp;rdquo;[1]. This shows that prices will follow news rather than previous and present prices. Information is unpredictable in terms of its release/publication showing market prices will follow a random walk pattern and the prediction can not be high.&lt;/p&gt;
&lt;p&gt;There are some problems that arise with EMH. One problem is that &amp;ldquo;stock prices does not follow a random walk pattern and can be predicted to a certain degree&amp;rdquo;[2]. Another problem associated with EMH is with the information&amp;rsquo;s unpredictability, the unpredictability is called into question with the introduction of social media (Facebook, Twitter, blogs). The rise of social media can be a early indicator for news before it is released/published. This project is attempting to predict the market based on how the President tweets. This currently has not been done according to my research.&lt;/p&gt;
&lt;h2 id=&#34;2-datasets&#34;&gt;2. DataSets&lt;/h2&gt;
&lt;p&gt;In this project, two datasets will be used -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The NASDAQ values from November 2016 to January 2020. This data was obtained through Yahoo! Finance and includes Date, Open, High, Low, Close, Adj Close, and Volume for a given day.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;President Trump&amp;rsquo;s tweets during the periods of November 2016 to January 2020 is over 41,000 tweets. The data includes id, link, content, date, retweets, favorites, mentions, hashtags, and geo for every tweet in the time frame. Since the performance of the prediction is on a daily basis, tweets will be split up by Date. This data is available on Kaggle (&lt;a href=&#34;https://www.kaggle.com/austinreese/trump-tweets?select=trumptweets.csv)&#34;&gt;https://www.kaggle.com/austinreese/trump-tweets?select=trumptweets.csv)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To strengthen the prediction, even more, some code from the 2016 electionâ€™s analysis of markets may be utilized but the focus will be on the markets during the Trump administration. Rally data maybe introduced in order to have a deeper sense of some of the tweets when it comes to important news that is announces at President Trump&amp;rsquo;s rallies. In order to have a realistic and strong prediction, the financial data needs to be aligned with the timing of tweets but news that has already started to affect the markets before a tweet has been sent out needs to be taken into account.&lt;/p&gt;
&lt;h2 id=&#34;data-cleaning-and-preprocessing&#34;&gt;Data Cleaning and Preprocessing&lt;/h2&gt;
&lt;p&gt;The data obtained needs to be cleaned and pre-processed in order to make it reliable for analysis.&lt;/p&gt;
&lt;h3 id=&#34;twitter-data&#34;&gt;Twitter Data&lt;/h3&gt;
&lt;p&gt;When importing the Twitter data, there are several things that are noticed when printing the first five rows. Three of the columns mention, hashtags, and geo are currently showing NaN. After calculating the missing values, all the values in these columns are missing or are zero so we can drop these columns from the dataframe.&lt;/p&gt;
&lt;p&gt;The tweets are one of the last columns needed to be cleaned. The text of the tweets needs to be uniformed in order to conduct analysis. Removing punctuations was the first step followed by removing content specifically seen in tweets. These could be the word retweet, the hashtag symbol(#), the @ symbol followed by a username, and any hyperlinks that could be in a tweet.&lt;/p&gt;
&lt;h3 id=&#34;stock-data&#34;&gt;Stock Data&lt;/h3&gt;
&lt;p&gt;Stock data has a unique set of challenges when it comes to cleaning. Unlike tweets, stock data is only available Monday through Friday and is not available for holidays that the market is closed. In order to have a complete dataset, several options are available. One option is to drop the tweets that fall on a weekend. This would not be useful since markets can react to news that happens on the weekend. Another option is to approximate the missing values in the stock data. This has not been conducted yet.&lt;/p&gt;
&lt;h2 id=&#34;3-methodologyprocess&#34;&gt;3. Methodology/Process&lt;/h2&gt;
&lt;p&gt;The collection of finance and Twitter data will be used to visualize and predict the results. Some of Twitter or dataset data will need to be cleaned and classified to build the model. The methodology is composed of the following steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use data from President Trump&amp;rsquo;s personal twitter to help visualize and create the model&lt;/li&gt;
&lt;li&gt;Use data from Yahoo finance API to help visualize and create the model&lt;/li&gt;
&lt;li&gt;Data cleaning and extraction.&lt;/li&gt;
&lt;li&gt;New data will be updated to keep up with the current time.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;preliminary-analysis-and-eda&#34;&gt;Preliminary Analysis and EDA&lt;/h2&gt;
&lt;h3 id=&#34;twitter-data-1&#34;&gt;Twitter Data&lt;/h3&gt;
&lt;p&gt;When starting to conduct preliminary analysis and exploratory data analysis (EDA), it is helpful to first check for any null values in the data and there are no null values in the twitter data.&lt;/p&gt;
&lt;p&gt;The date column is a column that is needed to track the amount of tweets per month and year. In the column, the timestamp and the date are combined so this need to be separated in several ways. The first being separating the date from the timestamp into its own column. This is followed up by separating the date into 4 columns for day, month, year and month-year in order to track tweets based on specified criteria.&lt;/p&gt;
&lt;p&gt;After graphing the amount of tweets per year, the observation is that 2016 and 2020 have a low tweet count. The reminder is that the data starts in November 2016 making 2016 have two months of data compared to 2020 with only one month being January. From 2017 through 2019, we can see that the amount of tweets increases by almost a thousand every year. The tweets per month tell a different story. The amount varies greatly over the years with the greatest amount being near the end of 2016 and the beginning of 2017.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-307/master/project/images/year_tweets.png&#34; alt=&#34;Figure 1: Caption missing&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Caption missing&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-307/master/project/images/month_tweets.png&#34; alt=&#34;Figure 2: Caption missing&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; Caption missing&lt;/p&gt;
&lt;h3 id=&#34;stock-data-1&#34;&gt;Stock Data&lt;/h3&gt;
&lt;p&gt;Similar to the twitter data, checking for null values is important but since the data is from Yahoo! Finance there are no missing values on the days that the markets are opened.&lt;/p&gt;
&lt;p&gt;Once graphing the open and closed prices of the NASDAQ, there seems to be an general upwards trend in the market over the time period.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-307/master/project/images/market.png&#34; alt=&#34;Figure 3 Caption missing&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; Caption missing&lt;/p&gt;
&lt;h2 id=&#34;outline-of-plan&#34;&gt;Outline of plan&lt;/h2&gt;
&lt;p&gt;In the next seven weeks, these are the tasks that need to be accomplished.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Week 9 - Week 10: Clean and preprocess the data needed for the project&lt;/li&gt;
&lt;li&gt;Week 10 - Week 11: Research what methods that should be used&lt;/li&gt;
&lt;li&gt;Week 11 - Week 13: Preform sentiment analysis to find features and see if any correlation exists&lt;/li&gt;
&lt;li&gt;Week 13 - Week 16: Build out NLP model&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4-technologies-used&#34;&gt;4. Technologies used&lt;/h2&gt;
&lt;p&gt;Python, Jupyter notebook or collab, Pandas, Scikit-learn, Tensorflow/PyTorch&lt;/p&gt;
&lt;h2 id=&#34;5-references&#34;&gt;5. References&lt;/h2&gt;
&lt;p&gt;[1] Goel, A. and Mittal, A., 2011. Stock Prediction Using Twitter Sentiment Analysis. [online] cs229.stanford.edu. Available at: &lt;a href=&#34;http://cs229.stanford.edu/proj2011/GoelMittal-StockMarketPredictionUsingTwitterSentimentAnalysis.pdf&#34;&gt;http://cs229.stanford.edu/proj2011/GoelMittal-StockMarketPredictionUsingTwitterSentimentAnalysis.pdf&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;[2] J. Bollen, H. Mao, and X. Zeng, â€œTwitter mood predicts the stock market,â€ Journal of Computational Science, vol. 2, no. 1, pp. 1â€“8, 2011.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-308/hw7/task_3_next_steps/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-308/hw7/task_3_next_steps/</guid>
      <description>
        
        
        &lt;h1 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h1&gt;
&lt;p&gt;I am still not 100% that this is the project I want to complete. As the instructions for HW 5 laid out, we do not have to fully commit at this point to the project. I may try to work on a basic deep learning project that can introduce me to that type of work. Next steps for the project I have started here would be to complete the basic descriptive data modeling in charts. Then would be to model the data and pull in the playoff teams from 2009-2019 to compare the model output with the playoff team that qualified for the playoffs. I want to work on this over the next month before moving onto the writing portion of the project.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-308/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-308/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;nfl-regular-season-skilled-position-player-performance-as-a-predictor-of-playoff-appearance&#34;&gt;NFL Regular Season Skilled Position Player Performance as a Predictor of Playoff Appearance&lt;/h1&gt;
&lt;p&gt;Travis Whitaker, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-308&#34;&gt;fa20-523-308&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-308/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-choice-of-data-sets&#34;&gt;3. Choice of Data-sets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-methodology&#34;&gt;4. Methodology&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-inference&#34;&gt;5. Inference&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-conclusion&#34;&gt;6. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#project-plan&#34;&gt;Project Plan&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#8-references&#34;&gt;8. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords&lt;/strong&gt;:&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;In the modern NFL the biggest negotiating tools for players in signing a new contract is their on-field performance. Many players choose to &amp;ldquo;hold-out&amp;rdquo; of pre-season practice or regular season games as a negotiating tool in their attempt to sign a more lucrative contract. Players often feel as though their exceptional performance on the field is not reflected in the monetary compensation structure of their contract. This is most often reflected in skill position players such as wide receivers or running backs whose play on the field is most often celebrated (e.g., touchdowns) and discussed by fans of the game. While these positions are no doubt important to a teamâ€™s success, the question remains how important is one players contribution to a teamâ€™s overall success? Our project will attempt to evaluate the importance of the individual skill position players&amp;rsquo; (i.e., Quarterback (QB), Wide Receiver (WR), Running Back (RB), and Tight End (TE)) performance during the regular season and use in-game performance metrics as a predictive factor for their team making the playoffs. This is an attempt to answer the question does individual playerâ€™s performance lead to a team qualifying for post-season play?&lt;/p&gt;
&lt;p&gt;There are many playoff predictor models that focus on team performance or team wins vs losses as a predictor of making the playoffs &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. However, few take into consideration individual player performance as an indicator of their team making the post-season playoffs in the NFL. The most famous model that takes into consideration player performance is ELO rating &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. The first ELO rating was a straightforward model that took head-to-head results and player-vs-team model in order to predict win probability in an NFL game. However, in 2019 Silver and his team at FiveThirtyEight updated their ELO model to give a value rating to the quarterback position for each team. This quarterback value included metrics such as pass attempts, completions, passing yards, passing touchdowns, interceptions, sacks, rush attempts, rushing yards, and rushing touchdowns. Taking these metrics along with the defensive quality metrics, which is an adjustment of quarterback value based on the opposing defense ranking, gives you an overall value for your quarterback. Thus, this widely accepted model takes head-to-head team comparisons on a week-to-week basis and includes the quarterback value in predicting these head-to-head matchup. However, no model has taken just player performance and tried to predict team success based on each of their individual players. These previous models primarily look at offensive vs. defensive units and try to predict win/loss records based off each of these units.&lt;/p&gt;
&lt;p&gt;The goal of the present research is not to compare our model vs previous models, as these standing models are not meant for playoff prediction, rather a game-by-game matchup comparison. The present research investigates whether looking at top 12 position players at each of the skilled positions maps onto predicting the playoff teams. The reason top 12 players at each position were chosen is because only 12 teams make the post-season each year in the NFL. We will look at player performance between 2009-2019 in order to predict post-season qualification and then compare the playoff predicted players (i.e., top 12 players at their position) with the actual playoff teams that qualified for the playoffs each year between 2009- 2019.&lt;/p&gt;
&lt;h2 id=&#34;2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/h2&gt;
&lt;h2 id=&#34;3-choice-of-data-sets&#34;&gt;3. Choice of Data-sets&lt;/h2&gt;
&lt;p&gt;The dataset we will be using is in a github folder that holds nflscrapR-data that originates from NFL.com &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. The folder includes play-by-play data, including performance measures, for all regular season games from 2009 to 2019. This file will be paired with week-by-week regular season roster data for each team in the NFL. This will allow me to track skilled position player performance during the regular season and then compare this regular season file with the files that contain playoff teams for each year from 2009-2019. Supplemental data may be pulled from Pro-Football-Reference.com or other sources depending on what preliminary data analysis presents &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;4-methodology&#34;&gt;4. Methodology&lt;/h2&gt;
&lt;p&gt;The first step we am planning to take in understanding the data will be to use various slices of the data put into scatterplots and bar charts to find correlations and trends, as well as various time series charts. This will be an exploratory step in understanding the data. we may also deploy area charts to observe any interesting trends or segments of our data that may warrant additional analysis.&lt;/p&gt;
&lt;p&gt;Then each metric from player performance during the regular season will be included in the analysis or algorithm that will be built to predict playoff appearance. Playoff appearance is a designation for a team qualifying for the post-season or playoffs. We am thinking it may be important to engineer some new features to potentially provide insights.  For instance, it is possible to determine whether a play was during the final two minutes of a half and if a play was in the red zone. During these critical points of a game a win or lose is often determined. So my thought is by weighing these moments and performance metrics with more importance in an algorithm the machine will better predict a teamâ€™s likelihood of making the playoffs. Another secondary metric that may strengthen the predictive ability of the algorithm would be to use Football Outsiderâ€™s Success Rate, which is a determination of a playâ€™s success rate for the offense that is on the field &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. This can also provide me with the down and distance to go for the offense and players that are on the field. We will also use college position designations as way to normalize the positions performance across teams. Many NFL teams utilize different player sets. Thus, it is important to use a standard, which college football uses across all teams. Since we am only interested in skill position players this will include Wide Receiver (WR), Running Back (RB), Full Back (FB), Quarterback (QB), and Tight End (TE). These designations will allow the algorithm to compare, if needed, the skill position performance across teams and by designation of players on that team for each metric utilized.&lt;/p&gt;
&lt;p&gt;After breaking down the data into key categorical variables to see if there was an impact for these performance variables in making the playoffs for the NFL teams. These individual position statistics will need to be paired with their teammateâ€™s performance metrics so that each team is represented by all of their skill position players. It is often debated as to which position is most important in football and whether a QB is critical to a successful post-season appearance. My hope is that by combining each skill position player onto their respective team we will be able to better determine the importance of success at each position by whether or not that team made the playoffs. Further, it will be important to see whether roster makeup across teams varies by position. If roster makeup is stable than we will not need to combining positions. However, if roster makeup varies, we will need to combine positions into a larger group instead of two subgroups. The concern here is the deployment of WR over TE. Some teams may carry more TE than others and fewer WR. Therefor we would need to combine WR and TE into a group called Designated Receiver (DR).&lt;/p&gt;
&lt;p&gt;Metric measurement needs to be consistent across years. A comparison of year-to-year metrics will need to be done comparing each years measurements from 2009-2019 in order to make sure that the measurement techniques are stable and do not vary across time. If there are changes in the way metrics are measured than either that year will need to be dropped from the model or adjustments will need to be made to the metric to balance it with the other years included in the model.&lt;/p&gt;
&lt;p&gt;Finally, once all metrics have been balanced and the team performance metrics have been aggregated. The algorithm will need to be implemented to identify the eight best teams from each NFL division and the two best other teams in the conference that would constitute the wild card playoff teams from each conference. Once this analysis is run, we will be able to look at retroactive NFL post-season designated teams from 2009-2019 to see how accurate the playoff prediction machine was at identifying NFL post-season teams for each year.&lt;/p&gt;
&lt;h2 id=&#34;5-inference&#34;&gt;5. Inference&lt;/h2&gt;
&lt;p&gt;An individual player-performance model for NFL skill position players (i.e., quarterback, wide receiver, tight end, and running back) will perform better than chance level (50%) of identifying playoff teams from the NFL during the season&amp;rsquo;s of 2009-2019.&lt;/p&gt;
&lt;h2 id=&#34;6-conclusion&#34;&gt;6. Conclusion&lt;/h2&gt;
&lt;p&gt;This section will be addressed upon project completion.&lt;/p&gt;
&lt;h2 id=&#34;7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/h2&gt;
&lt;h2 id=&#34;project-plan&#34;&gt;Project Plan&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; will be deleted in final submission&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; can not be after Refernce section&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nov. 02, 2020
-Complete a draft of the introduction section and the inferences section&lt;/p&gt;
&lt;p&gt;Nov. 09, 2020&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;build a functioning read in for all csv files needed using curl or another python function. Complete descriptive statistic analysis on regular season variables. (Model should look at player performance and whether that player made the nfl postseason the year of their recorded performance metrics).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nov. 16, 2020
-complete background and previous work section. Work on building prediction model for players making the postseason, train the machine to predict based on variables.&lt;/p&gt;
&lt;p&gt;Nov. 23, 2020&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Finish model to see how accurate the machine or model is at predicting players making the post-season. Write a conclusion section to based on model.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Dec. 1, 2020&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Polish paper, write abstract and table of contents sections.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Dec. 8, 2020&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make any changes requested by TA&amp;rsquo;s&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;8-references&#34;&gt;8. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Zita, C. (2020, September 16). Improving a Famous NFL Prediction Model. Retrieved November 02, 2020, from &lt;a href=&#34;https://towardsdatascience.com/improving-a-famous-nfl-prediction-model-1295a7022859&#34;&gt;https://towardsdatascience.com/improving-a-famous-nfl-prediction-model-1295a7022859&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Silver, N. (2018, September 05). How Our NFL Predictions Work. Retrieved November 02, 2020, from &lt;a href=&#34;https://fivethirtyeight.com/methodology/how-our-nfl-predictions-work/&#34;&gt;https://fivethirtyeight.com/methodology/how-our-nfl-predictions-work/&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Ryurko. Ryurko/NflscrapR-Data. 2 Mar. 2020, &lt;a href=&#34;https://github.com/ryurko/nflscrapR-data&#34;&gt;https://github.com/ryurko/nflscrapR-data&lt;/a&gt;. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Sports Reference, LLC. â€œPro Football Statistics and History.â€  Retrieved October 09, 2020. &lt;a href=&#34;https://www.pro-football-reference.com/&#34;&gt;https://www.pro-football-reference.com/&lt;/a&gt; &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-309/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-309/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;analysis-of-various-machine-learning-classification-techniques-in-detecting-heart-disease&#34;&gt;Analysis of Various Machine Learning Classification Techniques in Detecting Heart Disease&lt;/h1&gt;
&lt;p&gt;Ethan Nguyen, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-309&#34;&gt;fa20-523-309&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-309/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;This section will be addressed as the project nears completion&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-datasets&#34;&gt;2. Datasets&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#21-dataset-cleaning&#34;&gt;2.1 Dataset Cleaning&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#22-dataset-analysis&#34;&gt;2.2 Dataset Analysis&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-machine-learning-algorithms&#34;&gt;3. Machine Learning Algorithms&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-scikit-learn-and-algorithm-types&#34;&gt;3.1 Scikit-Learn and Algorithm Types&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-classification-algorithms&#34;&gt;3.2 Classification Algorithms&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#33-clustering-algorithms&#34;&gt;3.3 Clustering Algorithms&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#project-timeline&#34;&gt;Project Timeline&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#october-26&#34;&gt;October 26&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#november-2&#34;&gt;November 2&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#november-9&#34;&gt;November 9&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#november-16&#34;&gt;November 16&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; health, healthcare, cardiovascular disease, data analysis&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;Since cardiovascular diseases are the number 1 cause of death globally, early prevention could help in extending oneâ€™s life span and possibly quality of life. Since there are cases where patients do not show any signs of cardiovascular trouble until an event occurs, having an algorithm predict from their medical history would help in picking up on early warning signs a physician may overlook. Or could also reveal additional risk factors and patterns for research on prevention and treatment.&lt;/p&gt;
&lt;p&gt;This project will take a high-level overview of common, widely available classification algorithms and analyze their effectiveness for this specific use case. Notable ones include, Gaussian Naive Bayes, K-Nearest Neighbors, and Support Vector Machines.&lt;/p&gt;
&lt;p&gt;Additionally, two data sets that contain common features will be used to increase the training and test pool for evaluation. As well as to explore if additional feature types contribute to a better prediction. As it is known that a large set of data is required to reduce the possibility of the algorithmâ€™s overfitting.&lt;/p&gt;
&lt;h2 id=&#34;2-datasets&#34;&gt;2. Datasets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/johnsmith88/heart-disease-dataset&#34;&gt;https://www.kaggle.com/johnsmith88/heart-disease-dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/sulianova/cardiovascular-disease-dataset&#34;&gt;https://www.kaggle.com/sulianova/cardiovascular-disease-dataset&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The range of creation dates are 1988 and 2019 respectively with different features of which 4 are common between. This does bring up a small hiccup in preprocessing to consider. Namely the possibility of changing diet and culture trends resulting in significantly different trends/patterns within the same age group. As well as possible differences in measurement accuracy. However this large gap is within the scope of the project in exploring which features can help provide an accurate prediction.&lt;/p&gt;
&lt;p&gt;This possible phenomenon may be of interest to explore closely if time allows. Whether a trend itself is even present or there is an overarching trend across different cultures and time periods. Or to consider if this difference is significant enough that the data from the various sets needs to be adjusted to normalize the ages to present day.&lt;/p&gt;
&lt;h3 id=&#34;21-dataset-cleaning&#34;&gt;2.1 Dataset Cleaning&lt;/h3&gt;
&lt;p&gt;The datasets used have already been significantly cleaned from the raw data and has been provided as a csv file. These files were then imported into the python notebook as pandas dataframes for easy manipulation.&lt;/p&gt;
&lt;p&gt;An initial check was made to ensure the integrity of the data matched the description from the source websites. Then some preprocessing was completed to normalize the common features between the datasets. These features were gender, age, and cholesterol levels. The first two adjustments were trivial in conversion however, in the case of cholesterol levels, the 2019 set is on a 1-3 scale while the 1988 dataset provided them as real measurements. A conversion of the 1988 dataset was done based on guidelines found online for the age range of the dataset &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;22-dataset-analysis&#34;&gt;2.2 Dataset Analysis&lt;/h3&gt;
&lt;p&gt;From this point on, the 1988 dataset will be referred to as &lt;code&gt;dav_set&lt;/code&gt; and 2019 data set will be referred to as &lt;code&gt;sav_set&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To provide further insight on what to expect and how a model would be applied, the population of the datasets was analysed first. As depicted in Figure 2.1 the population samples of both datasets of gender vs age show the majority of the data is centered around 60 years of age with a growing slope from 30 onwards.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/master/project/images/agevssex.jpg&#34; alt=&#34;Figure 2.1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.1&lt;/strong&gt;: Age vs Gender distributions of the dav_set and sav_set.&lt;/p&gt;
&lt;p&gt;This trend appears to signify that the datasets focused solely on an older population or general trend in society of not monitoring heart conditions as closely in the younger generation.&lt;/p&gt;
&lt;p&gt;Moving on to Figure 2.2, we see an interesting trend with a significant growing trend in the sav_set in older population having more cardiovascular issues compared to the dav_set. While this cannot be seen in the dav_set. This may be caused by the additional life expectancy or a change in diet as noted in the introduction.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/master/project/images/agevstarget.jpg&#34; alt=&#34;Figure 2.2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.2&lt;/strong&gt;: Age vs Target distributions of the dav_set and sav_set.&lt;/p&gt;
&lt;p&gt;In Figure 2.3, the probability of having cardiovascular issues between the sets are interesting. In the dav_set the inequality of higher probability could be attributed to the larger female samples in the dataset. With the sav_set having a more equal probability between the genders.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/master/project/images/gendervsprobability.jpg&#34; alt=&#34;Figure 2.3&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.3&lt;/strong&gt;: Gender vs Probability of cardiovascular issues of the dav_set and sav_set.&lt;/p&gt;
&lt;p&gt;Finally, in Figure 2.4 is the probability vs cholesterol levels. This one is very interesting between the two datasets in terms of trend levels. With the dav_set having a higher risk at normal levels compared to the sav_set. This could be another hint of a societal change across the years or may in fact be due to the low sample size. Especially since the sav_set matches the general consensus of higher cholesterol levels increasing risk of cardiovascular issues &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/master/project/images/cholesterolvsprobability.jpg&#34; alt=&#34;Figure 2.4&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.4&lt;/strong&gt;: Cholesterol levels vs Probability of cardiovascular issues of the dav_set and sav_set.&lt;/p&gt;
&lt;p&gt;To close out this initial analysis is the correlation map of each of the features. From Figure 2.5 and 2.6 it can be concluded that both of these datasets are viable to conduct machine learning as the correlation factor is below the recommended value of 0.8 &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. Although we do see the signs of a low sample amount in the dav_set with a higher correlation factor compared to the sav_set.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/master/project/images/davsetcorrelation.jpg&#34; alt=&#34;Figure 2.5&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.5&lt;/strong&gt;: dav_set correlation matrix.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/master/project/images/savsetcorrelation.jpg&#34; alt=&#34;Figure 2.6&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.6&lt;/strong&gt;: sav_set correlation matrix.&lt;/p&gt;
&lt;h2 id=&#34;3-machine-learning-algorithms&#34;&gt;3. Machine Learning Algorithms&lt;/h2&gt;
&lt;p&gt;With many machine learning algorithms already available and many more in development. Selecting the optimal one for an application can be a challenging balance since each algorithm has both its advantages and disadvantages. As mentioned in the introduction, we will explore applying the most common and established algorithms available to the public.&lt;/p&gt;
&lt;p&gt;Starting off, is selecting a library from the most popular ones available. Namely Keras, Pytorch, Tensorflow, and Scikit-Learn. Upon further investigation it was determined that Scikit-Learn would be used for this project. The reason being Scikit-Learn is a great general machine learning library that also includes pre and post processing functions. While Keras, Pytorch, and Tensorflow are targeted for neural networks and other higher-level deep learning algorithms which are outside of the scope of this project at this time &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;31-scikit-learn-and-algorithm-types&#34;&gt;3.1 Scikit-Learn and Algorithm Types&lt;/h3&gt;
&lt;p&gt;Diving further into the Scikit-Learn library, its key strength appears to be the variety of algorithms available that are relatively easy to implement against a dataset. Of those available, they are classified under three different categories based on the approach each takes. They are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Classification
&lt;ul&gt;
&lt;li&gt;Applied to problems that require identifying the category an object belongs to.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Regression
&lt;ul&gt;
&lt;li&gt;For predicting or modeling continuous values.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clustering
&lt;ul&gt;
&lt;li&gt;Grouping similar objects into groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For this project, we will be investigating the Classification and Clustering algorithms offered by the library due to the nature of our dataset. Since it is a binary answer, the continuous prediction capability of regression algorithms will not fair well. Compared to classification type algorithms which are well suited for determining binary and multi-class classification on datasets &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. Along with Clustering algorithms being capable of grouping unlabeled data which is one of the key problem points mentioned in the introduction &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;32-classification-algorithms&#34;&gt;3.2 Classification Algorithms&lt;/h3&gt;
&lt;p&gt;The following algorithms were determined to be candidates for this project based on the documentation available on the Scikit-learn for supervised learning &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4 id=&#34;321-support-vector-machines&#34;&gt;3.2.1 Support Vector Machines&lt;/h4&gt;
&lt;p&gt;This algorithm was chosen because classification is one of the target types and has a decent list of advantages that appear to be applicable to this dataset &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Effective in high dimensional spaces as well as if the number dimensions out number samples.&lt;/li&gt;
&lt;li&gt;Is very versatile.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;322-k-nearest-neighbors&#34;&gt;3.2.2 K-Nearest Neighbors&lt;/h4&gt;
&lt;p&gt;This algorithm was selected due to being a non-parametric method that has been successful in classification applications &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;. From the dataset analysis, it is appears that the decision boundary may be very irregular which is a strong point of this type of method.&lt;/p&gt;
&lt;h4 id=&#34;323-gaussian-naive-bayes&#34;&gt;3.2.3 Gaussian Naive Bayes&lt;/h4&gt;
&lt;p&gt;Is an implementation of the Naive Bayes theorem that has been targeted for classification. The advantages of this algorithm is its speed and requires a small training set compared to more advanced algorithms &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4 id=&#34;324-decision-trees&#34;&gt;3.2.4 Decision Trees&lt;/h4&gt;
&lt;p&gt;This algorithm was chosen to investigate another non-parametric method to determine their efficacy against this dataset application. This algorithm also has some advantages over K-Nearest namely &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple to interpret and visualize&lt;/li&gt;
&lt;li&gt;Requires little data preparation
&lt;ul&gt;
&lt;li&gt;Handles numerical and categorical data instead of needing to normalize&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Can validate the model and is possible to audit from a liability standpoint.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;33-clustering-algorithms&#34;&gt;3.3 Clustering Algorithms&lt;/h3&gt;
&lt;p&gt;The following algorithms were determined to be candidates for this project based on the table of clustering algorithms available on the Scikit-learn &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4 id=&#34;331-k-means&#34;&gt;3.3.1 K-Means&lt;/h4&gt;
&lt;p&gt;The usecase for this algorithm is general purpose with even and low number of clusters &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;. Of which the sav_set appears to have with the even distribution across most of the features.&lt;/p&gt;
&lt;h4 id=&#34;332-mean-shift&#34;&gt;3.3.2 Mean-shift&lt;/h4&gt;
&lt;p&gt;This algorithm was chosen for its strength in dealing with uneven cluster sizes and non-flat geometry &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;. Though it is not easily scalable the application of our small dataset size might be of interest.&lt;/p&gt;
&lt;h4 id=&#34;333-spectral-clustering&#34;&gt;3.3.3 Spectral Clustering&lt;/h4&gt;
&lt;p&gt;As an inverse, this algorithm was chosen for its strength with fewer uneven clusters &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;. In comparison to Mean-shift, this maybe the better algorithm for this application.&lt;/p&gt;
&lt;h2 id=&#34;project-timeline&#34;&gt;Project Timeline&lt;/h2&gt;
&lt;p&gt;The following is a plan for the rest of the semester, using the due dates for Assignments 8-11 as milestone dates.&lt;/p&gt;
&lt;h3 id=&#34;october-26&#34;&gt;October 26&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Explore options on normalizing or conversion of the features to connect between the datasets and determine if they are viable to add to the project.
&lt;ul&gt;
&lt;li&gt;A large portion of time was dedicated to researching this point. Unfortunately, nothing of note was discovered to realize this aspect of the plan.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Explore ML models and frameworks and determine viability for the project.
&lt;ul&gt;
&lt;li&gt;Additional information on the algorithms selected. Mainly the underlying calculation, theory, and disadvantages to compensate for has been added to the Nov 2nd milestone date.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Update Report.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;november-2&#34;&gt;November 2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Commence build out of ML models.
&lt;ul&gt;
&lt;li&gt;Tuning of hyperparameters as necessary.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Update Report.&lt;/li&gt;
&lt;li&gt;Milestone Update
&lt;ul&gt;
&lt;li&gt;Delays were encountered due to external events.&lt;/li&gt;
&lt;li&gt;Underestimated the amount of time needed to building the ML models.
&lt;ul&gt;
&lt;li&gt;Task of adding additional information on algorithms selected has been pushed back further due to above.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Initial implementations do not look very promising
&lt;ul&gt;
&lt;li&gt;It is suspected that over fitting is occurring with the base line hyperparameters for the dav_set.&lt;/li&gt;
&lt;li&gt;Accuracy results for the sav_set are not as high as expected for the selected algorithms.&lt;/li&gt;
&lt;li&gt;Further investigation and experimentation is required to implement the clustering type algorithms. Suspect would need to look into dimensionality reduction in order to obtain better accuracy results.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A general download function appears to not be possible. The website that hosts the datasets used requires an API key for script interactions that is unique to each user.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;november-9&#34;&gt;November 9&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ML Models should be complete.&lt;/li&gt;
&lt;li&gt;Start analysis of the various models and their viability.
&lt;ul&gt;
&lt;li&gt;Additional tuning of hyperparameters as necessary.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Update Report&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;november-16&#34;&gt;November 16&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Finalize Report and findings.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;WebMD. 2020. Understanding Your Cholesterol Report. [online] Available at: &lt;a href=&#34;https://www.webmd.com/cholesterol-management/understanding-your-cholesterol-report&#34;&gt;https://www.webmd.com/cholesterol-management/understanding-your-cholesterol-report&lt;/a&gt; [Accessed 21 October 2020]. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;R, V., 2020. Feature Selection â€” Correlation And P-Value. [online] Medium. Available at: &lt;a href=&#34;https://towardsdatascience.com/feature-selection-correlation-and-p-value-da8921bfb3cf&#34;&gt;https://towardsdatascience.com/feature-selection-correlation-and-p-value-da8921bfb3cf&lt;/a&gt; [Accessed 21 October 2020]. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Stack Overflow. 2020. Differences In Scikit Learn, Keras, Or Pytorch. [online] Available at: &lt;a href=&#34;https://stackoverflow.com/questions/54527439/differences-in-scikit-learn-keras-or-pytorch&#34;&gt;https://stackoverflow.com/questions/54527439/differences-in-scikit-learn-keras-or-pytorch&lt;/a&gt; [Accessed 27 October 2020]. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 1.4. Support Vector Machines â€” Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/svm.html#classification&#34;&gt;https://scikit-learn.org/stable/modules/svm.html#classification&lt;/a&gt; [Accessed 27 October 2020]. &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 2.3. Clustering â€” Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#clustering&#34;&gt;https://scikit-learn.org/stable/modules/clustering.html#clustering&lt;/a&gt; [Accessed 27 October 2020]. &lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 1. Supervised Learning â€” Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/supervised_learning.html#supervised-learning&#34;&gt;https://scikit-learn.org/stable/supervised_learning.html#supervised-learning&lt;/a&gt; [Accessed 27 October 2020]. &lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 1.6. Nearest Neighbors â€” Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/neighbors.html&#34;&gt;https://scikit-learn.org/stable/modules/neighbors.html&lt;/a&gt; [Accessed 27 October 2020]. &lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 1.9. Naive Bayes â€” Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/naive_bayes.html&#34;&gt;https://scikit-learn.org/stable/modules/naive_bayes.html&lt;/a&gt; [Accessed 27 October 2020]. &lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 1.10. Decision Trees â€” Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/tree.html&#34;&gt;https://scikit-learn.org/stable/modules/tree.html&lt;/a&gt; [Accessed 27 October 2020]. &lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 2.3. Clustering â€” Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#clustering&#34;&gt;https://scikit-learn.org/stable/modules/clustering.html#clustering&lt;/a&gt; [Accessed 27 October 2020]. &lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-312/assignment6/assignment6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-312/assignment6/assignment6/</guid>
      <description>
        
        
        &lt;h1 id=&#34;engr-e-534-assignment-6-ai-in-health-and-medicine&#34;&gt;ENGR-E 534 Assignment 6: AI in Health and Medicine&lt;/h1&gt;
&lt;h1 id=&#34;ai-enabled-covid-19-diagnostic-framework-utilizing-smartphone-based-embedded-sensors&#34;&gt;AI-enabled COVID-19 diagnostic framework utilizing Smartphone-based Embedded Sensors&lt;/h1&gt;
&lt;p&gt;Saptarshi Sinha, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-312/&#34;&gt;fa20-523-312&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-312/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; smartphone, neural networks, CNN, RNN, embedded sensors, symptom detection, cloud computing&lt;/p&gt;
&lt;h2 id=&#34;1-background-the-need-for-smarter-and-more-pervasive-covid-19-monitoring&#34;&gt;1. Background: The need for smarter and more pervasive COVID-19 monitoring&lt;/h2&gt;
&lt;p&gt;As mankind grapples with the menacing threat of an ongoing pandemic involving the novel COVID-19 (coronavirus infection), researchers and clinicians across the board have tirelessly involved themselves in myriad efforts for controlling the relentless proliferation of this virus so as to check the viral-driven casualties across the globe. It might seem that for the very first time, science and technology have been put to its greatest test ever. It seems that only time can tell if our scientific valor is indeed powerful enough to succeed in such a test, or if the virus would instead claim a major portion of the worldâ€™s population as its unfortunate casualty.&lt;/p&gt;
&lt;p&gt;Numerous scientific approaches have been fielded in a relatively short amount of time to deal with the current problem. Many approaches involve novel technologies such as remote video surveillance using assistive robots that monitor virus-inflicted patients, while also protecting those healthcare workers by not involving them in such in-person diagnostic processes. Other approaches involve using machine learning based methodologies for sorting out patents with the virus from those without it simply by using an efficient algorithmic procedure of analyzing different aspects of patientsâ€™ CT scans. Major companies have also stepped in to assist in a war-footing format. As an example, Amazon Care is providing pick-up and delivery-based services of test-kits in particular virus-prone locations. Appleâ€™s Siri is now able to provide symptom-based guidance in relation to COVID-19. Microsoft helped creating the Adaptive Biotechnologies platform that studies how our immune system responds to the virus which can provide insights for establishing drug development procedures. Finally, various biotechnological companies all across the world have started conducting extensive research into vaccine development and drug development procedures to combat this novel strain of the virus.&lt;/p&gt;
&lt;p&gt;As amazing these techniques might seem at a superficial glance, the major setback the world is suffering from is with the extent of the viral spread that is amplified due to the lack of testing capabilities. They are either inadequate or cannot handle an entire nationâ€™s population. Although proactive actions have been employed in many nations, testing kits are still being produced slowly. This gives the virus an unfair advantage as time is of the essence. People (esp. asymptomatic individuals) with the virus remain undiagnosed for a greater length of time during which they can inadvertently aid with the proliferation of the viral disease. In this particular context, a very novel strategy for COVID-19 testing and diagnosis will be discussed that utilizes something that we all possess â€“ a smartphone device.&lt;/p&gt;
&lt;h2 id=&#34;2-design--working-principle-ai-based-diagnostic-framework-for-covid-19-utilizing-smartphone-based-embedded-sensors-and-artificial-neural-networks&#34;&gt;2. Design &amp;amp; Working Principle: AI-based diagnostic framework for COVID-19 utilizing Smartphone-based Embedded Sensors and Artificial Neural Networks&lt;/h2&gt;
&lt;p&gt;Cornell Universityâ€™s archive on Human Computer Interaction (HCI) features a recent article that discusses a strategy involving COVID-19 diagnosis with smartphone-based sensors. In its simplest form, the framework includes the smartphone, and its accompanying sensors and algorithms. External hardware accessories with high-power consumption, or access to specialized equipment is not required for this design &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Since the application framework involves something that common people use on a daily basis, no tutorials or expert assistance is required to work with such an application. To understand the framework better, we must first note the various symptom types that are exhibited by COVID-19 patients which include high fever, tiredness, dry cough, intense headache, shortness of breath, nausea, etc. To efficiently capture the symptoms, an essential piece of information to keep in mind here is that modern smartphone devices come equipped with various in-built sensors viz. camera sensor, inertial sensor, temperature sensor, accelerometer sensor, microphones, etc. Many previous endeavors utilized such sensors to detect symptoms for other diseases &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. For instance, temperature-fingerprint sensor was used previously for measuring fever-levels; camera sensors (with accelerometers) were utilized earlier to analyze fatigue levels via pattern-recognition algorithms for human-gait analysis; camera sensor (with inertial sensor) were also used for analyzing neck posture to evaluate the headache severities; and, even the microphone was utilized previously for analyzing a patientâ€™s cough-noise in a diagnostic process &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;The research article describes a strategy which uses these various smartphone sensors and their respective algorithms. This is followed up by creating a dataset record comprising predicted levels of the different symptoms which are collected from different patients and studied using deep learning approaches &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Chiefly, it uses Convolutional Neural Networks (CNN) to analyze spatial data (viz. imaging data from the camera sensor), and Recurrent Neural Networks (RNN) for temporal data (viz. signal or text-based measurements) &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. The entire prediction-based framework can be summarized as follows:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/Picture1.png&#34; alt=&#34;Smartphone-based framework for COVID-19 testing&#34;&gt;&lt;/p&gt;
&lt;p&gt;
    &lt;img src=&#34;path_to_image&#34; alt&gt;
    &lt;em&gt;Figure 1: Smartphone-based framework for COVID-19 testing; Source: Adapted from [^1]&lt;/em&gt;
&lt;/p&gt;
&lt;p&gt;The above framework can be sub-divided into four important layers which provides further insights into the different procedures going on in the background while the system makes the disease predictions.&lt;/p&gt;
&lt;h3 id=&#34;i-reading&#34;&gt;i. Reading&lt;/h3&gt;
&lt;p&gt;The first layer involves reading based functionalities for the data coming from different smartphone sensors. This could refer to arrays of different types of data coming from different sources (viz. CT scan imageries, accelerometer readings, microphone sound signals, etc.).&lt;/p&gt;
&lt;h3 id=&#34;ii-configurations&#34;&gt;ii. Configurations&lt;/h3&gt;
&lt;p&gt;The second layer deals with configuring onboard sensors for varied metrics such as time intervals, image resolution, etc. Readings from these first two steps are fed as inputs for the â€œsymptoms algorithmâ€ that can be executed as a smartphone application.&lt;/p&gt;
&lt;h3 id=&#34;iii-symptoms-prediction&#34;&gt;iii. Symptoms Prediction&lt;/h3&gt;
&lt;p&gt;The third layer deals with symptoms-level evaluation. The result is stored as a record that can be fed as an input for the next layer.&lt;/p&gt;
&lt;h3 id=&#34;iv-covid-19-prediction&#34;&gt;iv. COVID-19 Prediction&lt;/h3&gt;
&lt;p&gt;Finally, the last layer involves the application of deep learning (DL) based algorithms to the input data for predicting whether the patient has been afflicted with the virus. A CNN and RNN based combined process is utilized here such that the system can analyze both the spatial data (viz. image pixels) as well as the temporal data (viz. text/signal information) [1].&lt;/p&gt;
&lt;h2 id=&#34;3-discussions-augmentation-with-cloud-comuputing-capabilities&#34;&gt;3. Discussions: Augmentation with Cloud-Comuputing capabilities&lt;/h2&gt;
&lt;p&gt;To enhance the performance of this framework, the recorded data and predicted results can be uploaded to cloud-computing servers. This can help researchers and medical professionals from all around the globe in exchanging information and insights involving accurate patient diagnosis. Such applications are already developing. For instance, IBM recently launched the COVID-19 High Performance Computing Consortium &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. As the name suggests, this consortium has been explicitly designed to tackle the threat of COVID-19 by harnessing enormous computing power for streamlining the search for more information, aiding the hunt of possible treatment paths, and creating drug-and-disease based informational repositories that are made available to appropriate and eligible researchers and institutions strewn all across the globe &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;All in all, it is indeed very commendable on the part of these researchers to facilitate the design of such a low-cost yet effective method of diagnosing COVID-19 when testing capacities are severely limited. If used appropriately, it can stem the spread of this virus by making it possible to diagnose patients sooner and quarantining them. Of course, the strategy does not focus on the treatment itself. But in the current scenario, where we have arrived at a breaking point with this disease, it would greatly assist healthcare personnel with locating and quarantining patients, that would indirectly help saving scores of other lives.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Maghdid, Halgurd S., et al. â€œA Novel AI-Enabled Framework to Diagnose Coronavirus COVID 19 Using Smartphone Embedded Sensors: Design Study.â€ ArXiv:2003.07434 [Cs, q-Bio], May 2020. arXiv.org, &lt;a href=&#34;http://arxiv.org/abs/2003.07434&#34;&gt;http://arxiv.org/abs/2003.07434&lt;/a&gt; &lt;/br&gt; &lt;/br&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;D. Gil, â€œIBM Releases Novel AI-Powered Technologies to Help Health and Research Community Accelerate the Discovery of Medical Insights and Treatments for COVID-19â€, ibm.com, Apr. 3, 2020. [Online]. Available: &lt;a href=&#34;https://www.ibm.com/blogs/research/2020/04/ai-powered-technologies-accelerate-discovery-covid-19/&#34;&gt;https://www.ibm.com/blogs/research/2020/04/ai-powered-technologies-accelerate-discovery-covid-19/&lt;/a&gt; [Accessed Oct. 17, 2020] &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-312/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-312/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;aquatic-toxicity-analysis-with-the-aid-of-autonomous-surface-vehicle-asv&#34;&gt;Aquatic Toxicity Analysis with the aid of Autonomous Surface Vehicle (ASV)&lt;/h1&gt;
&lt;p&gt;Saptarshi Sinha, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-312/&#34;&gt;fa20-523-312&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-312/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;With the passage of time, human activities have created and contributed much to the aggrandizing problems of various forms of environmental pollution. Massive amounts of industrial effluents and agricultural waste wash-offs, that often comprise pesticides and other forms of agricultural chemicals, find their way to fresh water bodies, to lakes, and eventually to the oceanic systems. Such events start producing a gradual increase in the toxicity levels of marine ecosystems thereby perturbing the natural balance of such water-bodies. In this endeavor, an attempt will be made to measure the various water quality metrics (viz. temperature, pH, dissolved-oxygen level, and conductivity) with the help of an autonomous surface vehicle (ASV). This collected data will then be analyzed to ascertain if these values exhibit aberration from the established values that are found from USGS and EPA databases for water-quality standards. In the event, the collected data significantly deviates from the standard values of unpolluted sources in nearby geographical areas, that are obtained from the above databases, it can be concluded that the aquatic system in question has been degraded and may no longer be utilized for any form of human usage, such as being sourced for drinking water.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-choice-of-data-sets&#34;&gt;3. Choice of Data-sets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-methodology&#34;&gt;4. Methodology&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#41-hardware-component&#34;&gt;4.1 Hardware Component&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#42-software-component&#34;&gt;4.2 Software Component&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-inference&#34;&gt;5. Inference&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-conclusion&#34;&gt;6. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#8-references&#34;&gt;8. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; toxicology, pollution, autonomous systems, surface vehicle, sensors, arduino, water quality, data analysis, environment, big data, ecosystem&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;When it comes to revolutionizing our qualities of life and improving standards, there is not another branch of science and technology that has made more impact than the myriad technological capabilities offered by the areas of Artificial Intelligence (AI) and its sub-fields involving Computer Vision, Robotics, Machine Learning, Deep Learning, Reinforcement Learning, etc. It should be borne in mind that AI was developed to allow machines/computer processors to work in the same way as the human brain works and which could make intelligent decisions at every conscious level. It was meant to help with tasks for rendering scientific applications more smarter and efficient. There are many tasks that can be performed in a far more dexterous fashion by employing smart-machines and algorithms than by involving human beings. But even more importantly, AI has also been designed to perform tasks that cannot be successfully completed by employing human beings. This could either be due to the prolonged boredom of the task itself, or a task that involves hazardous environments that cannot sustain life-forms for a long time. Some examples in this regard would involve exploring deep mines or volcanic trenches for mineral deposits, exploring the vast expanse of the universe and heavenly bodies, etc. And this is where the concept employing AI/Robotics based technology fits in perfectly for aquatic monitoring and oceanographical surveillance based applications.&lt;/p&gt;
&lt;p&gt;Toxicity analysis of ecologically vulnerable water-bodies, or any other marine ecosystem for that matter, could give us a treasure trove of information regarding biodiversity, mineral deposits, unknown biophysical phenomenon, but most importantly, it could also provide meaningful and scientific information related to the biodegradation of the ecosystem itself. In this research project, an attempt will be made to design a simple foundation of an aquatic Autonomous Surface Vehicle (ASV) that will be deployed in marine ecosystems. Such a vehicle would be embedded with different kind of electronic sensors, that are capable of measuring physical quantities such as temperature, pH, conductance, dissolved oxygen level, etc. The data collected by such a system can either be over a period of time (temporal data), or it could cover a vast aquatic geographical region (spatial data). This data will then be compared with existing datasets that are made publicly available by various environmental organizations in the United States, most importantly the Environmental Protection Agency (EPA) and the US Geological Survey (USGS). A comparative data analysis task between the data collected by the ASV and the vast array of environmental data that are made available from these agencies can then give us an indication about the status of the aquatic degradation of the ecosystem in question by measuring the extent to which the current data deviates from relevant historical data trends.&lt;/p&gt;
&lt;h2 id=&#34;2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/h2&gt;
&lt;p&gt;After reviewing the necessary background literture and previous work that has been done in this field, it can be stated that most of such endeavors focussed majorly on continuous environmental data collection with the help of sensors attached to a stationary buoy in a particular location of a water-body. Some of the other endeavors did involve deploying a non-stationary vehicle that collected data from large swaths of geographical areas in various water bodies &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Other research attempts focussed on niche areas such as study of the migration pattern exhibited by zooplanktons upon natural and aritifical irradiance &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, and detection and monitoring of marine fauna &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. However, neither did such attempts focus much on the data analysis portion for multiple sensory input(s) nor did it involve an intricate procedure to compare the collected data with historical trends so as to arrive at a suitable conclusion regarding the extent of environmental degradation.&lt;/p&gt;
&lt;p&gt;As mentioned in the previous section, this research project will exhaustively focus not just on the data-collection portion by a non-stationary vehicle, but it will also involve employing deeper study towards the subject of big-data analysis of both the current data of the system in question and the past data obtained for similar aquatic profiles. In this way, it would be possible to learn more about the toxicological aspects of the ecosystem in question.&lt;/p&gt;
&lt;h2 id=&#34;3-choice-of-data-sets&#34;&gt;3. Choice of Data-sets&lt;/h2&gt;
&lt;p&gt;Upon exploring a wide array of available datasets, the following data repositories were chosen to get the required water quality based data over a particular period of time and for a particular geographical region:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://waterdata.usgs.gov/nwis/qw&#34;&gt;USGS Water Quality Data&lt;/a&gt; &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.epa.gov/waterdata/water-quality-data-download&#34;&gt;EPA Water Quality Data&lt;/a&gt; &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The USGS dataset is very commensurate with the research goal of this endeavor and hence, focus will be put more on the USGS dataset over the EPA dataset. Some previous work was conducted on this USGS dataset by a particular research team &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. However, the emphasis of such work was done from a very broad perspective so as to create an overview of how to use and visualize the data from the USGS water quality portal. Besides, such a work emphasizes on characterizing the seasonal variation of lake water clarity in different regions throughout the continental US, something that is very deviant from what would be addressed in this particular article which majorly involves environmental degradation and toxicology analysis using an autonomous surface vehicle.&lt;/p&gt;
&lt;p&gt;To address the questions involving existence of multiple data-sets and motivation of using multiple data-sets, we must keep in mind that the very nature of this study is based on historical trends of the nature of water-quality in a particular region from the past and how it relates to the current situation. Because of these reasons, multiple data-sets will be referred to from multiple sources so as to achieve robust data-analytical results. This would ensure that too much focus is not given on outlier cases, that may be relevant to just a particular geographical region or an aberration in the data that may only have arisen due to an unknown underlying phenomenon or some form of cataclysmic event from the past. Using multiple datasets from different sources would help to get a resultant data structure that is more likely to converge towards an approximate level of historical thresholds and which can then be used to find out how the current observed data deviates from such previous patterns.&lt;/p&gt;
&lt;h2 id=&#34;4-methodology&#34;&gt;4. Methodology&lt;/h2&gt;
&lt;h3 id=&#34;41-hardware-component&#34;&gt;4.1 Hardware Component&lt;/h3&gt;
&lt;p&gt;The rough outline of the autonomous surface vehicle (ASV) in question has been perceived in the Autodesk Fusion 360 software model. A preliminary model has been designed in this software so as to 3D print the system. It will then be interfaced with the appropriate sensors in question. Then system will be driven by an Arduino-Uno based microcontroller, and it will have different types of environmental sensors that will collect and log data. These sensors have been purchased from the vendor, &amp;ldquo;Atlas Scientific&amp;rdquo;. As of now, the sensors that have been chosen for this ASV are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PT-1000 Temperature sensor kit - &lt;a href=&#34;https://atlas-scientific.com/kits/pt-1000-temperature-kit/&#34;&gt;https://atlas-scientific.com/kits/pt-1000-temperature-kit/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Potential of Hydrogen (pH) sensor kit - &lt;a href=&#34;https://atlas-scientific.com/kits/ph-kit/&#34;&gt;https://atlas-scientific.com/kits/ph-kit/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Dissolved Oxygen (DO) sensor kit - &lt;a href=&#34;https://atlas-scientific.com/kits/dissolved-oxygen-kit/&#34;&gt;https://atlas-scientific.com/kits/dissolved-oxygen-kit/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Conductivity K 1.0 sensor kit - &lt;a href=&#34;https://atlas-scientific.com/kits/conductivity-k-1-0-kit/&#34;&gt;https://atlas-scientific.com/kits/conductivity-k-1-0-kit/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A very rudimentary framework of the system has been realized in the Autodesk Fusion 360 software architecture as shown below. The design provided below is a very simplistic platform but which will lay the foundation of the final structure of the system (see Figure 1).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/ASVSS1.png&#34; alt=&#34;ASV from Fusion 360&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Nascent framework of the ASV system in Fusion 360&lt;/p&gt;
&lt;p&gt;With the chassis framework out of the way, a careful analysis was conducted towards the successful developmental work to be done to complete the build process for a fully functional prototype ASV. In essence, an ASV can be thought of being composed of certain key sub-elements. From a broad perspective, they comprise the hardware makeup, a suitable propulsion system, a sensing system, a communication system, and an appropriate source of onboard power source. The hardware makeup being out of the way, the other aspects can now be elaborated as follows:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Propulsion System:&lt;/strong&gt; The two possibilities that was considered in this regard involve using either a single servo motor with an assortment of rudders and propellers for appropriate steering, or using two separate servo motors, one of which will drive the left-hand side of the system and the other would drive the right-hand side. The second arrangement is preferred in this regard as it provides with better maneuverability and control of the system. For instance, to move forward in a rectilinear fashion, both the motors would be given the same level of power. Whereas for steering the system in a particular direction, one of the motors would be assigned a lower power level than the other, thereby enabling the system to curve inwards on the side which has the motor with a lower power level. Of course, there will always be perturbations and natural disturbances that will deter the system from making these correct path changes. For this reason, a Proportional-Integral-Derivative (PID) controlled response would be augmented for the locomotion algorithm.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sensing System:&lt;/strong&gt; As discussed previously, an arrangement involving four different sensors will be integrated in the ASV. This way, when the entire ASV system is deployed in an aquatic environment, it will be able to simultaneously provide readings for all four water-quality parameters in this case. Precisely, these water-quality parameters would be temperature, potential of hydrogen (pH), dissolved oxygen level, and specific conductance value. It should be noted in this perspective that it is possible to include even more sensors in this ASV system. However, the reason why it was not necessary to go beyond these four sensor types is primarily because of two reasons. Firstly, these parameters are important to most toxicological analysis studies &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; and the readings provided by such a sensory system could be considered as a foundation which could provide future directions (including adding more sensors, if needed). Secondly, we should also keep in mind that the hardware system has certain constraints. In this scenario, it involves a sensory shield (that can be integrated with the Arduino microcontroller) that is being used but which has a maximum of four ports for four different sensors only. Though it is possible to add another layer of shield on top of the current one (thereby raising the capability of integrating the number of sensors to eight), it adds unnecessary bandwidth issues, memory depletion possibilities, along with an increased demand of higher power supply. These issues will especially be more consequential in this case as we are dealing with a microcontroller that has limited memory and power, unlike a microprocessor. Hence, the decision to stick with four sensors only was made.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Communication System:&lt;/strong&gt; This is possibly the most important part of the ASV system as we need to device a technique to offload the data that is collected by the vehicle back to a remote computer/server that would likely be located at a considerable distance away from the ASV. There are different options that have been considered in this regard for establishing a proper communicative functionality between the ASV and the remote computer. Some options that have been considered involved Bluetooth, IR signals, RF signals, GPS-based system, satellite communication, etc. There are both pros and cons when it comes to using any of these different communication systems for the ASV. However, the most important metric in this case involves the maximum range the communication system could span over. Obviously, some of the options (viz. Bluetooth) would not be possible in this regard as they have a very limited communication range. Some others (viz. satellite communication systems) have a very high range but were nevertheless found unsuitable for this endeavor as they required too much onboard processing power to even carry out their most basic operations. Hence, a balanced approach was followed in this scenario and a GPS/RF-based system was eventually chosen as the most appropriate candidate for carrying out the proposed tasks of the ASV.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Power Source:&lt;/strong&gt; Finally, we need an onboard processing power system that can provide the required amount of power to all the functional entities housed in the ASV system. The characteristic of such a desired power source would be that it would not require charging often and can sustain proper ASV operations for at least five to six hours. Additionally, the weight of the power source should also not be too clumsy that might put the stability of the entire ASV system in jeopardy. It must have a suitable weight, and should also come in an appropriate shape and size such that the weight of the entire system is evenly distributed over a large area, thereby further reinforcing the stability of the system.&lt;/p&gt;
&lt;h3 id=&#34;42-software-component&#34;&gt;4.2 Software Component&lt;/h3&gt;
&lt;p&gt;After the data has been collected by the ASV either on a temporal scale (over a period of time) or a spatial scale (over a geographical area), it will then be analyzed to decipher the median convergent values of the water body for the four different parameters that have been measured (i.e. Temperature, pH, DO, and Conductivity). The results of this data analysis task will then be used to find out if such water quality parametric values manifested by the aquatic ecosystem in question deviates by a large proportion from the other result that is obtained after analyzing the historical data from USGS and EPA for a nearby and unpolluted source of water. The USGS and EPA websites make it easier to find data from a nearby geographical region by making it possible to enter the desired location prior to searching for water quality data in their huge databases. In this way, it can be figured out if the water quality parameters of the particular ecological system varies wildly from a neighboring system that has almost the same geographical and ecological attributes.&lt;/p&gt;
&lt;p&gt;The establishment of the degree of variance of the data from the historical data will be carried out by documenting the particular quartile range that the current data lies in with respect to the median data that is obtained from the past/historical datasets. For instance, if the current data resides in the second quartile, it can be demarcated as being more or less consistent with previously established values. However, if it resides in the first or third quartile then it might will that the system has aberrant aspects which might need to be investigated for possible levels of outside pollutants (viz. industrial effluents, agricultural wash-off, etc.), or presence of harmful invasive species that might be altering the delicate natural balance of the ecosystem in question.&lt;/p&gt;
&lt;h2 id=&#34;5-inference&#34;&gt;5. Inference&lt;/h2&gt;
&lt;p&gt;NOTE: This section will continue to be updated until project completion.&lt;/p&gt;
&lt;p&gt;The first preliminary set of results are displayed below. Here, the content of the dataset, after it is processed in a software architecture, is shown and it displays the alteration of the values (expressed in line plots, scatter plots, and histograms) of the four main water-quality parameters (viz. Temperature, Specific Conductance, pH, and Dissolved Oxygen) over the period of time that starts from October 9, 2020 to October 16, 2020.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/L_temp.png&#34; alt=&#34;Temperature plots&#34;&gt;
&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/S_temp.png&#34; alt=&#34;Temperature plots&#34;&gt;
&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/H_temp.png&#34; alt=&#34;Temperature plots&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; Line, Scatter, and Histogram plots for the water-quality parameter involving &amp;ldquo;Temperature&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/L_cond.png&#34; alt=&#34;Specific Conductance plots&#34;&gt;
&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/S_cond.png&#34; alt=&#34;Specific Conductance plots&#34;&gt;
&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/H_cond.png&#34; alt=&#34;Specific Conductance plots&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; Line, Scatter, and Histogram plots for the water-quality parameter involving &amp;ldquo;Specific Conductance&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/L_pH.png&#34; alt=&#34;pH plots&#34;&gt;
&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/S_pH.png&#34; alt=&#34;pH plots&#34;&gt;
&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/H_pH.png&#34; alt=&#34;pH plots&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 4:&lt;/strong&gt; Line, Scatter, and Histogram plots for the water-quality parameter involving &amp;ldquo;pH&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/L_dO2.png&#34; alt=&#34;Dissolved Oxygen level&#34;&gt;
&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/S_dO2.png&#34; alt=&#34;Dissolved Oxygen level&#34;&gt;
&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-312/raw/master/project/images/H_dO2.png&#34; alt=&#34;Dissolved Oxygen level&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 5:&lt;/strong&gt; Line, Scatter, and Histogram plots for the water-quality parameter involving &amp;ldquo;Dissolved Oxygen level&amp;rdquo;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First Benchmark results (Expected - November 11)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Second Benchmark results (Expected - November 13)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Third Benchmark results (Expected - November 15)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;6-conclusion&#34;&gt;6. Conclusion&lt;/h2&gt;
&lt;p&gt;NOTE: This section will be addressed upon project completion.&lt;/p&gt;
&lt;h2 id=&#34;7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/h2&gt;
&lt;p&gt;The author would like to thank Dr. Gregor Von Laszewski, Dr. Geoffrey Fox, and the associate instructors in the &lt;em&gt;FA20-BL-ENGR-E534-11530: Big Data Applications&lt;/em&gt; course (offered in the Fall 2020 semester at Indiana University, Bloomington) for their continued assistance and suggestions with regard to exploring this idea and also for their aid with preparing the various drafts of this article.&lt;/p&gt;
&lt;h2 id=&#34;8-references&#34;&gt;8. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Valada A., Velagapudi P., Kannan B., Tomaszewski C., Kantor G., Scerri P. (2014) Development of a Low Cost Multi-Robot Autonomous Marine Surface Platform. In: Yoshida K., Tadokoro S. (eds) Field and Service Robotics. Springer Tracts in Advanced Robotics, vol 92. Springer, Berlin, Heidelberg. &lt;a href=&#34;https://doi.org/10.1007/978-3-642-40686-7_43&#34;&gt;https://doi.org/10.1007/978-3-642-40686-7_43&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;M. Ludvigsen, J. Berge, M. Geoffroy, J. H. Cohen, P. R. De La Torre, S. M. Nornes, H. Singh, A. J. SÃ¸rensen, M. Daase, G. Johnsen, Use of an Autonomous Surface Vehicle reveals small-scale diel vertical migrations of zooplankton and susceptibility to light pollution under low solar irradiance. Sci. Adv. 4, eaap9887 (2018). &lt;a href=&#34;https://advances.sciencemag.org/content/4/1/eaap9887/tab-pdf&#34;&gt;https://advances.sciencemag.org/content/4/1/eaap9887/tab-pdf&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Verfuss U., et al., (2019, March). A review of unmanned vehicles for the detection and monitoring of marine fauna. Marine Pollution Bulletin, Volume 140, Pages 17-29. Retrieved from &lt;a href=&#34;https://doi.org/10.1016/j.marpolbul.2019.01.009&#34;&gt;https://doi.org/10.1016/j.marpolbul.2019.01.009&lt;/a&gt; &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;USGS Water Quality Data, Accessed: Nov. 2020, &lt;a href=&#34;https://waterdata.usgs.gov/nwis/qw&#34;&gt;https://waterdata.usgs.gov/nwis/qw&lt;/a&gt; &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;EPA Water Quality Data, Accessed Nov. 2020, &lt;a href=&#34;https://www.epa.gov/waterdata/water-quality-data-download&#34;&gt;https://www.epa.gov/waterdata/water-quality-data-download&lt;/a&gt; &lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Read, E. K., Carr, L., De Cicco, L., Dugan, H. A., Hanson, P. C., Hart, J. A., Kreft, J., Read, J. S., and Winslow, L. A. (2017), Water quality data for nationalâ€scale aquatic research: The Water Quality Portal, Water Resour. Res., 53, 1735â€“ 1745, doi:10.1002/2016WR019993. &lt;a href=&#34;https://agupubs.onlinelibrary.wiley.com/doi/epdf/10.1002/2016WR019993&#34;&gt;https://agupubs.onlinelibrary.wiley.com/doi/epdf/10.1002/2016WR019993&lt;/a&gt; &lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-313/assignment5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-313/assignment5/</guid>
      <description>
        
        
        &lt;h1 id=&#34;homework-5&#34;&gt;Homework 5&lt;/h1&gt;
&lt;h2 id=&#34;student-name-fauzan-isnaini&#34;&gt;Student Name: Fauzan Isnaini&lt;/h2&gt;
&lt;h1 id=&#34;predicting-stock-market-recovery-in-indonesia-after-covid-19-crash&#34;&gt;Predicting Stock Market Recovery in Indonesia after COVID-19 Crash&lt;/h1&gt;
&lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt;
&lt;p&gt;I will conduct this study by myself.&lt;/p&gt;
&lt;h2 id=&#34;topic&#34;&gt;Topic&lt;/h2&gt;
&lt;p&gt;The COVID-19 Pandemic is not just a crisis in the public health sector.
It also impacts unemployment rates, business revenues, and mass
psychology, which in the end lead to crashes in global stock markets.
While some stock indexes like the Dow Jones Industrial Average (DJIA)
and NASDAQ Composite already recovered, the Indonesian Stock Market
Index (IDX Composite) is still far below its price before the pandemic.
Some of the possible causes are: 1. Foreign investments represent about
50% of the total fund in the IDX stock exchange. In a pandemic
situation, foreign investors might choose to withdraw their stocks and
find another safer country to invest in. 2. Unpredictability of the
pandemic situation drives investors to reallocate their funds in safer
assets, such as cash, gold, or USD. 3. Changes in the macroeconomic
situation, such as unemployment rate, Indonesian Rupiah (IDR) exchange
rate, and interest rate. 4. Changes in the consumer buying power also
change the business revenues, thus changing fundamental data. 5. Mass
psychology of investors that the stock market is not safe in this
pandemic situation, holding them from returning to the stock market To
predict the time needed for IDX Composite to recover, there are two
indicators that can be utilized: 1. Fundamental indicators, which
represent the financial aspect. This can be in the form of macroeconomic
data and a company financial report 2. Technical indicators, which
represent the mass psychology of investors. This can be obtained from
news, social media, or statistical analysis of how the stock market
moves&lt;/p&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;In predicting the outcome, I will utilize these datasets: 1. Yahoo
Finance (finance.yahoo.com). Yahoo Finance contains a lot of both
fundamental and technical data, and they are free of charge. 2. Twitter
(twitter.com). I can conduct a content analysis on Twitter to represent
the mass psychology regarding the economic condition in Indonesia 3.
News channel. I can also utilize data crawler software to conduct
content analysis to compare positive and negative news in Indonesia. 4.
Third party stock data feeder. There are some third parties who provide
more comprehensive stock data on a subscription basis. This is another
option if the above datasets are not sufficient&lt;/p&gt;
&lt;h2 id=&#34;what-needs-to-be-done-to-get-a-great-grade&#34;&gt;What needs to be done to get a great grade&lt;/h2&gt;
&lt;p&gt;I will build a Python program to learn these data and generate a
prediction on when the IDX Composite will recover. I will also consider
the recovery rate of each of these sectors: 1. Mining 2. Agriculture 3.
Finance 4. Infrastructure 5. Miscellaneous Industries 6. Consumers&amp;rsquo;
Goods 7. Property 8. Trading 9. Basic Industry While they are
incorporated in the IDX Composite, the recovery rate of each sector may
be different because of their respective nature of the industry. For
example, consumer&amp;rsquo;s goods may be impacted less in this COVID-19
pandemic, thus resulting in a faster recovery. On the other hand, the
property sector might be the most impacted sector in this pandemic, thus
resulting in a long time to recover. The program will be able to learn
continuously, so if new data is available, it can renew the analysis and
give a more accurate prediction.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-313/assignment6/assignment6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-313/assignment6/assignment6/</guid>
      <description>
        
        
        &lt;h1 id=&#34;homework-6&#34;&gt;Homework 6&lt;/h1&gt;
&lt;p&gt;Student Name: Fauzan Isnaini&lt;/p&gt;
&lt;h1 id=&#34;how-ai-helps-diagnosis-and-decision-making-in-health-care-facilities&#34;&gt;How AI Helps Diagnosis and Decision Making in Health Care Facilities&lt;/h1&gt;
&lt;h2 id=&#34;radiology-assistant&#34;&gt;Radiology Assistant&lt;/h2&gt;
&lt;p&gt;Radiology is a branch of medicine that uses imaging technology to diagnose and treat disease. Diagnostic radiology helps health care providers see structures inside your body. Using the diagnostic images, the radiologist or other physicians can often [3]:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Diagnose the cause of your symptoms&lt;/li&gt;
&lt;li&gt;Monitor how well your body is responding to a treatment you are receiving for your disease or condition&lt;/li&gt;
&lt;li&gt;Screen for different illnesses, such as breast cancer, colon cancer, or heart disease
Within radiology, trained physicians visually assess medical images and report findings to detect, characterize and monitor diseases. Such assessment is often based on education and experience and can be, at times, subjective. In contrast to such qualitative reasoning, AI excels at recognizing complex patterns in imaging data and can provide a quantitative assessment in an automated fashion. More accurate and reproducible radiology assessments can then be made when AI is integrated into the clinical workflow as a tool to assist physicians.[1]
Some examples of AIâ€™s clinical application in radiology are [1]:&lt;/li&gt;
&lt;li&gt;Thoracic imaging
AI can help in identifying pulmonary nodules, which can be applied in early detection of lung cancer&lt;/li&gt;
&lt;li&gt;Abdominal and pelvic imaging
AI can help in detecting lesions in abdominal and pelvic. For example, AI can analyze data from computed topography (CT) and magnetic resonance imaging (MRI) to detect liver lesions, and characterize these lesions as benign or malignant. Furthermore, AI can also help in suggesting the follow-up actions for the patient.&lt;/li&gt;
&lt;li&gt;Colonoscopy
Colonic polyps that are undetected or misclassified pose a potential risk of colorectal cancer. AI can help in making an early detection and consistent monitoring of this risk.&lt;/li&gt;
&lt;li&gt;Mammography
Analyzing mammography is technically challenging, even for a trained expert. AI can assist in interpreting the image. For example, AI can identify and characterize microcalcifications. Microcalcifications are tiny deposits of calcium salts that are too small to be felt but can be detected by imaging, and can be an early sign of breast cancer. They can be scattered throughout the mammary gland, or occur in clusters. [4]&lt;/li&gt;
&lt;li&gt;Brain imaging
AI can help in making diagnostic prediction of brain tumors, which are characterized by abnormal growth of brain tissue.&lt;/li&gt;
&lt;li&gt;Radiation oncology
Radiation treatment planning can be automated by segmenting tumours for radiation dose optimization. Furthermore, assessing response to treatment by monitoring over time is essential for evaluating the success of radiation therapy efforts. AI is able to perform these assessments, thereby improving accuracy and speed.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ai-in-clinical-decision-support&#34;&gt;AI in Clinical Decision Support&lt;/h2&gt;
&lt;p&gt;Other than analyzing radiology images, AI can also digest data from blood tests, electrocardiogram (EKG), genomics, and patient medical history do give a better treatment to the patient. AI-enabled clinical decision support includes diagnosis and prognosis, and involves classification or regression algorithms that can predict the probability of a medical outcome or the risk for a certain disease.[5]
Here are some examples of how AI helps clinical decision [6]:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Accumulation of medical histories from birth alongside linked maternal electronic health record (HER) information in a healthcare facility, enabled the prediction of high obesity risk children as early as two years after birth, possibly allowing life-altering preventative interventions.&lt;/li&gt;
&lt;li&gt;The Advanced Alert Monitoring system developed and deployed by Kaiser Permanente uses Intensive Care Unit (ICU) data to predict fatally deteriorating cases and alert staff to the need of life-saving interventions.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-313/broken/assignment5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-313/broken/assignment5/</guid>
      <description>
        
        
        &lt;h1 id=&#34;homework-5&#34;&gt;Homework 5&lt;/h1&gt;
&lt;h2 id=&#34;student-name-fauzan-isnaini&#34;&gt;Student Name: Fauzan Isnaini&lt;/h2&gt;
&lt;h1 id=&#34;predicting-stock-market-recovery-in-indonesia-after-covid-19-crash&#34;&gt;Predicting Stock Market Recovery in Indonesia after COVID-19 Crash&lt;/h1&gt;
&lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt;
&lt;p&gt;I will conduct this study by myself.&lt;/p&gt;
&lt;h2 id=&#34;topic&#34;&gt;Topic&lt;/h2&gt;
&lt;p&gt;The COVID-19 Pandemic is not just a crisis in the public health sector.
It also impacts unemployment rates, business revenues, and mass
psychology, which in the end lead to crashes in global stock markets.
While some stock indexes like the Dow Jones Industrial Average (DJIA)
and NASDAQ Composite already recovered, the Indonesian Stock Market
Index (IDX Composite) is still far below its price before the pandemic.
Some of the possible causes are: 1. Foreign investments represent about
50% of the total fund in the IDX stock exchange. In a pandemic
situation, foreign investors might choose to withdraw their stocks and
find another safer country to invest in. 2. Unpredictability of the
pandemic situation drives investors to reallocate their funds in safer
assets, such as cash, gold, or USD. 3. Changes in the macroeconomic
situation, such as unemployment rate, Indonesian Rupiah (IDR) exchange
rate, and interest rate. 4. Changes in the consumer buying power also
change the business revenues, thus changing fundamental data. 5. Mass
psychology of investors that the stock market is not safe in this
pandemic situation, holding them from returning to the stock market To
predict the time needed for IDX Composite to recover, there are two
indicators that can be utilized: 1. Fundamental indicators, which
represent the financial aspect. This can be in the form of macroeconomic
data and a company financial report 2. Technical indicators, which
represent the mass psychology of investors. This can be obtained from
news, social media, or statistical analysis of how the stock market
moves&lt;/p&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;In predicting the outcome, I will utilize these datasets: 1. Yahoo
Finance (finance.yahoo.com). Yahoo Finance contains a lot of both
fundamental and technical data, and they are free of charge. 2. Twitter
(twitter.com). I can conduct a content analysis on Twitter to represent
the mass psychology regarding the economic condition in Indonesia 3.
News channel. I can also utilize data crawler software to conduct
content analysis to compare positive and negative news in Indonesia. 4.
Third party stock data feeder. There are some third parties who provide
more comprehensive stock data on a subscription basis. This is another
option if the above datasets are not sufficient&lt;/p&gt;
&lt;h2 id=&#34;what-needs-to-be-done-to-get-a-great-grade&#34;&gt;What needs to be done to get a great grade&lt;/h2&gt;
&lt;p&gt;I will build a Python program to learn these data and generate a
prediction on when the IDX Composite will recover. I will also consider
the recovery rate of each of these sectors: 1. Mining 2. Agriculture 3.
Finance 4. Infrastructure 5. Miscellaneous Industries 6. Consumers&amp;rsquo;
Goods 7. Property 8. Trading 9. Basic Industry While they are
incorporated in the IDX Composite, the recovery rate of each sector may
be different because of their respective nature of the industry. For
example, consumer&amp;rsquo;s goods may be impacted less in this COVID-19
pandemic, thus resulting in a faster recovery. On the other hand, the
property sector might be the most impacted sector in this pandemic, thus
resulting in a long time to recover. The program will be able to learn
continuously, so if new data is available, it can renew the analysis and
give a more accurate prediction.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-313/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-313/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;predicting-stock-market-recovery-after-pandemic&#34;&gt;Predicting Stock Market Recovery After Pandemic&lt;/h1&gt;
&lt;p&gt;Fauzan Isnaini, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-313/&#34;&gt;fa20-523-313&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-313/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Predicting the stock market is a complex task with lots of different variables comes into play. While it is difficult to predict the short-term volatility, there are several approaches to forecast the stock market in the long term.  In this paper, we will analyze multiple methods to forecast the Indonesian Stock Exchange (IDX) recovery after the Covid-19 pandemic. The forecast will be based on technical analysis, fundamental analysis, and sentiment analysis.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#21-predicting-long-term-stock-price-movement-using-the-random-forest-algorithm&#34;&gt;2.1 Predicting Long Term Stock Price Movement using the Random Forest Algorithm&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#22-predicting-the-next-recession-using-long-short-term-memory-lstm-algorithm&#34;&gt;2.2 Predicting the Next Recession using Long Short-term Memory (LSTM) Algorithm&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#23-stock-market-prediction-using-text-mining&#34;&gt;2.3 Stock Market Prediction Using Text Mining&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-choice-of-data-sets&#34;&gt;3. Choice of Data-sets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-methodology&#34;&gt;4. Methodology&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-inference&#34;&gt;5. Inference&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-conclusion&#34;&gt;6. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#8-references&#34;&gt;8. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; stock, market, predictive analytics, LSTM, random forest, regression, fundamental analysis, technical analysis, sentiment analysis, pandemic&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;The COVID-19 Pandemic is not just a crisis in the public health sector. It also impacts unemployment rates, business revenues, and mass psychology, which in the end lead to crashes in global stock markets. While some stock indexes like the Dow Jones Industrial Average (DJIA) and NASDAQ Composite have already recovered, the Indonesian Stock Market Index (IDX Composite) is still far below its price before the pandemic.
Some of the possible causes are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Foreign investments represent about 50% of the total fund in the IDX stock exchange. In a pandemic situation, foreign investors might choose to withdraw their stocks and find another safer country to invest in.&lt;/li&gt;
&lt;li&gt;Unpredictability of the pandemic situation drives investors to reallocate their funds in safer assets, such as cash, gold, or USD.&lt;/li&gt;
&lt;li&gt;Changes in the macroeconomic situation, such as unemployment rate, Indonesian Rupiah (IDR) exchange rate, and interest rate.&lt;/li&gt;
&lt;li&gt;Changes in the consumer buying power also change the business revenues, thus changing fundamental data.&lt;/li&gt;
&lt;li&gt;Mass psychology of investors that the stock market is not safe in this pandemic situation, holding them from returning to the stock market&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To predict the time needed for IDX Composite to recover, two indicators can be utilized:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fundamental indicators, which represent the financial aspect. This can be in the form of macroeconomic data and a company financial report&lt;/li&gt;
&lt;li&gt;Technical indicators, which represent the mass psychology of investors. This can be obtained from statistical analysis of how the stock market moves&lt;/li&gt;
&lt;li&gt;Sentiment analysis, which represents the mass psychology of Indonesian people. This can be obtained from Twitter and Google Trends&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/h2&gt;
&lt;p&gt;Predicting the stock market offers great profit, thus it is a widely popular research area. While there is no specific paper addressing how to predict market recovery, there are some researches related to this area that can be utilized in this study.&lt;/p&gt;
&lt;h3 id=&#34;21-predicting-long-term-stock-price-movement-using-the-random-forest-algorithm&#34;&gt;2.1 Predicting Long Term Stock Price Movement using the Random Forest Algorithm&lt;/h3&gt;
&lt;p&gt;Milosevic &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; uses some machine learning algorithms to predict whether some companyâ€™s value will be 10% higher or not over the period of one year. He evaluated the companiesâ€™ financial indicators and found out that the Random Forest algorithm can get 0.765 precision, which is an amazing performance in the stock market.&lt;/p&gt;
&lt;h3 id=&#34;22-predicting-the-next-recession-using-long-short-term-memory-lstm-algorithm&#34;&gt;2.2 Predicting the Next Recession using Long Short-term Memory (LSTM) Algorithm&lt;/h3&gt;
&lt;p&gt;Another long term prediction in this area is from Khedkar &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. He used LSTM in predicting the next recession in India. In this study, the stock closing price data is used, instead of financial data â€“ which is technical analysis. LSTM networks are well-suited to classifying, processing, and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series. The study managed to predict the stock market crash in 2020.&lt;/p&gt;
&lt;h3 id=&#34;23-stock-market-prediction-using-text-mining&#34;&gt;2.3 Stock Market Prediction Using Text Mining&lt;/h3&gt;
&lt;p&gt;Text mining usually accompanies the technical analysis method. We can conduct sentiment analysis on news and social media to predict whether the stock market goes up or down. Sentiments on Twitter usually indicate market volatility and volume, while sentiments on news are a better predictor of stock movement [4].&lt;/p&gt;
&lt;h2 id=&#34;3-choice-of-data-sets&#34;&gt;3. Choice of Data-sets&lt;/h2&gt;
&lt;p&gt;In predicting the outcome, these datasets will be utilized:
Yahoo Finance (finance.yahoo.com). Yahoo Finance contains a lot of both fundamental and technical data, and they are free of charge.
Twitter (twitter.com). Sentiment analysis on Twitter will be conducted to represent the mass psychology regarding the economic condition in Indonesia&lt;/p&gt;
&lt;h2 id=&#34;4-methodology&#34;&gt;4. Methodology&lt;/h2&gt;
&lt;p&gt;In this study, we will predict market movement in the next two years using two approaches, which are the fundamental approach, and technical approach accompanied by sentiment analysis. The fundamental approach will utilize the random forest algorithm, while the technical approach will utilize the bidirectional gated recurrent unit (BGRU), which is considered a variant of LSTM. In the second approach, we will use news from Twitter&amp;rsquo;s official accounts and historical stock prices to predict the market.&lt;/p&gt;
&lt;h2 id=&#34;5-inference&#34;&gt;5. Inference&lt;/h2&gt;
&lt;p&gt;This section will be addressed upon project completion.&lt;/p&gt;
&lt;h2 id=&#34;6-conclusion&#34;&gt;6. Conclusion&lt;/h2&gt;
&lt;p&gt;This section will be addressed upon project completion.&lt;/p&gt;
&lt;h2 id=&#34;7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/h2&gt;
&lt;p&gt;The author would like to thank Dr. Geoffrey Fox, Dr. Gregor Von Laszewski, and the associate instructors in the FA20-BL-ENGR-E534-11530: Big Data Applications course (offered in the Fall 2020 semester at Indiana University, Bloomington) for their continued assistance and suggestions concerning exploring this idea and also for their aid with preparing the various drafts of this article.&lt;/p&gt;
&lt;h2 id=&#34;8-references&#34;&gt;8. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;N. Milosevic, â€œEquity forecast: Predicting long term stock price movement using machine learning,â€ 2018. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;S. Khedkar, â€œStock Market Prediction Using Deep Learning and Python,â€ Medium, 27-Sep-2019. [Online]. Available: &lt;a href=&#34;https://medium.com/analytics-vidhya/stock-market-prediction-using-python-article-4-the-next-recession-923185a2736f&#34;&gt;https://medium.com/analytics-vidhya/stock-market-prediction-using-python-article-4-the-next-recession-923185a2736f&lt;/a&gt;. [Accessed: 20-Oct-2020]. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-313/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-313/test/</guid>
      <description>
        
        
        &lt;h2 id=&#34;this-is-testmd&#34;&gt;This is Test.md&lt;/h2&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-314/assignment_6/assignment_6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-314/assignment_6/assignment_6/</guid>
      <description>
        
        
        &lt;h1 id=&#34;artificial-intelligence-in-health&#34;&gt;Artificial Intelligence in Health&lt;/h1&gt;
&lt;p&gt;Artificial Intelligence has influenced most of the sectors in the world like health, agriculture, sports and so much more. In the last decade, one of the most influenced sector is healthcare. In the beginning, AI was considered only a technology to help in the medical decision-making. Little were we aware that it will bring a tremendous transition in the healthcare industry. From simple decision-making, it advanced to autonomous surgical robots, image diagnosis, virtual nursing assistants etc. Most of the websites/apps are now offering symptom checkers which enable the patients to reduce the number of hospital visits drastically.&lt;/p&gt;
&lt;h2 id=&#34;ai-in-cancer-prognosis-and-diagnosis&#34;&gt;AI in Cancer Prognosis and Diagnosis&lt;/h2&gt;
&lt;p&gt;Chronic health conditions like cancer, diabetics, heart diseases etc. are mostly benefited from artificial intelligence as shown in Figure 1.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-314/blob/master/assignment_6/images/ai_1.jpg&#34; alt=&#34;Figure 1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Chronic health conditions that benefit most from AI/ML&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Cancer is an aggressive disease with high mortality rate. But if the disease is diagnosed in early stages some of the cancers like lung cancer, breast cancer, thyroid cancer etc can be cured or controlled. A decade ago, doctors spent hours just for diagnosing cancer but still lacked accuracy. Now with the introduction of AI, the time for diagnosis has reduced considerably with much more precision.&lt;/p&gt;
&lt;p&gt;AI model can be trained with vast amount of image data from tests like Ultrasound scanning, sonography, Endoscopy etc. Integrative processing and extraction  of these images will result in more efficient diagnosis. A set of computer algorithms used to process medical images and extract details are refered to as DL. It can be used to inform doctors on prognosis, molecular status or treatment sensitivity.&lt;/p&gt;
&lt;p&gt;Integration of AI technology in cancer care has increased the survival rate of patients. Research is being conducted on introducing AI to provide a customized care to people according to their genes and history.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.healthcareitnews.com/news/3-charts-show-where-artificial-intelligence-making-impact-healthcare-right-now&#34;&gt;https://www.healthcareitnews.com/news/3-charts-show-where-artificial-intelligence-making-impact-healthcare-right-now&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-314/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-314/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;residential-power-usage-prediction&#34;&gt;Residential Power Usage Prediction&lt;/h1&gt;
&lt;p&gt;Siny P Raphel, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-314/&#34;&gt;fa20-523-314&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-314/blob/master/project/project.md&#34;&gt;sinypr@gmail.com&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;To be added&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#datasets&#34;&gt;Datasets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#planning&#34;&gt;Planning&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#reason-to-choose-this-dataset&#34;&gt;Reason to choose this dataset&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Electricity is an inevitable part of our day today life. Most of the electric service providers like duke, dominion provide customers their consumption data so that customers are aware of their usages. Some providers give predictions on their future usages so that they are prepared.&lt;/p&gt;
&lt;p&gt;This project is based on the dataset Residential Power Usage 3 years data in Kaggle datasets&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. The dataset contains data of hourly power consumption of a 2 storied house in Houston,Texas from 01-06-2016 to August 2020. It includes data during the Covid-19 lockdown and are marked as well. We are planning to build a model to predict future usage from available data.&lt;/p&gt;
&lt;h2 id=&#34;datasets&#34;&gt;Datasets&lt;/h2&gt;
&lt;p&gt;Data is spread across two csv files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;power_usage_2016_to_2020.csv&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This file contains basic details of the data like startdate with hour, value of power consumption in kwh, day of the week and notes. It has 4 features and 35953 instances.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-314/blob/master/project/images/fig-1.png&#34; alt=&#34;Figure 1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; First five rows of power_usage_2016_to_2020 data&lt;/p&gt;
&lt;p&gt;Day of the week is an integer value with 0 being Monday. Notes gives us details like whether that day is weekend, weekday, covid lockdown or vacation. The Figure 1 shows retrieval and first few rows of the data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-314/blob/master/project/images/fig-2.png&#34; alt=&#34;Figure 2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; Details in &amp;ldquo;notes&amp;rdquo; column&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;weather_2016_2020_daily.csv&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This file contains the weather conditions of that particular day. It has 19 features and 1553 instances. Figure 3 shows retrieval and first few rows and columns of this file.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-314/blob/master/project/images/fig-3.png&#34; alt=&#34;Figure 3&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; First few rows of weather_2016_2020_daily data&lt;/p&gt;
&lt;p&gt;Units of features are given as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Temperature    - F deg&lt;/li&gt;
&lt;li&gt;Dew Point      - F deg&lt;/li&gt;
&lt;li&gt;Humidity       - %age&lt;/li&gt;
&lt;li&gt;Wind           - mph&lt;/li&gt;
&lt;li&gt;Pressure       - Hg&lt;/li&gt;
&lt;li&gt;Precipitation  â€“ inch&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;planning&#34;&gt;Planning&lt;/h2&gt;
&lt;p&gt;We will be using python to develop the model. Since the expected outputs are real numbers(power consumption in kWh) we might be using linear regression or similar ones. We will try using gradient descent for optimization. Since the weather data has 19 features we might use feature selection methods to select best features that increase the accuracy of the model.
The data spread across two files will have to be merged according to date. For that the StartDate feature will have to be first split to date and time. Then the two datasets will have to be merged according to the date only. From the initial inspection of the data, the date feature of datasets have some date format issues which will have to be resolved before starting cleaning.&lt;/p&gt;
&lt;p&gt;In this project we will be planning the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Analyze and clean the data&lt;/li&gt;
&lt;li&gt;Visualize the data- study the relationships between features etc.&lt;/li&gt;
&lt;li&gt;Plan one or two algorithms that can be used to model&lt;/li&gt;
&lt;li&gt;Optimize or feature selection of features&lt;/li&gt;
&lt;li&gt;Calculate accuracy of each model&lt;/li&gt;
&lt;li&gt;Conclusion on which algorithm will be best suited to use and the reason for it.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;reason-to-choose-this-dataset&#34;&gt;Reason to choose this dataset&lt;/h2&gt;
&lt;p&gt;This dataset is chosen because,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There were datasets similar to this one. But this one has latest power usage data till August this year.&lt;/li&gt;
&lt;li&gt;It has marked covid lockdown, vacations, weekdays and weekends which is a challenge for prediction.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/srinuti/residential-power-usage-3years-data-timeseries&#34;&gt;https://www.kaggle.com/srinuti/residential-power-usage-3years-data-timeseries&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-314/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-314/test/</guid>
      <description>
        
        
        &lt;h1 id=&#34;this-is-to-test-markdown&#34;&gt;This is to test markdown&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;bullet&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-315/assignment6/assignment-6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-315/assignment6/assignment-6/</guid>
      <description>
        
        
        &lt;p&gt;Sunny Xu&lt;/p&gt;
&lt;p&gt;Geoffrey Fox&lt;/p&gt;
&lt;p&gt;INFO-I423, Section 11530&lt;/p&gt;
&lt;p&gt;October 20, 2020&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                            Assignment 6
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The topic I chose regarding artificial intelligence in Health and Medicine is artificial intelligence medical devices. In recent years, with the advancement of science and technology, there have been many successful cases of artificial intelligence in the medical and health field. More and more hospitals have also begun testing and using artificial intelligence medical devices. The popularity of artificial intelligence has also greatly facilitated and improved human life. Even though artificial intelligence brings great convenience to people&amp;rsquo;s lives, many people are still struggling with the question of whether such artificial intelligence brings people good or bad.&lt;/p&gt;
&lt;p&gt;The benefits of artificial intelligence medical devices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Drug development
&lt;ul&gt;
&lt;li&gt;The development of drugs has always been a big problem for scientists. Many times the success rate is too low, causing people to spend a lot of money but get nothing. Artificial intelligence has played a great role in this regard. It can quickly discover the effects of drugs and accurately predict the safety and side effects of drugs. In this way, artificial intelligence has made great progress in drug research for many diseases that have not been breakthroughs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Diagnosis of disease
&lt;ul&gt;
&lt;li&gt;In diagnosing disease conditions, humans have been transmitting various disease conditions and data to artificial intelligence, which also makes a large amount of information in the artificial intelligence database. Usually, doctors make their own judgments by understanding the condition, but sometimes there are cases of wrong judgments. At this time, artificial intelligence will be more accurate and precise in the diagnosis of the disease than human beings. Artificial intelligence has been instilled with data on various conditions and changes in the human body when it is being developed so that they can analyze the conditions through machine learning and make their judgments more accurate than normal people.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adjuvant therapy process
&lt;ul&gt;
&lt;li&gt;Artificial intelligence technology is also used to assist clinical doctors and nurses. In many cases, they can effectively help doctors to determine and formulate appropriate treatment plans and drug use. For the adjuvant therapy process, the best example is the application of IBM Watson in tumor research. Watson provided decision-making after learning many studies in the oncology treatment plan. Although it was not perfect yet, it was very useful for the medical team studying at the time.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Arrange health management
&lt;ul&gt;
&lt;li&gt;Artificial intelligence can form health management that is most suitable for the user through the data from the user&amp;rsquo;s mobile phone. At the same time, through the current advanced technology, many smartphones already have a certain judgment on the heartbeat and the length of time they look at the phone and the user&amp;rsquo;s physical habits. In this way, artificial intelligence can give users a healthy diet plan through the judgment of data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Internet medical consultation
&lt;ul&gt;
&lt;li&gt;In recent years, the place where artificial intelligence has been used most is the intelligent answering system to users on various websites. In many cases, it is not an easy task for people to contact their family doctor or a nearby hospital when they want. In this case, if there is something unexpected, people don&amp;rsquo;t know how to deal with it. At this time, artificial intelligence also reflects its convenience and usefulness. They can use some keywords in people&amp;rsquo;s questions to judge the knowledge points people want to know in order to answer people&amp;rsquo;s questions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Biomedical Research
&lt;ul&gt;
&lt;li&gt;For medical research, artificial intelligence has also contributed a lot of important knowledge points. The artificial intelligence system can tell scientists important points and establish many hypotheses by reading various research articles. At the same time, scientists can also use artificial intelligence to test the possibilities of various hypotheses. In this way, the research of scientists will become much more convenient.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The disadvantages of artificial intelligence medical devices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Although artificial intelligence brings various conveniences to human beings, it still has some potential and needs to be improved. For example, some artificial intelligence ventilators, so far, artificial intelligence ventilators cannot fully sense people&amp;rsquo;s breathing. Therefore, there will be a situation that when the person has regained the ability to breathe, the ventilator does not accurately sense it, and thus continues to provide breathing to the patient. Such a situation may be fatal. There are also some artificial intelligence. When they absorb information and data, there will be some studies that have not been 100% confirmed, and they may be absorbed by artificial intelligence. Such misinformation may also lead to artificial intelligence&amp;rsquo;s misjudgment of the condition, leading to the misdiagnosis of the patient.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In general, artificial intelligence medical devices have both good and bad aspects. In the future, if artificial intelligence will be better improved and improved, its impact on medicine will become greater and greater. In this way, people will be better diagnosed and treated. When using artificial intelligence, it can also reduce people&amp;rsquo;s medical expenses, so that people can be treated.&lt;/p&gt;
&lt;p&gt;Reference:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Johner, Christian. &amp;ldquo;Artificial Intelligence in Medical Devices.&amp;rdquo; Johner Institut, 1 Feb. 2019, &lt;a href=&#34;http://www.johner-institute.com/articles/software-iec-62304/and-more/artificial-intelligence/&#34;&gt;www.johner-institute.com/articles/software-iec-62304/and-more/artificial-intelligence/&lt;/a&gt;. Accessed 20 Oct. 2020.&lt;/li&gt;
&lt;li&gt;Suarez, Anna. &amp;ldquo;How IBM Watson Is Revolutionizing Cancer Research.&amp;rdquo; Healthcare Technology, 14 Aug. 2018, &lt;a href=&#34;http://www.healthtechzone.com/topics/healthcare/articles/2018/08/14/439124-how-ibm-watson-revolutionizing-cancer-research.htm&#34;&gt;www.healthtechzone.com/topics/healthcare/articles/2018/08/14/439124-how-ibm-watson-revolutionizing-cancer-research.htm&lt;/a&gt;. Accessed 20 Oct. 2020.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-315/report/project-plan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-315/report/project-plan/</guid>
      <description>
        
        
        &lt;p&gt;Team member: Peiran Zhao, Sunny Xu, Kris Zhang&lt;/p&gt;
&lt;p&gt;Geoffrey Fox&lt;/p&gt;
&lt;p&gt;INFO-I423, Section 11530&lt;/p&gt;
&lt;p&gt;October 09, 2020&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                            **Project Plan**
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;Team&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;We are a three members team all having informatics majors.&lt;/li&gt;
&lt;li&gt;Peiran Zhao:
&lt;ul&gt;
&lt;li&gt;I am currently a senior with an informatics major and a game design minor. I have a great interest in big data and deep learning, I think it is going to be a field with great potential and lots of opportunities.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sunny Xu:
&lt;ul&gt;
&lt;li&gt;I am a senior majoring in Informatics and having a cognate which is Computer Art. I have three dogs, they are all Pomeranian. I usually like to walk the dog, listen to music, and play computer games.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Kris Zhang:
&lt;ul&gt;
&lt;li&gt;I am a senior student who is majoring in Informatics with a cognate of game design. My hobbies are playing video games and having fun with my friends when I have free time. I believe that technology can change the lifestyle of people and society, thatâ€™s why I think this class is important.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Topic&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Gesture recognition and machine learning.&lt;/li&gt;
&lt;li&gt;Machine learning and especially deep learning has been really hot these years. With the help of technology, our lives are more and convenient and much easier than before. In this way, machine learning and deep learning has been a really hot topic and is undoubtedly our future. Gesture Recognition is also very trendy and has been working on for many years. However, it is not even close to its peak. And because gesture recognition is so useful in all fields, we are thinking about doing projects on this topic. We are going to cover some major features of gesture recognition as our research goes on. In this way, we are going to do lots of research on this area and use the dataset we get from online resources to demonstrate the effectiveness and efficiency of gesture recognition.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Dataset&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;We are planning to search and collect some datasets on the website.&lt;/li&gt;
&lt;li&gt;Our current dataset is directly coming from IBM Research and it is a really trustworthy dataset website. We are planning on using this dataset for our gesture recognition project. However, it is possible that we might change our mind as our project goes through. In that case, if the dataset we plan on using right is not working the best with our project, we will find some other related dataset later.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;What needs to be done to get a great grade&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;We need to unite and cooperate friendly.&lt;/li&gt;
&lt;li&gt;We set up a chatting room for us to chat with each other, therefore if there is any problem that one of us wants to discuss with, we get the chat room to communicate with the team.&lt;/li&gt;
&lt;li&gt;We set up a google drive folder that is shared with the whole team. In this way, we can do the work together and check each otherâ€™s works.&lt;/li&gt;
&lt;li&gt;If a team member has any questions or comments on the team or project, he or she should say that out honestly.&lt;/li&gt;
&lt;li&gt;All team members should do some research and share it with everyone.&lt;/li&gt;
&lt;li&gt;We need to set up a specific meeting time every week in order for all the people in our group to not fall behind.&lt;/li&gt;
&lt;li&gt;We need to check the rubric as we move on and make sure that we meet all the requirements for the project.&lt;/li&gt;
&lt;li&gt;Go to office hours for the class and check with the AI and professor about our project details to ensure that everything is running smoothly.&lt;/li&gt;
&lt;li&gt;We can check other team membersâ€™ works and correct them if any of us find out the problem with it. In this way, we can also know what we get wrong and how we can make it better.&lt;/li&gt;
&lt;li&gt;We will need to practice the ability to use Github and open resources programs since we donâ€™t have much past experience of it.&lt;/li&gt;
&lt;li&gt;We will follow directions on the rubric about writing project reports with the IEEE format, this is something we havenâ€™t tried before, but we will try our best to make sure we are doing it correctly.&lt;/li&gt;
&lt;li&gt;Processing data is also a sort of new field for all of us, but we are going to do lots of research, and watching some tutorials online to get the result we want.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-315/report/report/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-315/report/report/</guid>
      <description>
        
        
        &lt;h1 id=&#34;big-data-on-gesture-recognition-and-machine-learning&#34;&gt;Big Data on Gesture Recognition and Machine Learning&lt;/h1&gt;
&lt;p&gt;Sunny Xu, Peiran Zhao, Kris Zhang, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-315/&#34;&gt;fa20-523-315&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-315/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Since our technology is more and more advanced as time goes by, traditional human-computer interaction has become increasingly difficult to meet people&amp;rsquo;s demands. In this digital era, people need faster and more efficient methods to obtain information and data. Traditional and single input and output devices are not fast and convenient enough, it also requires users to learn their own methods of use, which is extremely inefficient and completely a waste of time. Therefore, artificial intelligence comes out, and its rise has followed the changeover times, and it satisfied people&amp;rsquo;s needs. At the same time, gesture is one of the most important way for human to deliver information. It is simple, efficient, convenient, and universally acceptable. Therefore, gesture recognition has become an emerging field in intelligent human-computer interaction field, with great potential and future.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-background&#34;&gt;2. Background&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-gesture-recognition&#34;&gt;3. Gesture recognition&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-conclusion&#34;&gt;4. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#plan&#34;&gt;Plan&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-references&#34;&gt;5. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; gesture recognition, human, technology, future&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;As of today, since technology is improving so fast, there are many things that can be related to AI and machine learning. Hand gestures will be one of the most important ways to understand people. As we often notice, when people are doing speech, they often use hand gestures to collaborate with their words. And studying hand gestures will often reveal what the people who are giving the speech are thinking about. For example, when someone is lying, they tend to touch their nose with their hand, etc. So studying hand gestures will not only help people understand much more about human beings and it can also help our technology grow. For example, in AI and machine learning. Studying hand gestures will make or improve AI and machine learning to better understand humans and be more human-like.&lt;/p&gt;
&lt;h2 id=&#34;2-background&#34;&gt;2. Background&lt;/h2&gt;
&lt;p&gt;Nowadays, people are doing more and more research on high-tech, which also makes various high-tech products appear in the society. For people, electricity is as important as water and air. It is impossible to imagine a life without electricity. We can realize that technology is changing everything about people from various aspects. People living in this high-tech era are also forced to learn and understand the usage of various high-tech products. As a representative of high technology, artificial intelligence has also attracted a lot of attention in society. Because of the emergence of artificial intelligence, people have also begun to realize that preserving the characteristics of the people is also a very important point in high technology. Therefore, scientists thought of gestures, one of the most commonly used body language.&lt;/p&gt;
&lt;h2 id=&#34;3-gesture-recognition&#34;&gt;3. Gesture recognition&lt;/h2&gt;
&lt;p&gt;Gesture recognition is mainly divided into two categories, one is based on external device recognition, the specific application is data gloves, wearing it on user&amp;rsquo;s hand, to obtain and analysis information through sensors. This method has obvious shortcomings, though it is accurate and has excellent response speed, but it is costly and is not good for large-scale promotion. The other one is the use of computer vision. People do not need to wear gloves. As its name implies, this method collects and analyzes information through a computer. It is convenient, comfortable, and not so limited based on external device identification. In contrast, it has greater potential and is more in line with the trend of the times. Of course, this method needs more effective and accurate algorithms to support, because the gestures made by different people at different times, in different environments and at different angles also represent different meanings. So, if we want more accurate information feedback. Then the advancement of algorithms and technology is inevitable. The development of gesture recognition is also the development of artificial intelligence, a process of the development of various algorithms from data gloves to the development of computer vision-based optical technology plays a role in promoting it.&lt;/p&gt;
&lt;h2 id=&#34;4-conclusion&#34;&gt;4. Conclusion&lt;/h2&gt;
&lt;p&gt;This section will be addressed upon project completion.&lt;/p&gt;
&lt;h2 id=&#34;plan&#34;&gt;Plan&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Introduction: Kris&lt;/li&gt;
&lt;li&gt;Background: Sunny&lt;/li&gt;
&lt;li&gt;Gesture: divided into several parts and each works at one part&lt;/li&gt;
&lt;li&gt;Conclusion: Peiran&lt;/li&gt;
&lt;li&gt;catch up to do more on the report&lt;/li&gt;
&lt;li&gt;each of us should do more research and put more time to the project&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-references&#34;&gt;5. References&lt;/h2&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-316/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-316/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;sentiment-analysis-and-visualization-using-an-us-election-dataset-for-the-2020-election&#34;&gt;Sentiment Analysis and Visualization using an US-election dataset for the 2020 Election&lt;/h1&gt;
&lt;p&gt;Sudheer Alluri, Indiana University, fa20-523-316, &lt;a href=&#34;mailto:ngsudheer@gmail.com&#34;&gt;ngsudheer@gmail.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vishwanadham Mandala, Indiana University, fa20-523-325, &lt;a href=&#34;mailto:vishwandh.mandala@gmail.com&#34;&gt;vishwandh.mandala@gmail.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-316/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Sentiment analysis is an evaluation of the opinion of the speaker, writer or other subject with regard to some topic.We are going to use US-elections dataset and combining the tweets of people opninon for leading presidential candidates. We have various datasets from kallage and combining tweets and NY times datasets, by combining all data predication will be dervied.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-datasets&#34;&gt;2. DataSets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-methodologyprocess&#34;&gt;3. Methodology/Process&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-technologies-used&#34;&gt;4. Technologies used&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-plan-for-the-rest-of-the-semseter&#34;&gt;5. Plan for the rest of the Semseter&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-refernces&#34;&gt;6. Refernces&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; sentiment,  US-election&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;For our final project, we will be focusing on the upcoming U.S. presidential elections. We plan to use a US-elections dataset to predict the votes each contestant will attain, by area. With growing data, the prediction will be changing constantly. We are making the difference by selecting the latest dataset available and previous election data to predict the number of votes each contestant will get to the closest figure. A feature we are introducing to enhance the quality is predicting various area types like counties, towns, and/or big cities.
One might argue that these kinds of predictions will only be helping organizations and not individuals. We assure you that this project will be helping the general public in many ways. The most evident being, an individual knowing which contestant his/her community or the general public around him/her prefer. This project is strictly statistical and does not have a goal to sway the elections in any way or to pressure an individual&lt;/p&gt;
&lt;p&gt;into picking a candidate. Overall, this is just a small step towards a future that might hold an environment where the next president of the United States of America could be accurately guessed based on previous data and innovative Big Data Technologies.&lt;/p&gt;
&lt;h2 id=&#34;2-datasets&#34;&gt;2. DataSets&lt;/h2&gt;
&lt;p&gt;We will be going to use the dataset, &lt;a href=&#34;https://www.kaggle.com/tunguz/us-elections-dataset,&#34;&gt;https://www.kaggle.com/tunguz/us-elections-dataset,&lt;/a&gt; and we will create the filets based on location. If needed, we may download Twitter data from posts on and by Donald Trump, Joe Biden, and their associates. Which leads us to our objective for the project, based on the data we collected, we should be able to predict the winner of the 2020 United States of Americaâ€™s presidential elections.&lt;/p&gt;
&lt;p&gt;All of the data will be location-based and if required we will download realtime campaigning and debate analysis data, giving us a live and updated prediction every time increment. To strengthen the prediction, even more, we may reuse some code from the 2016 electionâ€™s analysis, however, our main focus will be using the latest data we readily acquire during the time leading up to the 2020 election.
In conclusion, to make our predictions as realistic and as strong as we can get, we will be going to choose multiple data sets to integrate between the previous election and twitter data to predict the number of votes each candidate will acquire. Therefore, we will be predicting the winner of the 2020 presidential elections.&lt;/p&gt;
&lt;h2 id=&#34;3-methodologyprocess&#34;&gt;3. Methodology/Process&lt;/h2&gt;
&lt;p&gt;Our project has two main sections of data sets in it. The first and primary one containing candidate information and previous presidential election data and the second containing twitter data. We believed the second needed more time because the first dataset contained straightforward facts while the twitter dataset is more susceptible to different perspectives and viewpoints.
In this project we are analyzing twitter data of key presidential candidates and other key supporters.We gathered the data from kaggle datasets. Data is mainly divided into 3 sub categories. Tweets made by key personnel.Twitter profiles of the two candidates(all info including followers, following, # of tweets,etc.).The final category involves graphs for visualization purposes.A problem with twitter data is the fact that it is huge. We are using google drive and with it comes the problem of storage. To combat this we are only using 4 twitter data sets. The datasets of Donald J. Trump, Joe Biden, Kamala Harris, and Mike Pence. We also downloaded these data sets to use them locally.There are mainly 3 types of formats used in everyday twitter use: images, text, and video. Only text will be used in this project because the others are not useful for the purpose of the
experiment. Our project mostly uses twitter data as support to the primary dataset.It is there to strengthen the already predicted result. The reason why we cannot make the twitter data set our primary data set is because the data(tweets) are mostly opinion based with only some exceptions. So we cannot predict with the twitter data,however, it
can be used to show public support which will be vital in supporting the prediction derived from the primary data set.So, we found many twitter data sets on keggle and used certain parts from each to make our final four. The difference between the background sets and our final four datasets is the fact that their primary dataset was the twitter data while we used twitter data as our secondary dataset. We realized that twitter data is best used as secondary data that supports the primary dataset, which is more fact based.We can use three of the four OSoMe tools available: trends, networking, and maps. Trends and networking can be combined to find a group that involves every user that is taking part in the elections in some way. Mapping can show these users and their location. Giving us the area based result that we seek. However this method is already a part of our project .Due to the fact that all this data is in keggle in a wider array. Which gave us the option to condense into four large data sets.&lt;/p&gt;
&lt;p&gt;We will collect election data and twitter information and integrate both to predict the results. A lot of twitter or dataset data will be trimmed and parsed to build the model. We will calculate
Our data-gathering and preparation methodology is composed of the following steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use the latest election dataset-2020, we will be creating the model.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Data cleaning and extraction.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We will try to download the latest data from twitter and campaigning.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4-technologies-used&#34;&gt;4. Technologies used&lt;/h2&gt;
&lt;p&gt;Python, Jupyter notebook or collab, Pandas, Scikit-learn, PyTorch&lt;/p&gt;
&lt;h2 id=&#34;5-plan-for-the-rest-of-the-semseter&#34;&gt;5. Plan for the rest of the Semseter&lt;/h2&gt;
&lt;p&gt;October 26:
. Furthur looking into new datasets and getting new twitter data.
. Brainstrom ideas for future engineering and build features
. update the report.&lt;/p&gt;
&lt;p&gt;November 2:
. Working on creating function to download the content. Remove the spaces in the project.&lt;/p&gt;
&lt;p&gt;November 9:
TBD&lt;/p&gt;
&lt;p&gt;November 16:
TBD&lt;/p&gt;
&lt;h2 id=&#34;6-refernces&#34;&gt;6. Refernces&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/kerneler/starter-2020-united-states-e6a4facf-a&#34;&gt;https://www.kaggle.com/kerneler/starter-2020-united-states-e6a4facf-a&lt;/a&gt;
&lt;a href=&#34;https://www.kaggle.com/radustoicescu/2020-united-states-presidential-election/notebooks&#34;&gt;https://www.kaggle.com/radustoicescu/2020-united-states-presidential-election/notebooks&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
