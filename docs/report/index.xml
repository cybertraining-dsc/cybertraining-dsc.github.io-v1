<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cybertraining â€“ Report</title>
    <link>/report/</link>
    <description>Recent content in Report on Cybertraining</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/report/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/cloudmesh/openapi/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/cloudmesh/openapi/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;openapi-function-generator&#34;&gt;Openapi Function generator&lt;/h1&gt;
&lt;h2 id=&#34;activity-log&#34;&gt;Activity Log&lt;/h2&gt;
&lt;h2 id=&#34;week-of-mar-9---mar-16&#34;&gt;Week of Mar 9 - Mar 16&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Andrew Goldfarb&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Worked with Ishan and Jonathan to finalize the start stop
functionality.&lt;/li&gt;
&lt;li&gt;Added functionality to delete the process entry from the
registry upon stop command.&lt;/li&gt;
&lt;li&gt;Debugged weird start error for my personal machine where the
start functionality was running two bash terminals causing the
start function to fail.&lt;/li&gt;
&lt;li&gt;Met with Professor to discuss proper implementation of the
start/stop and how to tie into registry functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;week-prior-to-mar-9th&#34;&gt;Week prior to Mar 9th&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;bkgerreis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Jonathan Beckford&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prateek&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Andrew Goldfarb&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Edited the stop function to take process PID and use os.kill to
stop the process based on the name of the python file. However,
according to Ishan this is still not working.&lt;/li&gt;
&lt;li&gt;Resolved conflicts between master and our working branch&lt;/li&gt;
&lt;li&gt;Began work on assigning a default name if the user does not provide
one for server start. Potetially, a function to assign an alias
name to the whole process to amke it easier to reference.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;install-for-development&#34;&gt;Install for development&lt;/h2&gt;
&lt;p&gt;cloudmesh-installer git pull analytics&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd cloudmesh-openapi
pip install -e .
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;keep-up-to-date&#34;&gt;Keep up to date&lt;/h2&gt;
&lt;p&gt;explain how to set up and use upstream sync&lt;/p&gt;
&lt;h3 id=&#34;project-meeting&#34;&gt;Project Meeting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://iu.zoom.us/rec/share/4dIpJZ-p8ztIHpH_q1HAZ6wzL6iiaaa8h3QX8_YMzRkn8tBfY_mRIe8z3j-3cZ_9?startTime=1581987567000&#34;&gt;Mon 17 Feb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://iu.zoom.us/rec/share/_8ZLKK7Z6zpLb53f73_UW4EFBY_iX6a8gydM_vVbzRu2MhrC_sUCKhChUkLzgEK8?startTime=1582591839000&#34;&gt;Mon 24 Feb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;basic-function-generator&#34;&gt;Basic Function Generator&lt;/h3&gt;
&lt;h4 id=&#34;prateek-shaw----code-link&#34;&gt;Prateek Shaw -  code link.&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-229/tree/master/cloudmesh-openapi&#34;&gt;https://github.com/cloudmesh-community/sp20-516-229/tree/master/cloudmesh-openapi&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;created a basic function that will return the OpenAPI YAML file
of given python function including parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sp20-516-237----jonathan-beckford&#34;&gt;SP20-516-237 &amp;ndash; Jonathan Beckford&lt;/h4&gt;
&lt;p&gt;I created a class that generates the OpenAPI yaml file. I also created
a sample program that defines an example function, instantiates my
OpenAPI generator class and passes in the sample function as input. I
figured this would make things really easy to just paste any new
sample function for testing purposes. I also included the parameters
as was requested. I also ran my output yaml through the swagger
validator (&lt;a href=&#34;https://editor.swagger.io/&#34;&gt;https://editor.swagger.io/&lt;/a&gt;) to make sure it was compliant
and it was.&lt;br&gt;
&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-237/tree/master/projectAI/generateOpenAPI&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;sp20-516-231---brian-kegerreis&#34;&gt;sp20-516-231 - Brian Kegerreis&lt;/h4&gt;
&lt;p&gt;I created a function to generate an OpenAPI spec including a rough
attempt at response types (only supports text/plain media types at
this point)
&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-231/blob/master/openapi-exercises/example_echo.py&#34;&gt;https://github.com/cloudmesh-community/sp20-516-231/blob/master/openapi-exercises/example_echo.py&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;server-start&#34;&gt;Server Start&lt;/h3&gt;
&lt;h4 id=&#34;andrew-goldfarb---sp20-516-234&#34;&gt;Andrew Goldfarb - SP20-516-234&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-234/tree/open-api-exercise/openAPI&#34;&gt;https://github.com/cloudmesh-community/sp20-516-234/tree/open-api-exercise/openAPI&lt;/a&gt;
I have created a basic function that returns the IP address of the
server running the function to tell if it is running on the device
itself or connected to the internet running while running the
function.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/cloudmesh/openapi/scikitlearn/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/cloudmesh/openapi/scikitlearn/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;sklearngeneratorfile-high-level-overview&#34;&gt;SKlearnGeneratorFile High level Overview&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The SklearnGeneratorFile.py is the generator function which outputs the python file for given
Sckit-learn Library.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The function takes two inputs&lt;/p&gt;
&lt;p&gt;1.input_sklibrary&lt;/p&gt;
&lt;p&gt;2.model_tag&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Examples of the inputs are&lt;/p&gt;
&lt;p&gt;input_sklibrary = sklearn.linear_model.LinearRegression(Full model specification)
model_tag = any name which you want the tag the model instance like LinReg1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This Version of Scikit-learn service accepts csv files in UTF-8 format only.It is the user responsibility to make
sure the files are in UTF-8 format.It is the user responsibility to split the data in to train and test datasets.
Split data functionality is not currently supported.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;scikit-learn uses numpydoc format in the docstring so the scraping of the parameters and docstrings
are done using docscrape from numpydoc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;All the templates used in the code are based on X and y inputs scikit-learn takes and also based on the
return type&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pytests-for-scikit-learn-tests&#34;&gt;Pytests for Scikit learn tests.&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The below pytest generates the .py file used by generator to do a OPENAPI specification.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/tests/Scikitlearn-tests/test_06c_sklearngeneratortest.py&#34;&gt;Pytestcode&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt; pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/Scikitlearn_tests/test_06c_sklearngeneratortest.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The below pytest tests the methods generated .&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/tests/Scikitlearn-tests/test_06d_sklearngeneratortest.py&#34;&gt;Pytestcode&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/Scikitlearn_tests/test_06d_sklearngeneratortest.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/deprecated/openapi/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/deprecated/openapi/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;openapi-function-generator&#34;&gt;Openapi Function generator&lt;/h1&gt;
&lt;h2 id=&#34;activity-log&#34;&gt;Activity Log&lt;/h2&gt;
&lt;h2 id=&#34;week-of-mar-9---mar-16&#34;&gt;Week of Mar 9 - Mar 16&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Andrew Goldfarb&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Worked with Ishan and Jonathan to finalize the start stop
functionality.&lt;/li&gt;
&lt;li&gt;Added functionality to delete the process entry from the
registry upon stop command.&lt;/li&gt;
&lt;li&gt;Debugged weird start error for my personal machine where the
start functionality was running two bash terminals causing the
start function to fail.&lt;/li&gt;
&lt;li&gt;Met with Professor to discuss proper implementation of the
start/stop and how to tie into registry functionality.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;week-prior-to-mar-9th&#34;&gt;Week prior to Mar 9th&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;bkgerreis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Jonathan Beckford&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prateek&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Andrew Goldfarb&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Edited the stop function to take process PID and use os.kill to
stop the process based on the name of the python file. However,
according to Ishan this is still not working.&lt;/li&gt;
&lt;li&gt;Resolved conflicts between master and our working branch&lt;/li&gt;
&lt;li&gt;Began work on assigning a default name if the user does not provide
one for server start. Potetially, a function to assign an alias
name to the whole process to amke it easier to reference.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;install-for-development&#34;&gt;Install for development&lt;/h2&gt;
&lt;p&gt;cloudmesh-installer git pull analytics&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd cloudmesh-openapi
pip install -e .
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;keep-up-to-date&#34;&gt;Keep up to date&lt;/h2&gt;
&lt;p&gt;explain how to set up and use upstream sync&lt;/p&gt;
&lt;h3 id=&#34;project-meeting&#34;&gt;Project Meeting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://iu.zoom.us/rec/share/4dIpJZ-p8ztIHpH_q1HAZ6wzL6iiaaa8h3QX8_YMzRkn8tBfY_mRIe8z3j-3cZ_9?startTime=1581987567000&#34;&gt;Mon 17 Feb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://iu.zoom.us/rec/share/_8ZLKK7Z6zpLb53f73_UW4EFBY_iX6a8gydM_vVbzRu2MhrC_sUCKhChUkLzgEK8?startTime=1582591839000&#34;&gt;Mon 24 Feb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;basic-function-generator&#34;&gt;Basic Function Generator&lt;/h3&gt;
&lt;h4 id=&#34;prateek-shaw----code-link&#34;&gt;Prateek Shaw -  code link.&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-229/tree/master/cloudmesh-openapi&#34;&gt;https://github.com/cloudmesh-community/sp20-516-229/tree/master/cloudmesh-openapi&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;created a basic function that will return the OpenAPI YAML file
of given python function including parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sp20-516-237----jonathan-beckford&#34;&gt;SP20-516-237 &amp;ndash; Jonathan Beckford&lt;/h4&gt;
&lt;p&gt;I created a class that generates the OpenAPI yaml file. I also created
a sample program that defines an example function, instantiates my
OpenAPI generator class and passes in the sample function as input. I
figured this would make things really easy to just paste any new
sample function for testing purposes. I also included the parameters
as was requested. I also ran my output yaml through the swagger
validator (&lt;a href=&#34;https://editor.swagger.io/&#34;&gt;https://editor.swagger.io/&lt;/a&gt;) to make sure it was compliant
and it was.
&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-237/tree/master/projectAI/generateOpenAPI&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;sp20-516-231---brian-kegerreis&#34;&gt;sp20-516-231 - Brian Kegerreis&lt;/h4&gt;
&lt;p&gt;I created a function to generate an OpenAPI spec including a rough
attempt at response types (only supports text/plain media types at
this point)
&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-231/blob/master/openapi-exercises/example_echo.py&#34;&gt;https://github.com/cloudmesh-community/sp20-516-231/blob/master/openapi-exercises/example_echo.py&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;server-start&#34;&gt;Server Start&lt;/h3&gt;
&lt;h4 id=&#34;andrew-goldfarb---sp20-516-234&#34;&gt;Andrew Goldfarb - SP20-516-234&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-234/tree/open-api-exercise/openAPI&#34;&gt;https://github.com/cloudmesh-community/sp20-516-234/tree/open-api-exercise/openAPI&lt;/a&gt;
I have created a basic function that returns the IP address of the
server running the function to tell if it is running on the device
itself or connected to the internet running while running the
function.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/docker/ubuntu19.10/todo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/docker/ubuntu19.10/todo/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;
&lt;p&gt;make clean: only delete the artifacts created here, the clean wipes
currently everything&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;when using this in consecutive order, would cms init not wipe out the data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;should we not mount the .cloudmesh and other data dire into the conatiner.
This way we can use the host system for developments. Maybe we need to&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;support both ways&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;leverage cmsd
we have told the class that we have cmsd taht starts up cloudmesh in
a container. Develop a new directory docker-cmsd and use that&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/docker/ubuntu20.04-sklearn/todo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/docker/ubuntu20.04-sklearn/todo/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;
&lt;p&gt;THIS IS JUST THE SKELETON AND HAS NOT BEEN RUN ONCE IT HAS BUGS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;THIS HAS NOT YET THE SKLERAN START STOP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;make clean: only delete the artifacts created here, the clean wipes
currently everything&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;when using this in consecutive order, would cms init not wipe out the data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;should we not mount the .cloudmesh and other data dire into the conatiner.
This way we can use the host system for developments. Maybe we need to&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;support both ways&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;leverage cmsd
we have told the class that we have cmsd taht starts up cloudmesh in
a container. Develop a new directory docker-cmsd and use that&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/docker/ubuntu20.04/todo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/docker/ubuntu20.04/todo/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;
&lt;p&gt;THIS IS JUST THE SKELETON AND HAS NOT BEEN RUN ONCE IT HAS BUGS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;make clean: only delete the artifacts created here, the clean wipes
currently everything&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;when using this in consecutive order, would cms init not wipe out the data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;should we not mount the .cloudmesh and other data dire into the conatiner.
This way we can use the host system for developments. Maybe we need to&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;support both ways&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;leverage cmsd
we have told the class that we have cmsd taht starts up cloudmesh in
a container. Develop a new directory docker-cmsd and use that&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/project_review/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/project_review/</guid>
      <description>
        
        
        &lt;h1 id=&#34;project-review&#34;&gt;Project Review&lt;/h1&gt;
&lt;h2 id=&#34;team-members&#34;&gt;Team members:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Jonathan Beckford&lt;/li&gt;
&lt;li&gt;Brian Kegerreis&lt;/li&gt;
&lt;li&gt;Prateek Shaw&lt;/li&gt;
&lt;li&gt;Jagadeesh Kandimalla&lt;/li&gt;
&lt;li&gt;Ishan Mishra&lt;/li&gt;
&lt;li&gt;Andrew G&lt;/li&gt;
&lt;li&gt;Falconi&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;project-documentation&#34;&gt;Project Documentation:&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-openapi/index.html&#34;&gt;https://cloudmesh.github.io/cloudmesh-openapi/index.html&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;contributors-based-on-git-tracking&#34;&gt;Contributors based on Git tracking&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;NOTE:&lt;/strong&gt;&lt;/em&gt; This is not completely accurate because some did not have git config done correctly.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/graphs/contributors&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/graphs/contributors&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-breakdown&#34;&gt;Code Breakdown&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;cms command:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/command/openapi.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/command/openapi.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; all team&lt;/p&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms generate - to generate server yaml&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;executor&lt;/strong&gt; that parses parameters and calls generator:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/function/executor.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/function/executor.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt;  Brian, Professor&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;generator&lt;/strong&gt; that generates the server yaml:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/function/generator.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/function/generator.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt;  Brian, Jonathan, Prateek&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms server - to start and stop server&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/function/server.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/function/server.py&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Contributors:&lt;/strong&gt;  Jonathan, Andrew, Prateek, Ishan&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms registry - register the server and cache model&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;registry&lt;/strong&gt; - registers server&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/registry/Registry.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/registry/Registry.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Falconi, Praful, Professor&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;cache&lt;/strong&gt; - cache serialized model locally&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/registry/cache.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/registry/cache.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Jonathan&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;fileoperation&lt;/strong&gt; - upload input files&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/registry/fileoperation.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/registry/fileoperation.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Prateek, Brian&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms scikitlearn - generate sklearn functions&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/scikitlearn/SklearnGeneratorFile.py&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/cloudmesh/openapi/scikitlearn/SklearnGeneratorFile.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Jagadeesh&lt;/p&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms image processing&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Falconi, Ishan&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cms text analysis&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contirbutor:&lt;/strong&gt; Andrew Goldfarb&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/tree/master/tests/generator-natural-lang&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/tree/master/tests/generator-natural-lang&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;deployment-steps&#34;&gt;Deployment steps&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-openapi/README.html#installation&#34;&gt;https://cloudmesh.github.io/cloudmesh-openapi/README.html#installation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-openapi/README.html#quick-steps-to-generate-start-and-stop-cpu-sample-example&#34;&gt;https://cloudmesh.github.io/cloudmesh-openapi/README.html#quick-steps-to-generate-start-and-stop-cpu-sample-example&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;pytests&#34;&gt;Pytests&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-openapi/README.html#pytests&#34;&gt;https://cloudmesh.github.io/cloudmesh-openapi/README.html#pytests&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Integration of openapi with cms allows for running locally only.  Cloud integration was not fully completed although team did create a way to setup openapi in a VM using a remote script for &lt;a href=&#34;https://github.com/cloudmesh/get/blob/master/openapi/ubuntu18.04/index.html&#34;&gt;openstack&lt;/a&gt; and &lt;a href=&#34;https://github.com/cloudmesh/get/blob/master/openapi/google/index.html&#34;&gt;google&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The generator only supports creating arrays of number data type.  This limitation is due to the bug documented below in &lt;em&gt;&lt;strong&gt;Bugs&lt;/strong&gt;&lt;/em&gt; section.  So manual changes are required to the output yaml to allow for other data types until another work around is found or the bug is resolved.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;bugs&#34;&gt;Bugs&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;reported a bug to Connexion and documented it in github for future reference:
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/issues/60&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/issues/60&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;additional-artifacts-produced&#34;&gt;Additional artifacts produced:&lt;/h2&gt;
&lt;h3 id=&#34;openstack-vm-set-up-script&#34;&gt;Openstack VM set up script&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/get/blob/master/openapi/ubuntu18.04/index.html&#34;&gt;OPENSTACK&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/get/blob/master/openapi/google/index.html&#34;&gt;GOOGLE&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Jonathan Beckford, Andrew Goldfarb&lt;/p&gt;
&lt;h3 id=&#34;openapi-project-readme-generator&#34;&gt;Openapi project readme generator&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/tree/master/sphinx&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/tree/master/sphinx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt; Jonathan Beckford, Professor&lt;/p&gt;
&lt;h3 id=&#34;chapters&#34;&gt;Chapters&lt;/h3&gt;
&lt;h5 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h5&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-231/blob/master/chapter/k8s-kubernetes-scheduler.md&#34;&gt;https://github.com/cloudmesh-community/sp20-516-231/blob/master/chapter/k8s-kubernetes-scheduler.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contributors:&lt;/strong&gt;  Jonathan Beckford, Brian Kegerreis, Ashok Singam&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/readme-scikitlearn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/readme-scikitlearn/</guid>
      <description>
        
        
        &lt;h1 id=&#34;cloudmesh-openapi-scikit-learn&#34;&gt;Cloudmesh OpenAPI Scikit-learn&lt;/h1&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We use recommend Python 3.8.2 Python or newer.&lt;/li&gt;
&lt;li&gt;We recommend pip version 20.0.2 or newer&lt;/li&gt;
&lt;li&gt;We recommend that you use a venv (see developer install)&lt;/li&gt;
&lt;li&gt;MongoDB installed as regular program not as service&lt;/li&gt;
&lt;li&gt;Please run cim init command to start mongodb server&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We have not checked if it works on older versions.&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;Make sure to follow the instruction for &lt;code&gt;cms openapi&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;When getting started using the &lt;code&gt;openapi&lt;/code&gt;, please first call &lt;code&gt;cms help openapi&lt;/code&gt; to see the available functions and options. For your
convenience we include the manual page later on in this document.&lt;/p&gt;
&lt;h2 id=&#34;scikit-learn-documentation&#34;&gt;Scikit-learn Documentation&lt;/h2&gt;
&lt;p&gt;Scikit-learn is a Machine learning library in Python.We can choose a
ML algorithm like LinearRegression and cloudmesh will be able to spin
up OPENAPI specification for the library we choose.  We can interact
with the Scikit-learn library using either CURL commands or through
GUI.&lt;/p&gt;
&lt;p&gt;This Version of Scikit-learn service accepts csv files in UTF-8 format
only.It is the user responsibility to make sure the files are in UTF-8
format.It is the user responsiblity to split the data in to train and
test datasets.  Split data functionality is not currently supported.&lt;/p&gt;
&lt;h3 id=&#34;setting-up-scikit-learn-service&#34;&gt;Setting up Scikit-learn service&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Please complete the basic installation of
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi&#34;&gt;cloudmesh-openapi&lt;/a&gt;,
To make set up easy the same steps are even referenced at the
Developer Installation section in the document.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can find Scikit-learn documentation in
&lt;a href=&#34;https://scikit-learn.org/dev/modules/classes.html&#34;&gt;Scikit-learn&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The following packages needs to be installed to access Scikit-learn&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;p&gt;pip install pandas
pip install Scikit-learn&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;./cloudmesh-openapi&lt;/code&gt; directory on your machine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Utilize the Scikit-learn generate command to create the python file
which will used to generate OpenAPI spec&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi sklearnreadfile sklearn.linear_model.LinearRegression Linregpytest
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sample generated file can be viewed at
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/tree/master/tests/generator&#34;&gt;tests/generator&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Utilize the generate command to generate OpenAPI spec with upload functionality enabled&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate --filename=./tests/generator/LinearRegression.py --all_functions --enable_upload
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the server after the yaml file is generated ot the same directory as the .py file&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server start ./tests/generator/LinearRegression.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Access the REST service using
&lt;a href=&#34;http://localhost:8080/cloudmesh/ui/&#34;&gt;http://localhost:8080/cloudmesh/ui/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to upload the
testfiles.&lt;/p&gt;
&lt;p&gt;Place your test files in
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/tree/master/tests/Scikitlearn-data&#34;&gt;Scikitlearn-data&lt;/a&gt;
We are testing with X_SAT.csv(SAT Scores of students),y_GPA(GPA of
students)&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST &amp;quot;http://localhost:8080/cloudmesh/upload&amp;quot; \
     -H &amp;quot;accept: text/plain&amp;quot; \
     -H &amp;quot;Content-Type: multipart/form-data&amp;quot; \
     -F &amp;quot;upload=@tests/Scikitlearn-data/X_SAT.csv;type=text/csv&amp;quot;


curl -X POST &amp;quot;http://localhost:8080/cloudmesh/upload&amp;quot; \
     -H &amp;quot;accept: text/plain&amp;quot; \
     -H &amp;quot;Content-Type: multipart/form-data&amp;quot; \
     -F &amp;quot;upload=@tests/Scikitlearn-data/y_GPA.csv;type=text/csv&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to verify fit
method in Scikit-learn using the uploaded files&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/LinearRegression_upload-enabled/fit?X=X_SAT&amp;amp;y=y_GPA&amp;quot; -H &amp;quot;accept: */*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to run the
Predict method.&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/LinearRegression_upload-enabled/predict?X=X_SAT&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to run the Score method.&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/LinearRegression_upload-enabled/score?X=X_SAT&amp;amp;y=y_GPA&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;   
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop the server&lt;/p&gt;
&lt;p&gt;.. code:: bash&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server stop LinearRegression
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;cloudmesh-openapi-service-generator&#34;&gt;Cloudmesh OpenAPI Service Generator&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The README.md page is outomatically generated, do not edit it.
To modify  change the content in
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/README-source.md&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/README-source.md&lt;/a&gt;
Curley brackets must use two in README-source.md&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/cloudmesh-openapi/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/cloudmesh-openapi.svg&#34; alt=&#34;image&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://pypi.python.org/pypi/cloudmesh-openapi&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/cloudmesh-openapi.svg&#34; alt=&#34;Python&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache%202.0-blue.svg&#34; alt=&#34;License&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://pypi.python.org/pypi/cloudmesh-openapi&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/format/cloudmesh-openapi.svg&#34; alt=&#34;Format&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://pypi.python.org/pypi/cloudmesh-openapi&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/status/cloudmesh-openapi.svg&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://travis-ci.com/cloudmesh/cloudmesh-openapi&#34;&gt;&lt;img src=&#34;https://travis-ci.com/cloudmesh/cloudmesh-openapi.svg?branch=master&#34; alt=&#34;Travis&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;We recommend Python 3.8.2 Python or newer.&lt;/li&gt;
&lt;li&gt;We recommend pip version 20.0.2 or newer&lt;/li&gt;
&lt;li&gt;We recommend that you use a venv (see developer install)&lt;/li&gt;
&lt;li&gt;MongoDB installed as regular program not as service, which can
easily be done with cloudmesh on macOS, Linux, and Windows.&lt;/li&gt;
&lt;li&gt;Please run &lt;code&gt;cms gui quick&lt;/code&gt; to initialize the password for the mongodb
server&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: On windows you can use &lt;a href=&#34;https://gitforwindows.org/&#34;&gt;gitbash&lt;/a&gt;
so you can use bash and can use the same commands as on Linux or
macOS. Otherwise, please use the appropriate backslashes to access
the path.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;The installation is rather simple  and is documented next.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python -m venv ~/ENV3
source ~/ENV3/bin/activate 
mkdir cm
cd cm
pip install cloudmesh-installer
cloudmesh-installer get openapi 
cms help
cms gui quick
# fill out mongo variables
# make sure autinstall is True
cms config set cloudmesh.data.mongo.MONGO_AUTOINSTALL=True
cms admin mongo install --force
# Restart a new terminal to make sure mongod is in your path
cms init
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you like to know more about the installation of cloudmesh, please
visit the &lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/installation/install.html&#34;&gt;Cloudmesh
Manual&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;command-overview&#34;&gt;Command Overview&lt;/h2&gt;
&lt;p&gt;When getting started using cloudmes &lt;code&gt;openapi&lt;/code&gt;, please first call to
get familiar with the options you have:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms help openapi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We include the manual page later on in this document.&lt;/p&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;Next we provide a very simple quickstart guide to steps to generate a
simple microservice that returns the CPU information of your computer.
We demonstrate how to generate, start, and stop the servive.&lt;/p&gt;
&lt;p&gt;Navigate to &lt;code&gt;~/cm/cloudmesh-openapi&lt;/code&gt; folder. In this folder you will
have a file called &lt;code&gt;cpu.py&lt;/code&gt; from which we will generate the server.&lt;/p&gt;
&lt;p&gt;First, generate an OpenAPI YAML file with the convenient command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate get_processor_name \
    --filename=./tests/server-cpu/cpu.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will create the file &lt;code&gt;cpu.yaml&lt;/code&gt; that contains the OpenAPI
specification. To start the service from this specification simply use
the command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server start ./tests/server-cpu/cpu.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now that the service is up and running, you can issue a request for
example via the commandline with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/get_processor_name&amp;quot; \
     -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To view the automatically generated documentation, you can go to your
browser and open the link&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:8080/cloudmesh/ui&#34;&gt;http://localhost:8080/cloudmesh/ui&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;images/openapi-ui.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;You can also look at the status of the server with the command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server list
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;images/openapi-info.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once yo no longer need the service, you can stop it with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server stop cpu
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;quickstart-to-creating-your-own-microservice&#34;&gt;Quickstart to Creating your own Microservice&lt;/h2&gt;
&lt;p&gt;Cloudmesh uses introspection to generate an OpenAPI compliant YAML
specification that will allow your Python code to run as a web
service. For this reason, any code you write must conform to a set of
guidelines.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The parameters and return values of any functions you write must use
python typing&lt;/li&gt;
&lt;li&gt;Your functions must include docstrings&lt;/li&gt;
&lt;li&gt;If a function uses or returns a class, that class must be defined as
a dataclass in the same file&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next we demonstrate how to create your own microservice.
We provide two examples. One in which we return a float,
te other one in which the return value is wrapped in a
json object.&lt;/p&gt;
&lt;h3 id=&#34;returning-a-float&#34;&gt;Returning a Float&lt;/h3&gt;
&lt;p&gt;We define a function that adds tow values.  Note how x,
y, and the return value are all typed. In this case they are all
&lt;code&gt;float&lt;/code&gt;, but other types are supported. The description in the
docstring will be added to your YAML specification to help describe
what the function does.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def add(x: float, y: float) -&amp;gt; float:
    &amp;quot;&amp;quot;&amp;quot;
    adding float and float.
    :param x: x value
    :type x: float
    :param y: y value
    :type y: float
    :return: result
    :return type: float
    &amp;quot;&amp;quot;&amp;quot;
    result = x + y

    return result
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To generate, start, retrieve a result, and stop the service you can use the
following command sequence:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate add --filename=./tests/add-float/add.py
cms openapi server start ./tests/add-float/add.yaml 
curl -X GET &amp;quot;http://localhost:8080/cloudmesh/add?x=1&amp;amp;y=2&amp;quot; -H  &amp;quot;accept: text/plain&amp;quot;
# This command returns
&amp;gt; 3.0
cms openapi server stop add
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;returning-a-json-object&#34;&gt;Returning a Json Object&lt;/h3&gt;
&lt;p&gt;Often we like to wrap the return value into a json string object, which can easily be
done by modifying the previous example as showcased next.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from flask import jsonify

def add(x: float, y: float) -&amp;gt; str:
    &amp;quot;&amp;quot;&amp;quot;
    adding float and float.
    :param x: x value
    :type x: float
    :param y: y value
    :type y: float
    :return: result
    :return type: float
    &amp;quot;&amp;quot;&amp;quot;
    result = {&amp;quot;result&amp;quot;: x + y}

    return jsonify(result)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To generate, start, retrieve a result, and stop the service you can use the
following command sequence:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate add --filename=./tests/add-json/add.py
cms openapi server start ./tests/add-json/add.yaml 
curl -X GET &amp;quot;http://localhost:8080/cloudmesh/add?x=1&amp;amp;y=2&amp;quot; -H  &amp;quot;accept: text/plain&amp;quot;
# This command returns
&amp;gt; {&amp;quot;result&amp;quot;:3.0}
cms openapi server stop add
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As usual in both cases the web browser can be used to inspect the documentation as well as to test running the
example, by filling out the form.&lt;/p&gt;
&lt;h2 id=&#34;details-of-the-cms-openapi-command&#34;&gt;Details of the &lt;code&gt;cms openapi&lt;/code&gt; command&lt;/h2&gt;
&lt;p&gt;The gaol as stated earlier is to transform a simple python function as a service&lt;/p&gt;
&lt;h3 id=&#34;generating-openapi-specification&#34;&gt;Generating OpenAPI specification&lt;/h3&gt;
&lt;p&gt;Once you have a Python function you would like to deploy as a web
service, you can generate the OpenAPI specification. Navigate to your
.py file&amp;rsquo;s directory and generate the YAML. This will print
information to your console about the YAML file that was generated.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate [function_name] --filename=[filename.py]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you would like to include more than one function in your web
service, like addition and subtraction, use the &lt;code&gt;--all_functions&lt;/code&gt;
flag. This will ignore functions whose names start with &amp;lsquo;_&amp;rsquo;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate --filename=[filename.py] --all_functions
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can even write a class like Calculator that contains functions for
addition, subtraction, etc. You can generate a specification for an
entire class by using the &lt;code&gt;--import_class&lt;/code&gt; flag.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate [ClassName] --filename=[filename.py] --import_class
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;starting-a-server&#34;&gt;Starting a server&lt;/h3&gt;
&lt;p&gt;Once you have generated a specification, you can start the web service
on your localhost by providing the path to the YAML file. This will
print information to your console about the server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server start ./[filename.yaml]

  Starting: [server name]
  PID:      [PID]
  Spec:     ./[filename.py]
  URL:      http://localhost:8080/cloudmesh
  Cloudmesh UI:      http://localhost:8080/cloudmesh/ui
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;sending-requests-to-the-server&#34;&gt;Sending requests to the server&lt;/h3&gt;
&lt;p&gt;Now you have two options to interact with the web service. The first
is to navigate the the Cloudmesh UI and click on each endpoint to test
the functionality. The second is to use curl commands to submit
requests.&lt;/p&gt;
&lt;p&gt;We have already shown you earlier in our quickstart how to apply this to a
service such as our add service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ curl -X GET &amp;quot;http://localhost:8080/cloudmesh/add?x=1.2&amp;amp;y=1.5&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&amp;gt;   2.7
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;stopping-the-server&#34;&gt;Stopping the server&lt;/h3&gt;
&lt;p&gt;Now you can stop the server using the name of the server. If you
forgot the name, use &lt;code&gt;cms openapi server ps&lt;/code&gt; to get a list of server
processes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cms openapi server stop [server name]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;basic-auth&#34;&gt;Basic Auth&lt;/h3&gt;
&lt;p&gt;To use basic http authentication with a user password for the
generated API, add the following flag at the end of a &lt;code&gt;cms openapi generate&lt;/code&gt; command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--basic_auth=&amp;lt;username&amp;gt;:&amp;lt;password&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We plan on supporting more security features in the future. Example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate get_processor_name \
    --filename=./tests/server-cpu/cpu.py \
    --basic_auth=admin:secret
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;manual-page&#34;&gt;Manual Page&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;openapi generate [FUNCTION] --filename=FILENAME
                         [--serverurl=SERVERURL]
                         [--yamlfile=YAML]
                         [--import_class]
                         [--all_functions]
                         [--enable_upload]
                         [--verbose]
                         [--basic_auth=CREDENTIALS]
openapi server start YAML [NAME]
              [--directory=DIRECTORY]
              [--port=PORT]
              [--server=SERVER]
              [--host=HOST]
              [--verbose]
              [--debug]
              [--fg]
              [--os]
openapi server stop NAME
openapi server list [NAME] [--output=OUTPUT]
openapi server ps [NAME] [--output=OUTPUT]
openapi register add NAME ENDPOINT
openapi register filename NAME
openapi register delete NAME
openapi register list [NAME] [--output=OUTPUT]
openapi TODO merge [SERVICES...] [--dir=DIR] [--verbose]
openapi TODO doc FILE --format=(txt|md)[--indent=INDENT]
openapi TODO doc [SERVICES...] [--dir=DIR]
openapi sklearn FUNCTION MODELTAG
openapi sklearnreadfile FUNCTION MODELTAG
openapi sklearn upload --filename=FILENAME

Arguments:
  FUNCTION  The name for the function or class
  MODELTAG  The arbirtary name choosen by the user to store the Sklearn trained model as Pickle object
  FILENAME  Path to python file containing the function or class
  SERVERURL OpenAPI server URL Default: https://localhost:8080/cloudmesh
  YAML      Path to yaml file that will contain OpenAPI spec. Default: FILENAME with .py replaced by .yaml
  DIR       The directory of the specifications
  FILE      The specification

Options:
  --import_class         FUNCTION is a required class name instead of an optional function name
  --all_functions        Generate OpenAPI spec for all functions in FILENAME
  --debug                Use the server in debug mode
  --verbose              Specifies to run in debug mode
                         [default: False]
  --port=PORT            The port for the server [default: 8080]
  --directory=DIRECTORY  The directory in which the server is run
  --server=SERVER        The server [default: flask]
  --output=OUTPUT        The outputformat, table, csv, yaml, json
                         [default: table]
  --srcdir=SRCDIR        The directory of the specifications
  --destdir=DESTDIR      The directory where the generated code
                         is placed

Description:
This command does some useful things.

openapi TODO doc FILE --format=(txt|md|rst) [--indent=INDENT]
    Sometimes it is useful to generate teh openaopi documentation
    in another format. We provide fucntionality to generate the
    documentation from the yaml file in a different formt.

openapi TODO doc --format=(txt|md|rst) [SERVICES...]
    Creates a short documentation from services registered in the
    registry.

openapi TODO merge [SERVICES...] [--dir=DIR] [--verbose]
    Merges tow service specifications into a single servoce
    TODO: do we have a prototype of this?


openapi sklearn sklearn.linear_model.LogisticRegression
    Generates the .py file for the Model given for the generator

openapi sklearnreadfile sklearn.linear_model.LogisticRegression
Generates the .py file for the Model given for the generator which supports reading files

openapi generate [FUNCTION] --filename=FILENAME
                             [--serverurl=SERVERURL]
                             [--yamlfile=YAML]
                             [--import_class]
                             [--all_functions]
                             [--enable_upload]
                             [--verbose]
                             [--basic_auth=CREDENTIALS]
    Generates an OpenAPI specification for FUNCTION in FILENAME and
    writes the result to YAML. Use --import_class to import a class
    with its associated class methods, or use --all_functions to 
    import all functions in FILENAME. These options ignore functions
    whose names start with &#39;_&#39;. Use --enable_upload to add file
    upload functionality to a copy of your python file and the
    resulting yaml file.

    For optional basic authorization, we support (temporarily) a single user
    credential. CREDENTIALS should be formatted as follows:

    user:password

    Example: --basic_auth=admin:secret

openapi server start YAML [NAME]
                  [--directory=DIRECTORY]
                  [--port=PORT]
                  [--server=SERVER]
                  [--host=HOST]
                  [--verbose]
                  [--debug]
                  [--fg]
                  [--os]
    starts an openapi web service using YAML as a specification
    TODO: directory is hard coded as None, and in server.py it
      defaults to the directory where the yaml file lives. Can
      we just remove this argument?

openapi server stop NAME
    stops the openapi service with the given name
    TODO: where does this command has to be started from

openapi server list [NAME] [--output=OUTPUT]
    Provides a list of all OpenAPI services in the registry

openapi server ps [NAME] [--output=OUTPUT]
    list the running openapi service

openapi register add NAME ENDPOINT
    Openapi comes with a service registry in which we can register
    openapi services.

openapi register filename NAME
    In case you have a yaml file the openapi service can also be
    registerd from a yaml file

openapi register delete NAME
    Deletes the names service from the registry

openapi register list [NAME] [--output=OUTPUT]
    Provides a list of all registerd OpenAPI services
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;basic-examples&#34;&gt;Basic Examples&lt;/h2&gt;
&lt;p&gt;Please follow &lt;a href=&#34;tests/README.md&#34;&gt;Pytest Information&lt;/a&gt; document for
pytests related information&lt;/p&gt;
&lt;p&gt;We have included a significant number of tests that aso serve as examples&lt;/p&gt;
&lt;h3 id=&#34;example-one-function-in-a-python-file&#34;&gt;Example: One function in a python file&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Please check &lt;a href=&#34;tests/server-cpu/cpu.py&#34;&gt;Python file&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run below command to generate yaml file and start server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate get_processor_name --filename=./tests/server-cpu/cpu.py
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;example-multiple-functions-in-python-file&#34;&gt;Example: Multiple functions in python file&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Please check &lt;a href=&#34;tests/generator-calculator/calculator.py&#34;&gt;Python file&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run below command to generate yaml file and start server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate --filename=./tests/generator-calculator/calculator.py --all_functions
cms openapi generate server start ./tests/generator-calculator/calculator.py
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;example-functions-in-python-class-file&#34;&gt;Example: Function(s) in python class file&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Please check &lt;a href=&#34;tests/generator-testclass/calculator.py&#34;&gt;Python file&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run below command to generate yaml file and start server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate Calculator \
    --filename=./tests/generator-testclass/calculator.py \
    --import_class&amp;quot;
cms openapi server start ./tests/generator-testclass/calculator.yaml
curl -X GET &amp;quot;http://localhost:8080/cloudmesh/Calculator/multiplyint?x=1&amp;amp;y=5&amp;quot;
cms openapi server stop Calculator
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;example-uploading-data&#34;&gt;Example: Uploading data&lt;/h3&gt;
&lt;p&gt;Code to handle uploads is located in
&lt;code&gt;cloudmesh-openapi/tests/generator-upload&lt;/code&gt;. The code snippet in
uploadexample.py and the specification in uploadexample.yaml can be
added to existing projects by adding the &lt;code&gt;--enable_upload&lt;/code&gt; flag to the
&lt;code&gt;cms openapi generate&lt;/code&gt; command. The web service will be able to
retrieve the uploaded file from &lt;code&gt;~/.cloudmesh/upload-file/&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;upload-example&#34;&gt;Upload example&lt;/h4&gt;
&lt;p&gt;This example shows how to upload a CSV file and how the web service
can retrieve it.&lt;/p&gt;
&lt;p&gt;First, generate the OpenAPI specification and start the server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate print_csv2np \
    --filename=./tests/generator-upload/csv_reader.py \
    --enable_upload
cms openapi server start ./tests/generator-upload/csv_reader.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, navigate to localhost:8080/cloudmesh/ui. Click to open
the /upload endpoint, then click &amp;lsquo;Try it out.&amp;rsquo; Click to choose a file
to upload, then upload &lt;code&gt;tests/generator-upload/np_test.csv&lt;/code&gt;. Click
&amp;lsquo;Execute&amp;rsquo; to complete the upload.&lt;/p&gt;
&lt;p&gt;The uploaded file will be located at
&lt;code&gt;~/.cloudmesh/upload-file/[filename]&lt;/code&gt;. The file
&lt;code&gt;tests/generator-upload/csv_reader.py&lt;/code&gt; contains some example code to
retrieve the array in the uploaded file. To see this in action, click
to open the /print_csv2np endpoint, then click &amp;lsquo;Try it out.&amp;rsquo; Enter
&amp;ldquo;np_test.csv&amp;rdquo; in the field that prompts for a filename, and then click
Execute to view the numpy array defined by the CSV file.&lt;/p&gt;
&lt;h3 id=&#34;example-pipeline-anova-svm-example&#34;&gt;Example: Pipeline Anova SVM Example&lt;/h3&gt;
&lt;p&gt;This example is based on the sklearn example
&lt;a href=&#34;https://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection_pipeline.html#sphx-glr-auto-examples-feature-selection-plot-feature-selection-pipeline-py&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In this example, we will upload a data set to the server, tell the
server to train the model, and utilize said model for predictions.&lt;/p&gt;
&lt;p&gt;Firstly, ensure we are in the correct directory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pwd
~/cm/cloudmesh-openapi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let us generate the yaml file from our python file to generate the proper specs for our service.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cms openapi generate PipelineAnovaSVM \
      --filename=./tests/Scikitlearn-experimental/sklearn_svm.py \
      --import_class --enable_upload
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now let us start the server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cms openapi server start ./tests/Scikitlearn-experimental/sklearn_svm.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The server should now be active. Navigate to
&lt;code&gt;http://localhost:8080/cloudmesh/ui&lt;/code&gt;. We now have a nice user inteface
to interact with our newly generated API. Let us upload the data
set. We are going to use the iris data set in this example. We have
provided it for you to use. Simply navigate to the &lt;code&gt;/upload&lt;/code&gt; endpoint
by clicking on it, then click &lt;code&gt;Try it out&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We can now upload the file. Click on &lt;code&gt;Choose File&lt;/code&gt; and upload the data
set located at &lt;code&gt;~./tests/Scikitlearn-experimental/iris.data&lt;/code&gt;.  Simply
hit &lt;code&gt;Execute&lt;/code&gt; after the file is uploaded. We should then get a return
code of 200 (telling us that everything went ok).&lt;/p&gt;
&lt;p&gt;The server now has our dataset. Let us now navigate to the &lt;code&gt;/train&lt;/code&gt;
endpoint by, again, clicking on it. Similarly, click &lt;code&gt;Try it out&lt;/code&gt;.
The parameter being asked for is the filename. The filename we are
interested in is &lt;code&gt;iris.data&lt;/code&gt;. Then click &lt;code&gt;execute&lt;/code&gt;.  We should get
another 200 return code with a Classification Report in the Response
Body.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-CLASSIFICATION_REPORT:&#34; data-lang=&#34;CLASSIFICATION_REPORT:&#34;&gt;
           0       1.00      1.00      1.00         8
           1       0.85      1.00      0.92        11
           2       1.00      0.89      0.94        19

    accuracy                           0.95        38
   macro avg       0.95      0.96      0.95        38
weighted avg       0.96      0.95      0.95        38
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Our model is now trained and stored on the server. Let us make a
prediction now. As we have done, navigate to the &lt;code&gt;/make_prediction&lt;/code&gt;
endpoint.  The information we need to provide is the name of the model
we have trained as well as some test data. The name of the model will
be the same as the name of the data-file (ie. iris). So type in &lt;code&gt;iris&lt;/code&gt;
into the &lt;code&gt;model_name&lt;/code&gt; field. Finally for params, let us use the
example &lt;code&gt;5.1, 3.5, 1.4, 0.2&lt;/code&gt; as the model expects 4 values
(attributes). After clicking execute, we should received a response
with the classification the model has made given the parameters.&lt;/p&gt;
&lt;p&gt;The response received should be as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;Classification: [&#39;Iris-setosa&#39;]&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can make as many predictions as we like. When finished, we can shut down the server.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cms openapi server stop sklearn_svm
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;example-to-run-ai-services-in-the-cloud&#34;&gt;Example to Run AI Services in the Cloud&lt;/h2&gt;
&lt;h3 id=&#34;google&#34;&gt;Google&lt;/h3&gt;
&lt;p&gt;After you create your google cloud account, it is recommended to
download and install Google&amp;rsquo;s &lt;a href=&#34;https://cloud.google.com/sdk/docs/quickstarts&#34;&gt;Cloud
SDK&lt;/a&gt;.  This will
enable CLI. Make sure you enable all the required services.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcloud services enable servicemanagement.googleapis.com
gcloud services enable endpoints.googleapis.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and any other services you might be using for your specific Cloud API
function.&lt;/p&gt;
&lt;p&gt;To begin using the tests for any of the Google Cloud Platform AI
services you must first set up a Google account (set up a free tier
account): &lt;a href=&#34;https://cloud.google.com/billing/docs/how-to/manage-billing-account&#34;&gt;Google Account
Setup&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;After you create your google cloud account, it is recommended to
download and install Google&amp;rsquo;s &lt;a href=&#34;https://cloud.google.com/sdk/docs/quickstarts&#34;&gt;Cloud
SDK&lt;/a&gt;.  This will
enable CLI. Make sure you enable all the required services.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcloud services enable servicemanagement.googleapis.com
gcloud services enable servicecontrol.googleapis.com
gcloud services enable endpoints.googleapis.com
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and any other services you might be using for your specific Cloud API
function.&lt;/p&gt;
&lt;p&gt;It is also required to install the cloudmesh-cloud package, if not
already installed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cloudmesh-installer get cloud
cloudmesh-installer install cloud
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will allow you automatically fill out the cloudmesh yaml file
with your credentials once you generate the servcie account JSON file.&lt;/p&gt;
&lt;p&gt;After you have verified your account is created you must then give your account access to the proper APIs and create a
project in the Google Cloud Platform(GCP) console.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Go to the &lt;a href=&#34;console.cloud.google.com/projectselector2/home/&#34;&gt;project
selector&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow directions from Google to create a project linked to your
account&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;quickstart-google-python-api&#34;&gt;Quickstart Google Python API&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;For quickstart in using Google API for Python visit &lt;a href=&#34;https://developers.google.com/docs/api/quickstart/python&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;setting-up-your-google-account&#34;&gt;Setting up your Google account&lt;/h3&gt;
&lt;p&gt;Before you generate the service account JSON file for your account you
will want to enable a number of services in the GCP console.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google Compute&lt;/li&gt;
&lt;li&gt;Billing&lt;/li&gt;
&lt;li&gt;Cloud Natural Language API&lt;/li&gt;
&lt;li&gt;Translate API&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;To do this you will need to click the menu icon in the Dashboard
navigation bar. Ensure you are in the correct porject.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once that menu is open hover over the &amp;ldquo;APIs and Services&amp;rdquo; menu item
and click on &amp;ldquo;Dashboard&amp;rdquo; in the submenu.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At the dashboard click on the &amp;ldquo;+ Enable APIs and Services&amp;rdquo; button
at the top of the dashboard&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Search for &lt;strong&gt;cloud natural language&lt;/strong&gt; to find the API in the search
results and click the result&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once the page opens click &amp;ldquo;Enable&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do the same for the &lt;strong&gt;translate&lt;/strong&gt; API to enable that as well&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do the same for the &lt;strong&gt;compute engine API&lt;/strong&gt; to enable that as well&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You must now properly set up the account roles to ensure you will have
access to the API. Follow the directions from Google to &lt;a href=&#34;https://cloud.google.com/natural-language/docs/setup#auth&#34;&gt;set up proper
authentication&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Make you account an owner for each of the APIs in the IAM tool as
directed in the authentication steps for the natural language API.
This makes your service account have proper access to the required
APIs and once the private key is downloaded those will be stored
there.&lt;/p&gt;
&lt;p&gt;It is VERY important that you create a service account and download
the private key as described in the directions from Google.  If you do
not the cms google commands will not work properly.&lt;/p&gt;
&lt;p&gt;Once you have properly set up your permissions please make sure you
download your JSON private key for the service account that has
permissions set up for the required API services. These steps to
download are found
&lt;a href=&#34;https://cloud.google.com/natural-language/docs/setup#sa-create&#34;&gt;here&lt;/a&gt;.
Please take note of where you store the downloaded JSON and copy the
path string to a easily accessible location.&lt;/p&gt;
&lt;p&gt;The client libraries for each API are included in teh requirements.txt file for the openapi proejct and should be isntalled when the
package is installed. If not, follow directions outlined by google install each package:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;google-cloud-translate
google-cloud-language
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To pass the information from your service account private key file ot
the cloudmesh yaml file run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms register update --kind=google --service=compute --filename=GOOGLE_JSON_FILE
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;running-the-google-natural-language-and-translate-rest-services&#34;&gt;Running the Google Natural Language and Translate REST Services&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;~/.cloudmesh&lt;/code&gt; repo and create a cache directory
for your text examples you would like to analyze.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir text-cache
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add any plain text files your would like to analyze to this
directory with a name that has no special characters or spaces.
You can copy the files at this location,
&lt;code&gt;./cloudmesh-openapi/tests/textanaysis-example-text/reviews/&lt;/code&gt; into
the text-cache if you want to use provided examples.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;./cloudmesh-openapi&lt;/code&gt; directory on your machine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Utilize the generate command to create the OpenAPI spec&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate TextAnalysis --filename=./tests/generator-natural-lang/natural-lang-analysis.py --all_functions
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the server after the yaml file is generated ot the same
directory as the .py file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapie start server ./tests/generator-natural-lang/natural-lang-analysis.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to verify it
returns a result as expected.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sample text file name is only meant to be the name of the file
not the full path.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://127.0.0.1:8080/cloudmesh/analyze?filename=SAMPLE_TEXT_FILENAME&amp;amp;cloud=google&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This is currently only ready to translate a single word through
the API.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://127.0.0.1:8080/cloudmesh/translate_text?cloud=google&amp;amp;text=WORD_TO_TRANSLATE&amp;amp;lang=LANG_CODE&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop the server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server stop natural-lang-analysis
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;example-using-aws&#34;&gt;Example using AWS&lt;/h3&gt;
&lt;p&gt;Sign up for AWS&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go to &lt;a href=&#34;https://portal.aws.amazon.com/billing/signup&#34;&gt;https://portal.aws.amazon.com/billing/signup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Follow online instructions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Create an IAM User&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For instructions, see
&lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_create-admin-group.html&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Set up AWS CLI and AWS SDKs&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To download and instructions to install AWS CLI, see
&lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Install Boto 3&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install boto3
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;For quickstart, vist &lt;a href=&#34;https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As long as you enable all the services you need for using AWS AI APIs you should be able to write your functions for OpenAPI&lt;/p&gt;
&lt;h3 id=&#34;example-using-azure&#34;&gt;Example using Azure&lt;/h3&gt;
&lt;h4 id=&#34;setting-up-azure-sentiment-analysis-and-translation-services&#34;&gt;Setting up Azure Sentiment Analysis and Translation Services&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create an Azure subscription. If you do not have one, create a
&lt;a href=&#34;https://azure.microsoft.com/try/cognitive-services/&#34;&gt;free account&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;a href=&#34;https://portal.azure.com/#create/Microsoft.CognitiveServicesTextAnalytics&#34;&gt;Text Analysis resource&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This link will require you to be logged in to the Azure portal&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account?tabs=multiservice%2Cwindows&#34;&gt;Translation Resource&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The microsoft packages are included in the openapi package
requirements file so they should be installed. If they are not,
install the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install msrest 
pip install azure-ai-textanalytics
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;~/.cloudmesh&lt;/code&gt; repo and create a cache directory for your text examples you would like to analyze.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir text-cache
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add any plain text files your would like to analyze to this
directory with a name that has no special characters or spaces.
You can copy the files at this location,
&lt;code&gt;./cloudmesh-openapi/tests/textanaysis-example-text/reviews/&lt;/code&gt; into
the text-cache if you want to use provided examples.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Navigate to the &lt;code&gt;./cloudmesh-openapi&lt;/code&gt; directory on your machine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Utilize the generate command to create the OpenAPI spec&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate TextAnalysis --filename=./tests/generator-natural-lang/natural-lang-analysis.py --all_functions
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the server after the yaml file is generated ot the same
directory as the .py file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapie start server ./tests/generator-natural-lang/natural-lang-analysis.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run a curl command against the newly running server to verify it
returns a result as expected.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sample text file name is only meant to be the name of the file not the full path.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://127.0.0.1:8080/cloudmesh/analyze?filename=&amp;lt;&amp;lt;sample text file name&amp;gt;&amp;gt;&amp;amp;cloud=azure&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This is currently only ready to translate a single word through the API.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Available language tags are described in the &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/cognitive-services/translator/reference/v3-0-languages&#34;&gt;Azure docs&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://127.0.0.1:8080/cloudmesh/translate_text?cloud=azure&amp;amp;text=&amp;lt;&amp;lt;word to translate&amp;gt;&amp;gt;&amp;amp;lang=&amp;lt;&amp;lt;lang code&amp;gt;&amp;gt;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop the server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server stop natural-lang-analysis
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The natural langauge analysis API can be improved by allowing for full
phrase translation via the API. If you contribute to this API there is
room for improvement to add custom translation models as well if
preferred to pre-trained APIs.&lt;/p&gt;
&lt;h4 id=&#34;setting-up-azure-computervision-ai-services&#34;&gt;Setting up Azure ComputerVision AI services&lt;/h4&gt;
&lt;h5 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h5&gt;
&lt;p&gt;Using the Azure Computer Vision AI service, you can describe, analyze
and/ or get tags for a locally stored image or you can read the text
from an image or hand-written file.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Azure subscription. If you do not have one, create a &lt;a href=&#34;https://azure.microsoft.com/try/cognitive-services/&#34;&gt;free
account&lt;/a&gt; before
you continue further.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a Computer Vision resource and get the
&lt;code&gt;COMPUTER_VISION_SUBSCRIPTION_KEY&lt;/code&gt; and
&lt;code&gt;COMPUTER_VISION_ENDPOINT&lt;/code&gt;. Follow
&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account?tabs=singleservice%2Cunix&#34;&gt;instructions&lt;/a&gt;
to get the same.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install following Python packages in your virtual environment:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install requests
pip install Pillow
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install Computer Vision client library&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install --upgrade azure-cognitiveservices-vision-computervision
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;steps-to-implement-and-use-azure-ai-image-and-text-rest-services&#34;&gt;Steps to implement and use Azure AI image and text &lt;em&gt;REST-services&lt;/em&gt;&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Go to &lt;code&gt;./cloudmesh-openapi&lt;/code&gt; directory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run following command to generate the YAML files&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate AzureAiImage --filename=./tests/generator-azureai/azure-ai-image-function.py --all_functions --enable_upload
cms openapi generate AzureAiText --filename=./tests/generator-azureai/azure-ai-text-function.py --all_functions --enable_upload
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Verify the &lt;em&gt;YAML&lt;/em&gt; files created in &lt;code&gt;./tests/generator-azureai&lt;/code&gt; directory&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;azure-ai-image-function.yaml
azure-ai-text-function.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Start the REST service by running following command in &lt;code&gt;./cloudmesh-openapi&lt;/code&gt; directory&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server start ./tests/generator-azureai/azure-ai-image-function.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The default port used for starting the service is 8080. In case you
want to start more than one REST service, use a different port in
following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server start ./tests/generator-azureai/azure-ai-text-function.yaml --port=&amp;lt;**Use a different port than 8080**&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Access the REST service using &lt;a href=&#34;http://localhost:8080/cloudmesh/ui/&#34;&gt;http://localhost:8080/cloudmesh/ui/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After you have started the azure-ai-image-function or azure-ai-text-function on default port 8080, run following command to upload the image or text_image file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X POST &amp;quot;http://localhost:8080/cloudmesh/upload&amp;quot; -H  &amp;quot;accept: text/plain&amp;quot; -H  &amp;quot;Content-Type: multipart/form-data&amp;quot; -F &amp;quot;upload=@tests/generator-azureai/&amp;lt;image_name_with_extension&amp;gt;;type=image/jpeg&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Keep your test image files at &lt;code&gt;./tests/generator-azureai/&lt;/code&gt; directory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;em&gt;azure-ai-text-function&lt;/em&gt; started on port=8080, in order to test the azure ai function for text detection in an image, run following command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/azure-ai-text-function_upload-enabled/get_text_results?image_name=&amp;lt;image_name_with_extension_uploaded_earlier&amp;gt;&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;em&gt;azure-ai-image-function&lt;/em&gt; started on port=8080, in order to
test the azure ai function for describing an image, run following
command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/azure-ai-image-function_upload-enabled/get_image_desc?image_name=&amp;lt;image_name_with_extension_uploaded_earlier&amp;gt;&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;em&gt;azure-ai-image-function&lt;/em&gt; started on port=8080, in order to
test the azure ai function for analyzing an image, run following
command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/azure-ai-image-function_upload-enabled/get_image_analysis?image_name=&amp;lt;image_name_with_extension_uploaded_earlier&amp;gt;&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;em&gt;azure-ai-image-function&lt;/em&gt; started on port=8080, in order to
test the azure ai function for identifying tags in an image, run
following command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8080/cloudmesh/azure-ai-image-function_upload-enabled/get_image_tags?image_name=&amp;lt;image_name_with_extension_uploaded_earlier&amp;gt;&amp;quot; -H &amp;quot;accept: text/plain&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check the running REST services using following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server ps
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stop the REST service using following command(s):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi server stop azure-ai-image-function
cms openapi server stop azure-ai-text-function
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;list-of-tests&#34;&gt;List of Tests&lt;/h2&gt;
&lt;p&gt;The following table lists the different test we have, we provide additional
information for the tests in the test directory in a README file. Summaries
are provided below the table&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Test&lt;/th&gt;
&lt;th&gt;Short Description&lt;/th&gt;
&lt;th&gt;Link&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Generator-calculator&lt;/td&gt;
&lt;td&gt;Test to check if calculator api is generated correctly. This is to test multiple function in one python file&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/tests/generator-calculator/test_01_generator.py&#34;&gt;test_01_generator.py&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Generator-testclass&lt;/td&gt;
&lt;td&gt;Test to check if calculator api is generated correctly. This is to test multiple function in one python class file&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/tests/generator-testclass/test_02_generator.py&#34;&gt;test_02_generator.py&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Server-cpu&lt;/td&gt;
&lt;td&gt;Test to check if cpu api is generated correctly. This is to test single function in one python file and function name is different than file name&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/tests/server-cpu/test_03_generator.py&#34;&gt;test_03_generator.py&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Server-cms&lt;/td&gt;
&lt;td&gt;Test to check if cms api is generated correctly. This is to test multiple function in one python file.&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/tests/server-cms/test_04_generator.py&#34;&gt;test_04_generator.py&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Registry&lt;/td&gt;
&lt;td&gt;test_001_registry.py - Runs tests for registry. Description is in tests/README.md&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/tests/README.md&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Image-Analysis&lt;/td&gt;
&lt;td&gt;image_test.py - Runs benchmark for text detection for Google Vision API and AWS Rekognition. Description in image-analysis/README.md&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/tests/image-analysis/README.md&#34;&gt;image&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For more information about test cases ,please check &lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/tests/README.md&#34;&gt;tests info&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_001_registry.py&#34;&gt;test_001_registry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_003_server_manage_cpu.py&#34;&gt;test_003_server_manage_cpu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_010_generator.py&#34;&gt;test_010_generator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_011_generator_cpu.py&#34;&gt;test_011_generator_cpu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_012_generator_calculator.py&#34;&gt;test_012_generator_calculator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_015_generator_azureai.py&#34;&gt;test_015_generator_azureai&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_020_server_manage.py&#34;&gt;test_020_server_manage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;tests/test_server_cms_cpu.py&#34;&gt;test_server_cms_cpu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that there a many more tests that you can explore.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/add-float/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/add-float/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;readme&#34;&gt;README&lt;/h1&gt;
&lt;p&gt;please see the README in the root dir of this repository&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/add-json/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/add-json/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;readme&#34;&gt;README&lt;/h1&gt;
&lt;p&gt;please see the README in the root dir of this repository&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/generator-natural-lang/googlecloudvmset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/generator-natural-lang/googlecloudvmset/</guid>
      <description>
        
        
        &lt;h1 id=&#34;steps&#34;&gt;Steps:&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Setup a google account with Google Cloud&lt;/li&gt;
&lt;li&gt;Create a project&lt;/li&gt;
&lt;li&gt;Set permission for create on compute engine in the project&lt;/li&gt;
&lt;li&gt;create a service account file and link to json in cloudmesh yaml file
&lt;a href=&#34;https://cloud.google.com/docs/authentication/production?hl=en_US&#34;&gt;https://cloud.google.com/docs/authentication/production?hl=en_US&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Create a storage location using google storage
&lt;a href=&#34;https://cloud.google.com/storage/docs/creating-buckets#storage-create-bucket-code_samples&#34;&gt;https://cloud.google.com/storage/docs/creating-buckets#storage-create-bucket-code_samples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install the google cloud sdk
&lt;a href=&#34;https://cloud.google.com/compute/docs/tutorials/python-guide&#34;&gt;https://cloud.google.com/compute/docs/tutorials/python-guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install the google cloud api client library
&lt;a href=&#34;https://cloud.google.com/apis/docs/client-libraries-explained&#34;&gt;https://cloud.google.com/apis/docs/client-libraries-explained&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Write a startup script for your vm&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;azure&#34;&gt;Azure&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal&#34;&gt;https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal&lt;/a&gt;
Credentials:
app-name: vm-creation-example
auth url:https://andyvmcreateexample.com/auth&lt;/p&gt;
&lt;p&gt;app (client) ID: 8db85342-7efd-433c-aeba-d175ae4d4404
directory (tenant) id: 398e5475-e850-4239-ba0d-62ddc3e644ff
object ID: 38224a7e-79e0-4642-b765-2bf731d296ad
client-secret: w[f7o=[dKKeSn?VxF3iNoZDW3ctMmd3G
subscription id:4513afc9-4159-49d0-aa1d-0a2a0ab9933c&lt;/p&gt;
&lt;p&gt;when creating a vm in the portal the network interface is set up for you
but if you do it programmatically you have to set it up.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/gregor/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/gregor/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;test-it-yourself&#34;&gt;Test it yourself&lt;/h1&gt;
&lt;p&gt;cd to &lt;code&gt;cloudmesh-openapi&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Start the service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapii server start ./tests/server-cpu.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Stop the service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapii3 server stop cpu
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;urls&lt;/p&gt;
&lt;p&gt;cloudmesh/ui&lt;/p&gt;
&lt;p&gt;cloudmesh/cpu&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/image-analysis/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/image-analysis/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;test-it-yourself&#34;&gt;Test it yourself&lt;/h1&gt;
&lt;h2 id=&#34;in-cloudmesh-openapi&#34;&gt;In cloudmesh-openapi&lt;/h2&gt;
&lt;p&gt;Start server&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cms openapi server start ./tests/image-analysis/image.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Get Response Google Vision&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -sL http://127.0.0.1:8080/cloudmesh/image/detect_text_google
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Get Response AWS Rekognition&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -sL http://127.0.0.1:8080/cloudmesh/image/detect_text_aws
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Stop server&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cms openapi server stop image
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;urls&lt;/p&gt;
&lt;p&gt;cloudmesh/image/detect_text_google&lt;/p&gt;
&lt;p&gt;cloudmesh/image/detect_text_aws&lt;/p&gt;
&lt;h2 id=&#34;image_testpy&#34;&gt;image_test.py&lt;/h2&gt;
&lt;p&gt;How to run test&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/image-analysis/image_test.py 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;image_test.py has 7 tests&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Uses generate command to generate new yaml file&lt;/li&gt;
&lt;li&gt;Check yaml syntax&lt;/li&gt;
&lt;li&gt;Starts server&lt;/li&gt;
&lt;li&gt;Does a curl call for google vision api response&lt;/li&gt;
&lt;li&gt;Does a curl call for aws rekognition api response&lt;/li&gt;
&lt;li&gt;Stops the server&lt;/li&gt;
&lt;li&gt;Prints benchmark&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;how-to-write-and-run-test-case-for-openapi&#34;&gt;How to write and run test case for OpenAPI&lt;/h1&gt;
&lt;h2 id=&#34;this-document-will-explain-how-to-validate-if-openapi-is-generated-correctly-and-server-start-and-stop-working-correctly&#34;&gt;This document will explain how to validate if openapi is generated correctly and server start and stop working correctly&lt;/h2&gt;
&lt;h3 id=&#34;we-have-create-a-framework-class-which-has-below-basic-test-case-functions&#34;&gt;We have create a framework class which has below basic test case functions&lt;/h3&gt;
&lt;p&gt;Framework file is present under tests/lib named as generator_test.py&lt;/p&gt;
&lt;h4 id=&#34;below-test-cases-are-related-to-generator-api&#34;&gt;Below test cases are related to generator API&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Create a build folder and copy py file into it. Build sub folder will created where test py file present.&lt;/li&gt;
&lt;li&gt;It will call generator generate function to generate Yaml file inside build folder&lt;/li&gt;
&lt;li&gt;It will check if generated YMAL file syntax is correct or not.&lt;/li&gt;
&lt;li&gt;It will check if number of function generated in YMAL is same as py file.&lt;/li&gt;
&lt;li&gt;Delete the build folder.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;two-test-cases-are-related-to-server-api&#34;&gt;Two test cases are related to server API&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;It will start server&lt;/li&gt;
&lt;li&gt;It will stop server&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;how-to-create-test-case&#34;&gt;How to create test case&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;If you creating new Open API , then inside tests folder you have to commit your working py and yaml files.&lt;/li&gt;
&lt;li&gt;Create new function for test case where py and yaml located. Example (test_01_generator)&lt;/li&gt;
&lt;li&gt;We have already created test cases function file for generator-calculator name as test_01_generator.py. Please check this file.&lt;/li&gt;
&lt;li&gt;Copy the contains of test_01_generator.py and paste inside your test py file.&lt;/li&gt;
&lt;li&gt;Change startservercommand and filename variables value accordingly to your use case.&lt;/li&gt;
&lt;li&gt;Change some of parameters of constructor of GeneratorBaseTest class.&lt;/li&gt;
&lt;li&gt;if your py file has a class then.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt; &lt;span style=&#34;color:#000&#34;&gt;gen&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; GeneratorBaseTest&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;filename,False,True&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;if your py file has functions then&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt; &lt;span style=&#34;color:#000&#34;&gt;gen&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt; GeneratorBaseTest&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;filename,True,False&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;First boolean flag in GeneratorBaseTest for &amp;ndash;all_functions and second flag is for &amp;ndash;import_class&lt;/li&gt;
&lt;li&gt;If you need to write more test cases based on your requirement, check order of test case and write accordingly.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;how-to-run-test-case&#34;&gt;How to run test case&lt;/h3&gt;
&lt;p&gt;Below command can use to run your case. Make sure your current directory is cloudmesh-openapi.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ how &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;do&lt;/span&gt; you call this you can add -x to stop pytest when first &lt;span style=&#34;color:#204a87&#34;&gt;test&lt;/span&gt; failed
pytest -v  --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/generator-calculator/test_01_generator.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;run-test-case-with-csv-command-enabled&#34;&gt;Run test case with CSV command enabled&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ how &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;do&lt;/span&gt; you call this , you can add -x to stop pytest when first &lt;span style=&#34;color:#204a87&#34;&gt;test&lt;/span&gt; failed
pytest -v  --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/generator-calculator/test_01_generator.py  &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; fgrep &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;# cvs&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;below-are-test-case-files&#34;&gt;Below are test case files&lt;/h2&gt;
&lt;p&gt;Generator-calculator and file name is test_01_generator.py&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pytest -v  --capture=no tests/generator-calculator/test_01_generator.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Generator-testclass and file name is test_02_generator.py&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pytest -v --capture=no tests/generator-testclass/test_02_generator
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Server-cpu and file name is test_03_generator.py&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pytest -v  --capture=no tests/server-cpu/test_03_generator
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Server-cms and file name is test_04_generator.py&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pytest -v  --capture=no tests/server-cms/test_04_generator
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Generator and file name is test_05_generator.py&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pytest -v --capture=no tests/generator/test_05_generator
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Azure AI Image Function is test_06_generator.py&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/generator_azureai/test_06_generator
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Azure AI Text Function is test_07_generator.py&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/generator_azureai/test_07_generator
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Natural Language Analysis Generator Tests are run from test_generator_natural_language.py&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no  ./tests/test_generator_natural_language.py::TestGenerator
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This test will generate an OpenAPI spec for the natural-lang-analysis.py file located in the generator-natural-lang
directory. If the above command is copied and pasted to run in the terminal it will do the following.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generate a yaml file&lt;/li&gt;
&lt;li&gt;Verify the spec has all the functions that are available in the natural-lang-analysis.py file&lt;/li&gt;
&lt;li&gt;Start a server hosting the openAPI spec&lt;/li&gt;
&lt;li&gt;Run a call against the sentiment analysis and translation endpoint for each available cloud service (Google/Azure) and verify it was successful.&lt;/li&gt;
&lt;li&gt;Stop the service&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Results for Natural Language Tests&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Attribute&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;cpu_count&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.active&lt;/td&gt;
&lt;td&gt;2.0 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.available&lt;/td&gt;
&lt;td&gt;2.1 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.free&lt;/td&gt;
&lt;td&gt;148.8 MiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.inactive&lt;/td&gt;
&lt;td&gt;2.0 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.percent&lt;/td&gt;
&lt;td&gt;73.2 %&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.total&lt;/td&gt;
&lt;td&gt;8.0 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.used&lt;/td&gt;
&lt;td&gt;4.8 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.wired&lt;/td&gt;
&lt;td&gt;2.8 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;platform.version&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;python&lt;/td&gt;
&lt;td&gt;3.8.1 (v3.8.1:1b293b6006, Dec 18 2019, 14:08:53)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;[Clang 6.0 (clang-600.0.57)]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;python.pip&lt;/td&gt;
&lt;td&gt;20.0.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;python.version&lt;/td&gt;
&lt;td&gt;3.8.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sys.platform&lt;/td&gt;
&lt;td&gt;darwin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.machine&lt;/td&gt;
&lt;td&gt;x86_64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.node&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.processor&lt;/td&gt;
&lt;td&gt;i386&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.release&lt;/td&gt;
&lt;td&gt;18.2.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.system&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.version&lt;/td&gt;
&lt;td&gt;Darwin Kernel Version 18.2.0: Fri Oct  5 19:41:49 PDT 2018; root:xnu-4903.221.2~2/RELEASE_X86_64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Status&lt;/th&gt;
&lt;th&gt;Time&lt;/th&gt;
&lt;th&gt;Start&lt;/th&gt;
&lt;th&gt;tag&lt;/th&gt;
&lt;th&gt;Node&lt;/th&gt;
&lt;th&gt;User&lt;/th&gt;
&lt;th&gt;OS&lt;/th&gt;
&lt;th&gt;Version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/copy_py_file&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;0.003&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:47&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/generate&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;2.601&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:47&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/read_spec&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;0.012&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:49&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/start_service&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;1.864&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:49&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;test_generator_natural_language/test_run_analyze_google&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;0.67&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:51&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;test_generator_natural_language/test_run_analyze_azure&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;0.58&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:52&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/stop_server&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;2.095&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:52&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;generator_test/delete_file&lt;/td&gt;
&lt;td&gt;ok&lt;/td&gt;
&lt;td&gt;0.002&lt;/td&gt;
&lt;td&gt;2020-05-09 06:33:54&lt;/td&gt;
&lt;td&gt;openapi&lt;/td&gt;
&lt;td&gt;Andrews-MacBook-Pro.local&lt;/td&gt;
&lt;td&gt;andrewgoldfarb&lt;/td&gt;
&lt;td&gt;Darwin&lt;/td&gt;
&lt;td&gt;10.14.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;todo-describe-what-they-do&#34;&gt;TODO DESCRIBE WHAT THEY DO&lt;/h2&gt;
&lt;p&gt;cache-scikitlearn
deprecated
examples
generator
generator-azureai
generator-calculator
generator-printerclass
generator-testclass
generator-upload
image-analysis
lib
Scikit-learntestfiles
Scikitlearn_tests
server-cms
server-cms-simple
server-cpu
server-sample
server-sampleFunction
test_mlperf
textanalysis-example-text
&lt;strong&gt;init&lt;/strong&gt;.py
README.md
test_001_registry.py
test_03_generator.py
test_010_generator.py
test_011_generator_cpu.py
test_012_generator_calculator.py
test_015_generator_azureai.py
test_020_server_manage.py
test_server_cms_cpu.py
util.py&lt;/p&gt;
&lt;p&gt;THIS WAS HERE BEFORE&lt;/p&gt;
&lt;h2 id=&#34;test_001_registrypy&#34;&gt;test_001_registry.py&lt;/h2&gt;
&lt;p&gt;This test has 5 test functions&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;test_registry_add&lt;/li&gt;
&lt;li&gt;test_registry_list_name&lt;/li&gt;
&lt;li&gt;test_registry_list&lt;/li&gt;
&lt;li&gt;test_registry_delete&lt;/li&gt;
&lt;li&gt;test_benchmark&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Test 1 calls registry and adds to the registry. If successful prints &amp;lsquo;PASSED&amp;rsquo;&lt;/p&gt;
&lt;p&gt;Test 2 calls registry and prints ONLY the server specified in filename.&lt;/p&gt;
&lt;p&gt;Test 3 calls registry and print list for ALL servers in registry.&lt;/p&gt;
&lt;p&gt;Test 4 calls registry and deletes entry for filename.&lt;/p&gt;
&lt;p&gt;Test 5 runs benchmark test on registry.&lt;/p&gt;
&lt;h3 id=&#34;how-to-call-this&#34;&gt;How to call this&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cms &lt;span style=&#34;color:#204a87&#34;&gt;set&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;filename&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;./tests/server-cpu/cpu.yaml&amp;#34;&lt;/span&gt;
pytest -v --capture&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;no tests/test_001_registry.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;deprecated
examples
generator
generator-calculator
generator-printerclass
generator-testclass
server-class
server-cms
server-cms-simple
server-cpu
server-sample
server-sampleFunction
textanalysis-example-text
&lt;strong&gt;init&lt;/strong&gt;.py
README.md
test_001_registry.py  Falconi
test_03_generator.py  jonthan
test_010_generator.py jonthan
test_011_generator_cpu.py prateek
test_012_generator_calculator.py prateek
test_020_server_manage.py ishan
test_server_cms_cpu.py andrew&amp;ndash;&amp;gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/server-cpu/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/server-cpu/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;test-it-yourself&#34;&gt;Test it yourself&lt;/h1&gt;
&lt;p&gt;cd to &lt;code&gt;cloudmesh-openapi&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Start the service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapii server start ./tests/server-cpu.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Stop the service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapii3 server stop cpu
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;urls&lt;/p&gt;
&lt;p&gt;cloudmesh/ui&lt;/p&gt;
&lt;p&gt;cloudmesh/cpu&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/test_mlperf/readme-source/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/test_mlperf/readme-source/</guid>
      <description>
        
        
        &lt;h1 id=&#34;mlperf-tests&#34;&gt;MLPerf Tests&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;http://mlperf.org&#34;&gt;MLperf&lt;/a&gt; [@www-mlperf] provides &amp;ldquo;fair and useful benchmarks for measuring
training and inference performance of ML hardware, software, and
services&amp;rdquo;&lt;/p&gt;
&lt;p&gt;In this benchmark we will&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Deploy MLPerf on the system&lt;/li&gt;
&lt;li&gt;Use functions that run a number of tests as inout to the OpenAPI Gnerator&lt;/li&gt;
&lt;li&gt;From these functions we run our OpenAPI generator to create a service
that allows to run the MLperf examples through a Web service with
http calls&lt;/li&gt;
&lt;li&gt;Test out the created functions by running selected example invocations&lt;/li&gt;
&lt;li&gt;Report the time it takes to run these examples&lt;/li&gt;
&lt;li&gt;Provide a Makefile or python script that allows us to conveniently
cun these tests&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;
&lt;p&gt;Describe how to deploy&lt;/p&gt;
&lt;h3 id=&#34;reports-for-running-the-tests-on-machines&#34;&gt;Reports for running the tests on Machines&lt;/h3&gt;
&lt;p&gt;Provide summary information about teh runtime
Provide details do checked in results in the &lt;a href=&#34;results&#34;&gt;results&lt;/a&gt; directory&lt;/p&gt;
&lt;h3 id=&#34;local-output&#34;&gt;Local Output&lt;/h3&gt;
&lt;p&gt;All output is written into a &lt;code&gt;~/.cloudmesh/dest/benchmark/mlperf&lt;/code&gt; folder
which can be removed after the test is completed. In the results folder
we also find a copy of the OpenAPI YAML file that is generated with the
cenerator. This file can also be used to compare the generated output.&lt;/p&gt;
&lt;h2 id=&#34;selected-benchmarks&#34;&gt;Selected Benchmarks&lt;/h2&gt;
&lt;p&gt;Describe which benchmarks were selected&lt;/p&gt;
&lt;h2 id=&#34;functions&#34;&gt;Functions&lt;/h2&gt;
&lt;p&gt;Short description aboutthe functions that have been defined&lt;/p&gt;
&lt;h2 id=&#34;opeanapi&#34;&gt;OpeanAPI&lt;/h2&gt;
&lt;p&gt;Describe where to find the generated functions
Link th=o wher ethe open api is created in the&lt;/p&gt;
&lt;h2 id=&#34;how-to-run-individual-tests&#34;&gt;How to run individual tests&lt;/h2&gt;
&lt;p&gt;Describe how to run indific=dual Tests&lt;/p&gt;
&lt;h2 id=&#34;benchmarks&#34;&gt;Benchmarks&lt;/h2&gt;
&lt;p&gt;Links to benchmarks that are listed in the &lt;a href=&#34;results&#34;&gt;results&lt;/a&gt; directory&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/test_mlperf/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/test_mlperf/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;mlperf-tests&#34;&gt;MLPerf Tests&lt;/h1&gt;
&lt;p&gt;According to &lt;a href=&#34;https://mlperf.org/&#34;&gt;https://mlperf.org/&lt;/a&gt; MLPerf provides &amp;quot; Fair and useful
benchmarks for measuring training and inference performance of ML
hardware, software, and services&amp;rdquo; [@www-mlperf]&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/test_mlperf/results/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/test_mlperf/results/readme/</guid>
      <description>
        
        
        &lt;p&gt;put your result files here&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/cloudmesh-openapi/tests/timeseries-example/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/cloudmesh-openapi/tests/timeseries-example/readme/</guid>
      <description>
        
        
        &lt;h1 id=&#34;time-series-forecast-using-multi-cloud-ai-services&#34;&gt;Time Series Forecast using Multi Cloud AI Services&lt;/h1&gt;
&lt;p&gt;Prafull Porwal, &lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-255/blob/master/Cloudmesh-OpenAPI/Readme.md&#34;&gt;sp20-516-255&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-255/graphs/contributors&#34;&gt;Contributors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/fa19-516-147/pulse&#34;&gt;Insights&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-255/tree/master/Cloudmesh-OpenAPI/AWSForecast&#34;&gt;Project Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;objective&#34;&gt;Objective&lt;/h2&gt;
&lt;p&gt;Develop Open API for time series forecasting on multiple clouds&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Many cloud providers have introduced machine learning capabilities on their infrastructure. The project aims to provide an open API for timeseries forecasting for AWS using Forecast Services and S3&lt;/p&gt;
&lt;h3 id=&#34;aws-ai-service--forecast-open-api-service-features&#34;&gt;AWS AI Service : Forecast Open API Service Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Upload the data file to ./cloudmesh/upload-file location&lt;/li&gt;
&lt;li&gt;Upload the json schema file to ./cloudmesh/upload-file location&lt;/li&gt;
&lt;li&gt;Validate the data for missing and less than 0 values&lt;/li&gt;
&lt;li&gt;Split the dataset into Train and test by specifying split percentge.&lt;/li&gt;
&lt;li&gt;Provide list of Multi Cloud supported for Timeseries Forecasting&lt;/li&gt;
&lt;li&gt;Initialize the cloud service&lt;/li&gt;
&lt;li&gt;Create a Dataset Group&lt;/li&gt;
&lt;li&gt;Create a Target Time Series Dataset&lt;/li&gt;
&lt;li&gt;Import data into Forecast from AWS Storage S3&lt;/li&gt;
&lt;li&gt;Create a Predictor&lt;/li&gt;
&lt;li&gt;Generate Forecast&lt;/li&gt;
&lt;li&gt;Query the Forecast&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;additional-features&#34;&gt;Additional Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Multiple instance of the process supported&lt;/li&gt;
&lt;li&gt;Data Validation and missing values checks&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;environment-configuration&#34;&gt;Environment Configuration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Python 3.8.2 Python or newer.&lt;/li&gt;
&lt;li&gt;Use a venv (see developer install)&lt;/li&gt;
&lt;li&gt;MongoDB installed as regular program not as service&lt;/li&gt;
&lt;li&gt;AWS boto3 library&lt;/li&gt;
&lt;li&gt;Open API package installed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Make sure that cloudmesh is properly installed on your machine and you have mongodb setup to work with cloudmesh.
More details can be found in the &lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/installation/install.html&#34;&gt;Cloudmesh Manual&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;openapi-package-installation&#34;&gt;OpenAPI package installation&lt;/h3&gt;
&lt;p&gt;Make sure you use a python venv before installing. Users can install the code with&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ pip install cloudmesh-openapi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;pre-requisites-&#34;&gt;Pre Requisites :&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;add below parameter to cloudmesh.yaml for forecast service to work&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bucket_name : awsforecastassignnment&lt;/li&gt;
&lt;li&gt;region_name : us-east-1&lt;/li&gt;
&lt;li&gt;forecast_srv : forecast&lt;/li&gt;
&lt;li&gt;forecastquery_srv : forecastquery&lt;/li&gt;
&lt;li&gt;s3_srv : s3&lt;/li&gt;
&lt;li&gt;iam_role_arn: XXXXXX&lt;/li&gt;
&lt;li&gt;algorithmArn: arn:aws:forecast:::algorithm/Deep_AR_Plus&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Data Format : The data should be in csv file format and must have&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;item_id : reference column for which time series forecast is required&lt;/li&gt;
&lt;li&gt;target_value : the column which need to be predicted, data type integer&lt;/li&gt;
&lt;li&gt;timestamp : timestamp of data samples&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/forecast/latest/dg/API_CreateDataset.html&#34;&gt;AWS Time Series Forecast&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Json Schema : Json Schema file with name schema.json&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;quick-forecast-api-reference-commands&#34;&gt;Quick Forecast API reference Commands&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Start the open API server for the forecast service&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cms openapi server start .//forecast.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check for supported AI services&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://localhost:8080/cloudmesh/forecast
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;e.g. output:
&amp;ldquo;model&amp;rdquo;: &amp;ldquo;Supported Time Series Forecast Services AWS : Forecast &amp;quot;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Upload file to the server from location (
File path should be the location on server where file is located.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;http://localhost:8080/cloudmesh/forecast/upload&amp;#34;&lt;/span&gt; -F &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;upload=@&amp;lt;file_path&amp;gt;\countries-aggregated.csv&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;e.g. output:
countries-aggregated.csv uploaded successfully&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Validate data file&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;http://localhost:8080/cloudmesh/forecast/validate_data&amp;#34;&lt;/span&gt; -F &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;upload=@&amp;lt;file_path&amp;gt;\countries-aggregated.csv&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;e.g. output:
countries-aggregated.csv validated successfully&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Split the data into test and train. Data should be validated first before splitting&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://localhost:8080/cloudmesh/forecast/split_data?split_pct&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;output: &amp;ldquo;Please validate the data first&amp;rdquo;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://localhost:8080/cloudmesh/forecast/split_data?split_pct&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;20&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;output: &amp;ldquo;Data split successfully&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Initialize aws parameters&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;http://localhost:8080/cloudmesh/forecast/aws&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;e.g. output:
{&amp;ldquo;model&amp;rdquo;:&amp;ldquo;AWS AI Service initialized successfully&amp;rdquo;}&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create Forecast, this is a multistep process, it cretes datasetgroup, dataset, import job, predictor and forecast&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://localhost:8080/cloudmesh/forecast/create_forecast?country&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;Austrailia
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This api expects cloud services to be already initialized if not it will request to initialize
output:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Please initialize cloud service&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;output: &amp;ldquo;Forecast generated successfully&amp;rdquo;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lookup a Forecast&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl http://localhost:8080/cloudmesh/forecast/lookupForecast?countryName&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;Austrailia
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;output :
shows &lt;a href=&#34;https://github.com/cloudmesh-community/sp20-516-255/blob/master/Cloudmesh-OpenAPI/AWSForecast/sampleOutput&#34;&gt;ouput&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Delete Data Stack for the current project
This API should be executed at the end of the session to delete all the resources created for the analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;http://localhost:8080/cloudmesh/forecast/deletestack&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;algorithm-details&#34;&gt;Algorithm details&lt;/h2&gt;
&lt;p&gt;The AWS Forecast service supports following pre-defined algortithms&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Autoregressive Integrated Moving Average (ARIMA) Algorithm - arn:aws:forecast:::algorithm/ARIMA&lt;/li&gt;
&lt;li&gt;DeepAR+ Algorithm - arn:aws:forecast:::algorithm/Deep_AR_Plus&lt;/li&gt;
&lt;li&gt;Exponential Smoothing (ETS) - arn:aws:forecast:::algorithm/ETS&lt;/li&gt;
&lt;li&gt;Non-Parametric Time Series (NPTS) Algorithm - arn:aws:forecast:::algorithm/NPTS&lt;/li&gt;
&lt;li&gt;Prophet Algorithm - arn:aws:forecast:::algorithm/Prophet&lt;/li&gt;
&lt;li&gt;Supports hyperparameter optimization (HPO)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/forecast/latest/dg/forecast.dg.pdf&#34;&gt;AWS Time Series Forecast&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Requires data file with mandatory colums item_id, target_value and timestamp&lt;/li&gt;
&lt;li&gt;Requires a schema file schema.json to be provided by the user&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/forecast/latest/dg/forecast.dg.pdf&#34;&gt;https://docs.aws.amazon.com/forecast/latest/dg/forecast.dg.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/aws-samples/amazon-forecast-samples&#34;&gt;https://github.com/aws-samples/amazon-forecast-samples&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-301/project/misc_files/blank/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-301/project/misc_files/blank/</guid>
      <description>
        
        
        &lt;h1 id=&#34;blank&#34;&gt;Blank&lt;/h1&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-301/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-301/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;nba-performance-and-injury&#34;&gt;NBA Performance and Injury&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Gavin Hemmerlein, fa20-523-301&lt;/li&gt;
&lt;li&gt;Chelsea Gorius, fa20-523-344&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-301/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please add abstract&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-dataset&#34;&gt;2. Dataset&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-objective&#34;&gt;3. Objective&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-references&#34;&gt;4. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; please add keywords&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;The topic to be investigated is basketball player performance as it relates to injury. The topic of injury and recovery is a multi-billion dollar industry.  The Sports Medicine field is expected to reach $7.2 billion dollars by 2025 &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.  The scope of this effort is to explore National Basketball Association(NBA) teams, but the additional uses of a topic such as this could expand into other realms such as the National Football League, Major League Baseball, the Olympic Committees, and many other avenues.  For leagues with salaries, projecting an expected return on the investment can assist in contract negotiations and cater expectations.&lt;/p&gt;
&lt;h2 id=&#34;2-dataset&#34;&gt;2. Dataset&lt;/h2&gt;
&lt;p&gt;To compare performance and injury, a minimum of two datasets will be needed. The first is a dataset of injuries for players &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. This dataset will create the samples necessary for review.&lt;/p&gt;
&lt;p&gt;Once the controls for injuries are established, the next requirement will be to establish  pre-injury performance parameters and post-injury parameters.  These areas will be where the feature engineering will take place.  The datasets needed must dive into appropriate basketball performance stats to establish a metric to encompass a playerâ€™s performance. One example that ESPN has tried in the past is the Player Efficiency Rating (PER).  To accomplish this, it will be important to review player performance within games such as in the â€œNBA games dataâ€ &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; dataset.  There is a potential to pull more data from other datasets such as the â€œNBA Enhanced Box Score and Standings (2012 - 2018)â€ &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.  It is important to use the in depth data from the â€œNBA games dataâ€ &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. dataset because of how it will allow us to see how the player was performing throughout the season, and not just their average stats across the year.  With in depth information about each game of the season, and not just the teams and players aggregated stats, added to the data provided from the injury dataset &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; we will be able to compose new metrics to understand how these injuries are actually affecting the players performance.&lt;/p&gt;
&lt;p&gt;Along the way we look forward to discovering if there is also a causal relationship to the severity of some of the injuries, based on how the player was performing just before the injury.  The term â€œload managementâ€ has become popular in recent years to describe players taking rest periodically throughout the season in order to prevent injury from overplaying.  This new practice has received both support for the player safety it provides and also criticism around players taking too much time off.  Of course not all injuries are entirely based on the recent strain under the players body, but a better understanding about how that affects the injury as a whole could give better insight into avoiding more injuries.  It is important to remember though that any pattern identification would not lead to an elimination of all injuries, any contact sport will continue to have injuries, especially one as high impact as the NBA.  There is value to learn from why some players are able to return from certain injuries more quickly and why some return to almost equivalent or better playing performance than before the injury.  This comparison of performance will be made by deriving metrics based on varying ranges of games immediately leading up to injury and then immediately after returning from injury.  In addition to that we will perform comparisons to the players known peak performance to better understand how the injury affected them.  Another factor it will be important to include is the length of time recovering from the injury. Different players take differing amounts of time off, sometimes even with similar injuries.  Something will be said about the playerâ€™s dedication to recovery and determination to remain at peak performance, even through injury, when looking at how severe their injury was, how much time was taken for recovery, and how they performed upon returning.&lt;/p&gt;
&lt;p&gt;These datasets were chosen because they allow for a review of individual game performance, for each team, throughout each season in the recent decade.  Aggregate statistics such as points per game (ppg) can be deceptive because duration of the metric is such a large period of time.  The large sample of 82 games can lead to a perception issue when reviewing the data.  These datasets include more variables to help us determine effects to player injury, such as minutes per game (mpg) to understand how strenuous the pre-injury performance or how fatigue may have played a factor in the injury.  Understanding more of the variables such as fouls given or drawn can help determine if the player or other team seemed to be the primary aggressor before any injury.&lt;/p&gt;
&lt;h2 id=&#34;3-objective&#34;&gt;3. Objective&lt;/h2&gt;
&lt;p&gt;The objective of this project is to develop performance indicators for injured players returning to basketball in the NBA.  It is unreasonable to expect a player to return to the same level of play post injury immediately upon starting back up after recovery.  It often takes a player months if not years to return to the same level of play as pre-injury, especially considering the severity of the injuries.  In order to successfully analyse this information from the datasets, a predictive model will need to be created using a large set of the data to train.&lt;/p&gt;
&lt;p&gt;From this point, a test run will be used to gauge the validity and accuracy of the model compared to some of the data set aside.  The model created will be able to provide feature importance to give a better understanding of which specific features are the most crucial when it comes to determining how bad the effects of an injury may or may not be on player performance.  Feature engineering will be performed prior to training the model in order to improve the chances of higher accuracy from the predictions.  This model could be used to keep an eye out for how a player&amp;rsquo;s performance intensity and the engineered features could affect how long a player takes to recover from injury, if there are any warning signs prior to an injury, and even how well they perform when returning.&lt;/p&gt;
&lt;h2 id=&#34;4-references&#34;&gt;4. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;A. Mehra, &lt;em&gt;Sports Medicine Market worth $7.2 billion by 2025&lt;/em&gt;, Markets and Markets.
&lt;a href=&#34;https://www.marketsandmarkets.com/PressReleases/sports-medicine-devices.asp&#34;&gt;https://www.marketsandmarkets.com/PressReleases/sports-medicine-devices.asp&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;R. Hopkins, &lt;em&gt;NBA Injuries from 2010-2020&lt;/em&gt;, Kaggle. &lt;a href=&#34;https://www.kaggle.com/ghopkins/nba-injuries-2010-2018&#34;&gt;https://www.kaggle.com/ghopkins/nba-injuries-2010-2018&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;N. Lauga, &lt;em&gt;NBA games data&lt;/em&gt;, Kaggle.  &lt;a href=&#34;https://www.kaggle.com/nathanlauga/nba-games?select=games_details.csv&#34;&gt;https://www.kaggle.com/nathanlauga/nba-games?select=games_details.csv&lt;/a&gt; &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;P. Rossotti, &lt;em&gt;NBA Enhanced Box Score and Standings (2012 - 2018)&lt;/em&gt;, Kaggle. &lt;a href=&#34;https://www.kaggle.com/pablote/nba-enhanced-stats&#34;&gt;https://www.kaggle.com/pablote/nba-enhanced-stats&lt;/a&gt; &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-301/report/assignment6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-301/report/assignment6/</guid>
      <description>
        
        
        &lt;h1 id=&#34;assignment-6&#34;&gt;Assignment 6&lt;/h1&gt;
&lt;h1 id=&#34;health-and-medicine&#34;&gt;Health and Medicine&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Gavin Hemmerlein, fa20-523-301&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-301/blob/master/report/report_Assignment6.md&#34;&gt;Edit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please add abstract&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-the-subject&#34;&gt;2. The Subject&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-objective&#34;&gt;3. Objective&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-references&#34;&gt;4. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; please add keywords&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;The topic to be investigated is problems in Health and Medicine. The topic is intended to explore the nature and status of the AI solution.&lt;/p&gt;
&lt;h2 id=&#34;2-the-subject&#34;&gt;2. The Subject&lt;/h2&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;AI helps bust stroke, identify occlusions&amp;rdquo; &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Computer-aided imaging analysis in acute ischemic stroke â€“ background and clinical applications&amp;rdquo; &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Artificial intelligence to diagnose ischemic stroke and identify large vessel occlusions: a systematic review&amp;rdquo; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Detecting Large Vessel Occlusion at Multiphase CT Angiography by Using a Deep Convolutional Neural Network&amp;rdquo; &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;3-objective&#34;&gt;3. Objective&lt;/h2&gt;
&lt;p&gt;The&lt;/p&gt;
&lt;h2 id=&#34;4-references&#34;&gt;4. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Y. Mokli, J. Pfaff, D. Pinto dos Santos, C. Herweh, and S. Nagel &amp;ldquo;Computer-aided imaging analysis in acute ischemic stroke â€“ background and clinical applications&amp;rdquo;, &lt;em&gt;Neurological Research and Practice&lt;/em&gt;, p. 1-13. 2020 [Online serial]. Available:  &lt;a href=&#34;https://neurolrespract.biomedcentral.com/track/pdf/10.1186/s42466-019-0028-y&#34;&gt;https://neurolrespract.biomedcentral.com/track/pdf/10.1186/s42466-019-0028-y&lt;/a&gt; [Accessed Oct. 13, 2020]. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;N. Murray, &amp;ldquo;Artificial intelligence to diagnose ischemic stroke and identify large vessel occlusions: a systematic review,&amp;rdquo; &lt;em&gt;Journal of NeuroInterventional Surgery&lt;/em&gt;, vol. 12, no. 2, p. 156-164. 2020 [Online serial]. Available: &lt;a href=&#34;https://jnis.bmj.com/content/12/2/156&#34;&gt;https://jnis.bmj.com/content/12/2/156&lt;/a&gt;. [Accessed Oct. 13, 2020]. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;M. Stib, J. Vasquez, M. Dong, Y. Kim, S. Subzwari, H. Triedman, A. Wang, H. Wang, A. Yao, M. Jayaraman, J. Boxerman, C. Eickhoff, U. Cetintemel, G. Baird, and R. McTaggart, &amp;ldquo;Detecting Large Vessel Occlusion at Multiphase CT Angiography by Using a Deep Convolutional Neural Network&amp;rdquo;, &lt;em&gt;Original Research Neuroradiology&lt;/em&gt;, Sep 29, 2020. [Online serial]. Available: &lt;a href=&#34;https://pubs.rsna.org/doi/full/10.1148/radiol.2020200334&#34;&gt;https://pubs.rsna.org/doi/full/10.1148/radiol.2020200334&lt;/a&gt; [Accessed Oct. 13, 2020]. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-301/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-301/test/</guid>
      <description>
        
        
        &lt;h2 id=&#34;gavin-hemmerlein&#34;&gt;Gavin Hemmerlein&lt;/h2&gt;
&lt;h2 id=&#34;ghemmer&#34;&gt;ghemmer&lt;/h2&gt;
&lt;h2 id=&#34;engr-e-534&#34;&gt;ENGR-E 534&lt;/h2&gt;
&lt;p&gt;This is a test MarkDown file to ensure I have write privileges.&lt;/p&gt;
&lt;h1 id=&#34;test-typing&#34;&gt;Test Typing&lt;/h1&gt;
&lt;p&gt;This appears to be &lt;em&gt;working.&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;table&#34;&gt;Table&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Col1&lt;/th&gt;
&lt;th&gt;Col2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Row 1&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Row 2&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;22&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;images&#34;&gt;Images&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://assets.iu.edu/brand/3.2.x/trident-large.png&#34; alt=&#34;Image of IU Logo&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-304/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-304/test/</guid>
      <description>
        
        
        &lt;h1 id=&#34;header&#34;&gt;Header&lt;/h1&gt;
&lt;h2 id=&#34;sub-header-with&#34;&gt;Sub Header with&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bulleted&lt;/li&gt;
&lt;li&gt;lists&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sub-header-with-1&#34;&gt;Sub Header with&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Numbered&lt;/li&gt;
&lt;li&gt;Lists&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-305/homework-3/cody_harris_hw3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-305/homework-3/cody_harris_hw3/</guid>
      <description>
        
        
        &lt;h1 id=&#34;square-kilometer-array-ska-use-case&#34;&gt;Square Kilometer Array (SKA) Use Case&lt;/h1&gt;
&lt;p&gt;The SKA is an unprecedented, international, engineering endeavor to create the largest radio telescope in the world. Completion of this project requires the use of state-of-the-art technologies to facilitate the massive amount of data that will be captured [1]. Once this data is captured, it will require advanced high-performance computing centers to make sense of the data and gain valuable insight. While there are many innovative ideas involved with the SKA, this use case will only examine the technologies and processes involved with the solutions directly related to the SKAâ€™s big data needs.&lt;/p&gt;
&lt;h1 id=&#34;what-is-a-radio-telescope&#34;&gt;What is a radio telescope?&lt;/h1&gt;
&lt;p&gt;Before understanding the data needs of the SKA, it is important to understand what a radio telescope is. Many people are familiar with a regular telescope that uses a series of lenses to amplify light waves from distant places to create an image. A radio telescope is similar in the fact that it collects weak electromagnetic radiation from far distances, and then amplifies it so that it can be analyzed. Another application could be to send radio waves towards a direction and then record the reflection off celestial bodies. In any case, the signalâ€™s that astronomers are interested in are extremely weak. Many earthly sources of electro-magnetic radiation are many times greater in strength. There are multiple ways to combat this noise from earth-based radiation, and some of it could be done using hardware, or software, but there are also other ways to combat this that the SKA is utilizing.
Modern radio telescopes accept a wide range of radio frequencies, and then computationally split the frequencies into up to many thousands of channels. To further complicate things, while increasing the efficacy of the radio telescopes, generally more than one telescope is used. This allows multiple positions on the ground to receive the same radio signal, but at slightly different times and slightly different phases of the waveform. This variation allows for more complex analysis of the radio signal. Obviously, this adds another step in the computational work, but having a large array of radio telescopes is imperative to accomplish most modern astronomical research goals [2].&lt;/p&gt;
&lt;h1 id=&#34;science-goals&#34;&gt;Science Goals&lt;/h1&gt;
&lt;p&gt;The vast size of the SKA project allows the exploration of a variety of burning questions that not only intrigue astrophysicists, but nearly everyone on the planet. One overreaching design goal of the SKA is to have a design flexible enough that it can be used as a â€œdiscovery machineâ€ for the â€œexploration of the unknownâ€. With that said, there are five broad research goals of the SKA [3].&lt;/p&gt;
&lt;h2 id=&#34;galaxy-evolution-and-dark-energy&#34;&gt;Galaxy Evolution and Dark Energy&lt;/h2&gt;
&lt;p&gt;As a central goal of the SKA, this is quite a broad question that requires a great deal of study to fully understand. With the data gathered, researchers how to understand fundamental questions about how galaxies change over the course of their lifetimes. One problem with studying this, is that most galaxies nearest to us are so far along in their evolution that it is hard to know what happens in the early years of the galaxy. We can overcome this challenge with SKA, due to its â€œsensitivity and resolutionâ€. The SKA will be able to focus on younger galaxies that are much earlier in their evolution to study what our galaxy was like shortly after the big bang.
To gain an understanding of the creation and evolution of galaxies, a study of dark energy must be done. While this mysterious energy has made headlines in the past decade, it is still the subject of a lot of speculation. As gravity is a main driving factor in the evolution of cosmic objects, understanding dark energy is needed to gain a full picture of what is happening in galactical evolution. Currently our fundamental physical theories, derived by Einstein, suggest that universal expansion should be slowing, but it is not. This is where dark energy plays a part in the formation of our universe [4].&lt;/p&gt;
&lt;h2 id=&#34;was-einsteins-theory-of-relativity-correct&#34;&gt;Was Einsteinâ€™s theory of relativity, correct?&lt;/h2&gt;
&lt;p&gt;It is a tall order to question the most influential physicist in history. Technology is catching up with our theoretical understanding of physics so that we can test fundamental theories that we have held true for many years. The SKA hopes to use its incredible sensitivity to investigate gravitational waves from extremely powerful sources of gravity such as black holes. While Einsteinâ€™s theories are very likely to be mostly true, they might not be fully complete and that is what SKA hopes to find out [1].&lt;/p&gt;
&lt;h2 id=&#34;what-are-the-sources-of-large-magnetic-fields-in-space&#34;&gt;What are the sources of large magnetic fields in space?&lt;/h2&gt;
&lt;p&gt;We know that our earth creates a magnetic field that is imperative for life to exist. For the most part we understand that this is due to the composition and actions of the core of the planet. When it comes to the origin of magnetic fields in space, we are not completely sure what creates all the fields. The study of these magnetic fields will allow further study of the evolution of galaxies and our universe [5].&lt;/p&gt;
&lt;h2 id=&#34;what-are-the-origins-of-our-universe&#34;&gt;What are the origins of our universe?&lt;/h2&gt;
&lt;p&gt;This is a burning question that we have some theories about, but still have a great deal of exploration to do on the topic. The prevailing theory relies on the big bang, but the SKA hopes to further study the eras shortly after the big bang to gain insight into the origins of our universe. The SKA hopes to do this by once again using its sensitivity to give the most accurate measurements of the initial light sources in our universe [6]. As long this question remains unsolved, humans will always want to understand where we all came from.&lt;/p&gt;
&lt;h2 id=&#34;as-living-beings-are-we-alone-in-the-universe&#34;&gt;As living beings, are we alone in the universe?&lt;/h2&gt;
&lt;p&gt;Using Drakeâ€™s equation, and new exoplanet information, scientists are extremely optimistic that life exists somewhere in our universe. In some estimates, what has happened on our planet, could have happened about â€œ10 billion other times over in cosmic history!â€ [7].  One way that SKA can look for extraterrestrial life is by searching for radio signals sent out by advanced civilizations such as ours. Another way that SKA could look for extraterrestrial life is by looking for signs of the building blocks of life. One of these building blocks are amino acids, which can be identified by the SKA.&lt;/p&gt;
&lt;h1 id=&#34;current-progress&#34;&gt;Current Progress&lt;/h1&gt;
&lt;p&gt;The SKA telescopes reside in two separate locations. One location is in Western Australia and will be focused on low frequencies. The second location is in South Africa and will have two arrays, one for mid frequencies, and one for mid to high frequency [8].&lt;/p&gt;
&lt;h2 id=&#34;south-africa&#34;&gt;South Africa&lt;/h2&gt;
&lt;p&gt;Design and preparations for the final SKA implementation are still on-going. Currently there are two arrays named KAT7 and MeerKAT that are installed and functioning and will be the precursor to the SKA arrays in South Africa.&lt;/p&gt;
&lt;h2 id=&#34;australia&#34;&gt;Australia&lt;/h2&gt;
&lt;p&gt;This site also has a precursor to SKA already operating named ASKAP. It is currently located in the same location that the SKAâ€™s major components will eventually occupy, so this will give insights into the performance of this location for radio telescopes. Also, in Australia, as recent as in the past year, prototype antennas are being setup in smaller arrays to capture data and run tests before the design is used in the final array [10].&lt;/p&gt;
&lt;h1 id=&#34;big-data-challenges-and-solutions&#34;&gt;Big Data Challenges and Solutions&lt;/h1&gt;
&lt;p&gt;The SKA presents many big data challenges, from preprocessing to long-term storage of data. The estimated output of all the telescopes is around 700 PB per year [12].&lt;/p&gt;
&lt;h2 id=&#34;raw-data-and-preprocessing&#34;&gt;Raw Data and Preprocessing&lt;/h2&gt;
&lt;p&gt;The data comes in the form of an analog radio signals that are collected over a vast geographical area. At some point, to do analytics on the data, the data needs to be converted from analog to digital. While this is usually done via hardware, and is not on computational machines, this is still a data processing step that must be done at scale.
There is also some preprocessing of the data, that must happen constantly as data is collected. While this could be done once reaching the supercomputer, it is a repetitive task that could be done using FPGAs. The benefit of using a FGPA is that it can parallel process in many more threads and do repetitive algorithms faster and with less power as normal CPUs [12].&lt;/p&gt;
&lt;h2 id=&#34;storage-and-access&#34;&gt;Storage and Access&lt;/h2&gt;
&lt;p&gt;As mentioned previously, the estimated data output of the telescope at peak is 700 PB. The initiative also hopes to save all data for the lifetime of the project which is around 50 years. This ends up being in the realm of needing to eventually store 35 EB of data. For more immediate storage, the SKA team plans to use a buffer system. The way this works is by having a large array of fast read and write storage devices such as SSDs and NVMe (a specialized SSD). This buffer will immediately take in the data as it is coming in at rates that require write speeds that are not as prevalent with traditional spinning disks. After being written to this buffer, they will slowly move the data onto more affordable solutions, that have slower read/write speeds.
While the team could use SSDs for the entire storage, the cost would be enormous. It is much more cost effective to have most of the data stored on hard disk. When it comes to long-term storage of data, even cheaper sources of data such as tape drives could be utilized. After a certain time from data collection, the data will be opened up to the public, this means that the data will likely not end up in a cold storage system [12].&lt;/p&gt;
&lt;h2 id=&#34;processing-of-data&#34;&gt;Processing of data&lt;/h2&gt;
&lt;p&gt;Currently, the processing of data will be done at a large network of sites that will be made up of a variety of technologies. Mostly, no new high-performance computing centers will be created. Existing infrastructures, including public clouds will be used for the processing of data. Along with using FPGAs for pre-processing and possibly more processing afterwards, the SKA team plans to use GPU accelerators to allow for efficient processing.
Each team of researchers will have various goals that they will want from the data. This means that they will have a variety of processing needs, which will be carried out in SKA Regional Centers (SRCs). This might mean machine learning programs to get insights from the data, all the way to other mathematical operations to make the data ready for study. In any case, it is the expectation that this additional data is preserved as well, leading to even more data needing to be managed [12].&lt;/p&gt;
&lt;h2 id=&#34;other-challenges&#34;&gt;Other Challenges&lt;/h2&gt;
&lt;p&gt;While this data is not the most sensitive data on the planet, it is important that security is considered. The SKA team is planning on creating a sort of firewall between users and the actual HPC centers by using an AAAI (authorization, access, authentication, and identification) system. Security of proprietary data will be a concern that will have to be addressed. As there is a large team working on the project, as well as many external actors, security becomes extremely complex, especially the more access points there are to the data [12].
A project this large and versatile requires the use of many software tools. These software tools generally need some level or automatic communication if they are used together in a project. With a large number of tools, there becomes a complex IT infrastructure that needs to be managed, and constantly monitored. It is possible for one tool to receive a critical update, and then cause issues with integration of other software systems.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &amp;ldquo;Square Kilometre Array - ICRAR&amp;rdquo;, ICRAR, 2020. [Online]. Available: &lt;a href=&#34;https://www.icrar.org/our-research/ska/&#34;&gt;https://www.icrar.org/our-research/ska/&lt;/a&gt;. [Accessed: 23- Sep- 2020].&lt;br&gt;
[2] &amp;ldquo;What are Radio Telescopes? - National Radio Astronomy Observatory&amp;rdquo;, National Radio Astronomy Observatory, 2020. [Online]. Available:                                              &lt;a href=&#34;https://public.nrao.edu/telescopes/radio-telescopes/&#34;&gt;https://public.nrao.edu/telescopes/radio-telescopes/&lt;/a&gt;. [Accessed: 23- Sep- 2020].&lt;br&gt;
[3] &amp;ldquo;SKA Science - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available: &lt;a href=&#34;https://www.skatelescope.org/science/&#34;&gt;https://www.skatelescope.org/science/&lt;/a&gt;. [Accessed: 24-      Sep- 2020].&lt;br&gt;
[4] &amp;ldquo;Galaxy Evolution, Cosmology and Dark Energy - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available:      &lt;a href=&#34;https://www.skatelescope.org/galaxyevolution/&#34;&gt;https://www.skatelescope.org/galaxyevolution/&lt;/a&gt;. [Accessed:      24- Sep- 2020].&lt;br&gt;
[5] &amp;ldquo;Cosmic Magnetism - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available: &lt;a href=&#34;https://www.skatelescope.org/magnetism/&#34;&gt;https://www.skatelescope.org/magnetism/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[6] &amp;ldquo;Probing the Cosmic Dawn - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available: &lt;a href=&#34;https://www.skatelescope.org/cosmicdawn/&#34;&gt;https://www.skatelescope.org/cosmicdawn/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[7] L. Sierra, &amp;ldquo;Are we alone in the universe? Revisiting the Drake equation&amp;rdquo;, Exoplanet Exploration: Planets Beyond our Solar System, 2020. [Online]. Available: &lt;a href=&#34;https://exoplanets.nasa.gov/news/1350/are-we-alone-in-the-universe-revisiting-the-drake-equation/&#34;&gt;https://exoplanets.nasa.gov/news/1350/are-we-alone-in-the-universe-revisiting-the-drake-equation/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[8] &amp;ldquo;Design - ICRAR&amp;rdquo;, ICRAR, 2020. [Online]. Available: &lt;a href=&#34;https://www.icrar.org/our-research/ska/design/&#34;&gt;https://www.icrar.org/our-research/ska/design/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[9] &amp;ldquo;Africa - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available: &lt;a href=&#34;https://www.skatelescope.org/africa/&#34;&gt;https://www.skatelescope.org/africa/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[10] Square Kilometre Array, Building a giant telescope in the outback - part 2. 2020.&lt;br&gt;
[11] &amp;ldquo;Australia - Public Website&amp;rdquo;, SQUARE KILOMETRE ARRAY, 2020. [Online]. Available: &lt;a href=&#34;https://www.skatelescope.org/australia/&#34;&gt;https://www.skatelescope.org/australia/&lt;/a&gt;. [Accessed: 24- Sep- 2020].&lt;br&gt;
[12] Filled in Use Case Survey for SKA&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-305/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-305/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;how-big-data-technologies-can-improve-indoor-agriculture&#34;&gt;How Big Data Technologies Can Improve Indoor Agriculture&lt;/h1&gt;
&lt;p&gt;Cody Harris, &lt;a href=&#34;mailto:harrcody@iu.edu&#34;&gt;harrcody@iu.edu&lt;/a&gt;, fa20-523-305&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;TBD&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#topic-discussion&#34;&gt;Topic Discussion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#dataset&#34;&gt;Dataset&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#getting-a-good-grade&#34;&gt;Getting a Good Grade&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#data-storage-and-streaming&#34;&gt;Data Storage and Streaming&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#analytics&#34;&gt;Analytics&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#hardware&#34;&gt;Hardware&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#novel-ideas&#34;&gt;Novel Ideas&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#extensions&#34;&gt;Extensions&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; agriculture&lt;/p&gt;
&lt;h2 id=&#34;topic-discussion&#34;&gt;Topic Discussion&lt;/h2&gt;
&lt;p&gt;The overall topic of the project will include investigating how a host of Big Data technologies could be leveraged to improve multiple facets of the growing and distribution process for indoor farmers. One of the biggest benefits of growing indoors is the ability to precisely control the growing environment. From the light intensity and spectrum, to the nutrients given to the plant, there is an optimal combination of variables that produce the best results. Each farmer has priorities, whether those are yield, produce quality or a combination of various factors, it is a complex system that requires experimentation and robust tools to see the best results. There are a host of IoT sensors and controllers that can be employed to help monitor and control the growing environment, these all produce vast amounts of data that must be sifted through to extract insights. For sizeable farms, this produces big data problems that must be overcome.&lt;/p&gt;
&lt;p&gt;While some insights from the data can come during or directly after the growing â€œseasonâ€, some requires the produce to hit the shelves or to be used to create various food products. This means monitoring continues through the logistics process, and this data is integral when it comes to the end result of the produce. All this data allows for traceability in the food supply chain as well, in which big data technologies are perfect to handle.&lt;/p&gt;
&lt;p&gt;The end goal is to investigate and implement a scalable solution that follows the farmers crops from seed to consumers tables and optimizes the process along the way. Although indoor farms allow for great control, it is important to understand that there are many costs that are not associated with traditional farms. This means that to make the farming endeavor sustainable, optimization is important.&lt;/p&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;There are not any publicly available data sources that meet the needs of this project. In order to accomplish the goal of building an analytics platform for an indoor farm and the related logistics, simulation data will be created. The simulation data will encompass many different situations that could be encountered and labeled by these issues. Along with possible issues, the data will include mostly satisfactory situations, as this is what the farmer is most likely to encounter.&lt;/p&gt;
&lt;p&gt;The majority of the data being worked with will be streaming sensor data. The sensors will include: PAR (Photosynthetically Active Radiation), temperature, humidity, pH of grow medium, and CO2. Along with these streaming measurements, other data points about the specific grow area will be taken. A grow area could be as small as a row of ten plants, all the way to thousands of plants. These datapoints could be things such as phenotype, light spectrum, light cycle, feeding schedule, or any other labels that could be beneficial in determining the end attributes of the given produce.&lt;/p&gt;
&lt;p&gt;Variance in the data will come in a variety of forms. As completely identical data is not analogous to real life, it can be for certain measurements. For example, in an indoor growing environment equipped with HVAC, the temperature might only fluctuate a few percent all day, and then have a rapid change as the lights are turned off. With this in mind, certain simulation measurements should not have a great deal of noise in them unless trying to simulate an adverse event.&lt;/p&gt;
&lt;p&gt;As this data is streaming, the dataset will be a time series that needs to be handled in the sense of streaming as well as in a postmortem capacity. The size of the data should be large enough to properly simulate a large farm over the course of a grow cycle. This data set will simulate an experiment, in which a variety of conditions or phenotypes will be compared to a control. Within the realm of the experiment the simulation data might include adverse events, such as a power outage, that could actually occur during an experiment and these adverse events must be accounted for in the end conclusion.&lt;/p&gt;
&lt;h2 id=&#34;getting-a-good-grade&#34;&gt;Getting a Good Grade&lt;/h2&gt;
&lt;p&gt;As I am a graduate student, I am expected to not only write a report, but also create a software component. For the software, it will be a proof of concept to show that a scalable solution could be built to use open source big data technologies. The report will detail the work done in the solution being built, as well as exploring ideas that cannot be built but are required for the full solution to be implemented.&lt;/p&gt;
&lt;h3 id=&#34;data-storage-and-streaming&#34;&gt;Data Storage and Streaming&lt;/h3&gt;
&lt;p&gt;With a focus on open source platforms, Apache has solutions that can be leveraged to handle many aspects of big data streaming and storage in a distributed computing environment. While more investigation needs to be done on the exact software that will be used, Hadoop, Spark, or the combination of the two will be used to handle the large amount of data, whether that is for longer term storage or real time streaming. Another Apache system that will be evaluated is Kafka, but again, there are many possibly solutions to be used. The goal is to stay within the Apache environment as it is widely used in industry as well as is an open source platform.&lt;/p&gt;
&lt;h3 id=&#34;analytics&#34;&gt;Analytics&lt;/h3&gt;
&lt;p&gt;The analytics component of this project is diverse. While all goals might not be able to be achieved in the proof of work, all of the data needs that are required for the growing and logistics processes of an indoor farm will be evaluated and explained in the final report. There are two main components to the analytics: real time analytics and historic data analysis. While some models are being fine tuned for the specific farm, the real time analytics will likely be mostly monitoring at the beginning. As grow seasons go by and metrics are collected on the harvest, the real time analytics will be informed by the historic data using some sort of machine learning processes. These analytic goals can likely be completed using tools within Spark, using MLlib. If this cannot be accomplished, then another library will be used such as sci-kit learn.&lt;/p&gt;
&lt;h3 id=&#34;hardware&#34;&gt;Hardware&lt;/h3&gt;
&lt;p&gt;It is important that the proof of concept is designed for a distributed computing environment. The goal is to create open source software that can be used by small farms that sell solely at farmers markets, all the way to large commercial operations. When designing in this way, growing pains in the future can be minimized. For the hardware being used, multiple solutions are being evaluated. The first possible idea is using a commercial cloud application such as AWS, Azure, Google Cloud, etc. Secondly, personal local hardware could be used to create a virtual distributed computing environment. There are two options for local hardware. Either a personal computer with multiple virtual machines, or an array of Raspberry Piâ€™s will be used.&lt;/p&gt;
&lt;h3 id=&#34;novel-ideas&#34;&gt;Novel Ideas&lt;/h3&gt;
&lt;p&gt;Everything that has already been explained has more or less been attempted or implemented successfully. The innovation comes by trying to implement some ideas that are fresh by borrowing ideas and implementing them in the context of an indoor produce farm. The first big deviation from the norm is using a blockchain backbone to store immutable data. This idea is used in some niche farming scenarios but is yet to be adopted by produce farmers. Blockchain could be used to hold the logistical data to establish immutable custody data, but also to store the data from the growing process, pesticides tests, chemical makeup tests, genetic markers and more. Next, in the spirit of providing transparency there will be a public blockchain that could be explored by consumers or businesses that buy the farmers produce. In todayâ€™s world, we always wonder if we are paying some premium for products in order to just have a special label on that product. For this example, the label is: organic, GMO free, pesticide free, etc. Transparency goes a long way to prove to consumers that you are doing more for them to provide a good product, which allows for a greater amount that people are willing to spend. Some data might be proprietary, such as the exact genome of the phenotypes being used, or the specific growing protocols, so this information must stay off the blockchain.&lt;/p&gt;
&lt;h3 id=&#34;extensions&#34;&gt;Extensions&lt;/h3&gt;
&lt;p&gt;Not everything can be built or examined completely within the time constraints. Part of the project will be planning future updates or technologies that could improve the solution. One immediate future plan would be to incorporate cameras and computer vision to monitor the crops. Using images of plants, certain diseases, pests, or nutrient deficiencies can be seen as soon as they start to develop, giving the farmer the best odds at reversing the issue without effecting the harvest. Many of these issues cannot be greatly noticed with sensor data alone, which requires a farmer to constantly visually inspect crops. While this might not be terribly hard in some cases, some vertical grows might require large ladders to see all levels of the crop. This improvement could lead to less staff being required, which can allow more farmers to grow more for less money.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-305/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-305/test/</guid>
      <description>
        
        
        &lt;p&gt;Testing if I have write access to this repo.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-307/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-307/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;analysis-of-financial-markets-based-on-president-trumps-tweets&#34;&gt;Analysis of Financial Markets based on President Trump&amp;rsquo;s Tweets&lt;/h1&gt;
&lt;p&gt;Alex Baker, fa20-523-307, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-307/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Financial markets can be unpredictable as is but this unpredictability is increased by one man&amp;rsquo;s Twitter account, President Trump. My goal is to use Twitter and finance datasets to see how these tweets affect the market.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-datasets&#34;&gt;2. DataSets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-methodologyprocess&#34;&gt;3. Methodology/Process&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-technologies-used&#34;&gt;4. Technologies used&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-references&#34;&gt;5. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; analysis, finance, stock markets, politics&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;For the final project, my focus will be on financial market reactions through the President&amp;rsquo;s tweets. The plan is to utilize President Trump&amp;rsquo;s tweets and stock market data to predict the market reaction based on what is going to be published. A feature that is being introduced is a way to craft tweets based on historical data to see how the markets will react if a tweet such as that is published. This can be useful to see how news from the president can cause an increase or decline in markets.&lt;/p&gt;
&lt;h2 id=&#34;2-datasets&#34;&gt;2. DataSets&lt;/h2&gt;
&lt;p&gt;The datasets that will be used are the tweets from President Trump&amp;rsquo;s personal account as well as Yahoo fiance data. These will be gathered from their respected APIs. If needed, the following dataset from Kaggle (&lt;a href=&#34;https://www.kaggle.com/austinreese/trump-tweets?select=trumptweets.csv&#34;&gt;https://www.kaggle.com/austinreese/trump-tweets?select=trumptweets.csv&lt;/a&gt;) can be used in replace of Twitter&amp;rsquo;s API for President Trump&amp;rsquo;s tweets but are only available up to June 2020. Which leads to the objective for the project, based on the data collected, the program should be able to visualize and predict how the market will react when President Trump send out a tweet.&lt;/p&gt;
&lt;p&gt;The data will span from President Trumps inauguration to the current day. To strengthen the prediction, even more, some code from the 2016 electionâ€™s analysis of markets may be utilized but the focus will be on the markets during the Trump administration. Rally data maybe introduced in order to have a deeper sense of some of the tweets when it comes to important news that is announces at President Trump&amp;rsquo;s rallies. In order to have a realistic and strong prediction, the financial data needs to be aligned with the timing of tweets but news that has already started to affect the markets before a tweet has been sent out needs to be taken into account.&lt;/p&gt;
&lt;h2 id=&#34;3-methodologyprocess&#34;&gt;3. Methodology/Process&lt;/h2&gt;
&lt;p&gt;The collection of finance and Twitter data will be used to visualize and predict the results. Some of Twitter or dataset data will need to be cleaned and classified to build the model. The methodology is composed of the following steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use data from President Trump&amp;rsquo;s personal twitter to help visualize and create the model&lt;/li&gt;
&lt;li&gt;Use data from Yahoo finance API to help visualize and create the model&lt;/li&gt;
&lt;li&gt;Data cleaning and extraction.&lt;/li&gt;
&lt;li&gt;New data will be updated to keep up with the current time.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4-technologies-used&#34;&gt;4. Technologies used&lt;/h2&gt;
&lt;p&gt;Python, Jupyter notebook or collab, Pandas, Scikit-learn, Tensorflow/PyTorch&lt;/p&gt;
&lt;h2 id=&#34;5-references&#34;&gt;5. References&lt;/h2&gt;
&lt;p&gt;TBD&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-308/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-308/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;nfl-regular-season-skilled-position-player-performance-as-a-predictor-of-playoff-appearance&#34;&gt;NFL Regular Season Skilled Position Player Performance as a Predictor of Playoff Appearance&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please follow our template&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; improve markdown skills&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; use footnotes as refernces, learn how to do this, read our piaza posts&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Travis Whitaker &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-308&#34;&gt;fa20-523-308&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;The dataset we will be using is in a github folder that holds nflscrapR-data that originates from NFL.com [1]. The folder includes play-by-play data, including performance measures, for all regular season games from 2009 to 2019. This file will be paired with week-by-week regular season roster data for each team in the NFL. This will allow me to track skilled position player performance during the regular season and then compare this regular season file with the files that contain playoff teams for each year from 2009-2019. Supplemental data may be pulled from Pro-Football-Reference.com or other sources depending on what preliminary data analysis presents [2].&lt;/p&gt;
&lt;h2 id=&#34;what-needs-to-be-done-to-get-a-great-grade&#34;&gt;What needs to be done to get a great grade&lt;/h2&gt;
&lt;p&gt;The first step we am planning to take in understanding the data will be to use various slices of the data put into scatterplots and bar charts to find correlations and trends, as well as various time series charts. This will be an exploratory step in understanding the data. we may also deploy area charts to observe any interesting trends or segments of our data that may warrant additional analysis.&lt;/p&gt;
&lt;p&gt;Then each metric from player performance during the regular season will be included in the analysis or algorithm that will be built to predict playoff appearance. Playoff appearance is a designation for a team qualifying for the post-season or playoffs. We am thinking it may be important to engineer some new features to potentially provide insights.  For instance, it is possible to determine whether a play was during the final two minutes of a half and if a play was in the red zone. During these critical points of a game a win or lose is often determined. So my thought is by weighing these moments and performance metrics with more importance in an algorithm the machine will better predict a teamâ€™s likelihood of making the playoffs. Another secondary metric that may strengthen the predictive ability of the algorithm would be to use Football Outsiderâ€™s Success Rate, which is a determination of a playâ€™s success rate for the offense that is on the field [2]. This can also provide me with the down and distance to go for the offense and players that are on the field. We will also use college position designations as way to normalize the positions performance across teams. Many NFL teams utilize different player sets. Thus, it is important to use a standard, which college football uses across all teams. Since we am only interested in skill position players this will include Wide Receiver (WR), Running Back (RB), Full Back (FB), Quarterback (QB), and Tight End (TE). These designations will allow the algorithm to compare, if needed, the skill position performance across teams and by designation of players on that team for each metric utilized.&lt;/p&gt;
&lt;p&gt;After breaking down the data into key categorical variables to see if there was an impact for these performance variables in making the playoffs for the NFL teams. These individual position statistics will need to be paired with their teammateâ€™s performance metrics so that each team is represented by all of their skill position players. It is often debated as to which position is most important in football and whether a QB is critical to a successful post-season appearance. My hope is that by combining each skill position player onto their respective team we will be able to better determine the importance of success at each position by whether or not that team made the playoffs. Further, it will be important to see whether roster makeup across teams varies by position. If roster makeup is stable than we will not need to combining positions. However, if roster makeup varies, we will need to combine positions into a larger group instead of two subgroups. The concern here is the deployment of WR over TE. Some teams may carry more TE than others and fewer WR. Therefor we would need to combine WR and TE into a group called Designated Receiver (DR).&lt;/p&gt;
&lt;p&gt;Metric measurement needs to be consistent across years. A comparison of year-to-year metrics will need to be done comparing each years measurements from 2009-2019 in order to make sure that the measurement techniques are stable and do not vary across time. If there are changes in the way metrics are measured than either that year will need to be dropped from the model or adjustments will need to be made to the metric to balance it with the other years included in the model.&lt;/p&gt;
&lt;p&gt;Finally, once all metrics have been balanced and the team performance metrics have been aggregated. The algorithm will need to be implemented to identify the eight best teams from each NFL division and the two best other teams in the conference that would constitute the wild card playoff teams from each conference. Once this analysis is run, we will be able to look at retroactive NFL post-season designated teams from 2009-2019 to see how accurate the playoff prediction machine was at identifying NFL post-season teams for each year.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Ryurko. Ryurko/NflscrapR-Data. 2 Mar. 2020, github.com/ryurko/nflscrapR-data.
[2] Sports Reference, LLC. â€œPro Football Statistics and History.â€  Retrieved October 09, 2020. &lt;a href=&#34;https://www.pro-football-reference.com/&#34;&gt;https://www.pro-football-reference.com/&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-308/project/task_3_next_steps/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-308/project/task_3_next_steps/</guid>
      <description>
        
        
        &lt;h1 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h1&gt;
&lt;p&gt;I am still not 100% that this is the project I want to complete. As the instructions for HW 5 laid out, we do not have to fully commit at this point to the project. I may try to work on a basic deep learning project that can introduce me to that type of work. Next steps for the project I have started here would be to complete the basic descriptive data modeling in charts. Then would be to model the data and pull in the playoff teams from 2009-2019 to compare the model output with the playoff team that qualified for the playoffs. I want to work on this over the next month before moving onto the writing portion of the project.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-309/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-309/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;detecting-heart-disease-using-machine-learning-classification-techniques&#34;&gt;Detecting Heart Disease using Machine Learning Classification Techniques&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please follow our template&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ethan Nguyen&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Since cardiovascular diseases are the number 1 cause of death globally, early prevention could help in extending oneâ€™s life span and possibly quality of life. Since there are cases where patients do not show any signs of cardiovascular trouble until an event occurs, having an algorithm predict from their medical history would help in picking up on early warning signs a physician may overlook. Or could also reveal additional risk factors and patterns for research on prevention and treatment.&lt;/p&gt;
&lt;p&gt;It has been decided for this project to take a high-level overview of the common, widely available classification algorithms and analyze their effectiveness for this specific use case. Notable ones include, Gaussian Naive Bayes, Logistic Regression, K-Nearest Neighbors, and Support Vector Machines.&lt;/p&gt;
&lt;p&gt;Additionally, a variety of data sets that contain common information types will be used to increase the training and test pool for evaluation. As it is known that a large set of data is required to reduce the possibility of the algorithmâ€™s overfitting.&lt;/p&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/andrewmvd/heart-failure-clinical-data&#34;&gt;https://www.kaggle.com/andrewmvd/heart-failure-clinical-data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/johnsmith88/heart-disease-dataset&#34;&gt;https://www.kaggle.com/johnsmith88/heart-disease-dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/ronitf/heart-disease-uci&#34;&gt;https://www.kaggle.com/ronitf/heart-disease-uci&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The range of creation dates vary from as late as 2 years to as recent of 4 months. This does bring up a small hiccup in preprocessing to consider. Namely the possibility of changing diet and culture trends resulting in significantly different trends/patterns within the same age group.&lt;/p&gt;
&lt;p&gt;This possible phenomenon may be of interest to explore closely if time allows. Whether a trend itself is even present or there is an overarching trend across different cultures and time periods. Or to consider if this difference is significant enough that the data from the various sets needs to be adjusted to normalize the ages to present day.&lt;/p&gt;
&lt;h2 id=&#34;what-needs-to-be-done-to-achieve-a-great-grade&#34;&gt;What needs to be done to achieve a great grade&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;A report analyzing the results and outlining the procedure of the project.&lt;/li&gt;
&lt;li&gt;The report satisfies the minimum length requirement and complies with the additional requirements outlined in the project pdf&lt;/li&gt;
&lt;li&gt;Searching and curating a large data set on heart disease&lt;/li&gt;
&lt;li&gt;A software component that preprocesses and trains various machine learning algorithms on the chosen dataset&lt;/li&gt;
&lt;li&gt;The trained algorithms are tuned to a reasonable degree to obtain the maximum performance possible within the project timeframe&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;strech-goals-for-the-project&#34;&gt;Strech goals for the project&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Further analysis of the datasets to see if the age between the creation/release date reveal any shifts over time&lt;/li&gt;
&lt;li&gt;What occurs when the data set is normalized based on creation/release date to the newest set and if they reveal any other interesting trends&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-312/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-312/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;aquatic-toxicity-analysis-with-the-aid-of-autonomous-surface-vehicle-asv&#34;&gt;Aquatic Toxicity Analysis with the aid of Autonomous Surface Vehicle (ASV)&lt;/h1&gt;
&lt;p&gt;Saptarshi Sinha, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-312/&#34;&gt;fa20-523-312&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-312/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;With the passage of time, human activities have created and contributed much to the aggrandizing problems of various forms of environmental pollution. Massive amounts of industrial effluents and agricultural waste wash-offs, that often comprise pesticides and other forms of agricultural chemicals, find their way to fresh water bodies, to lakes, and eventually to the oceanic systems. Such events start producing a gradual increase in the toxicity levels of marine ecosystems thereby perturbing the natural balance of such water-bodies. In this endeavor, an attempt will be made to measure the various water quality metrics (viz. temperature, pH, dissolved-oxygen level, and conductivity) with the help of an autonomous surface vehicle (ASV). This collected data will then be analyzed to ascertain if these values exhibit aberration from the established values that are found from USGS and EPA databases for water-quality standards. In the event, the collected data significantly deviates from the standard values of unpolluted sources in nearby geographical areas, that are obtained from the above databases, it can be concluded that the aquatic system in question has been degraded and may no longer be utilized for any form of human usage, such as being sourced for drinking water.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-choice-of-data-sets&#34;&gt;3. Choice of Data-sets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-methodology&#34;&gt;4. Methodology&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#41-hardware-component&#34;&gt;4.1 Hardware Component&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#42-software-component&#34;&gt;4.2 Software Component&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-inference&#34;&gt;5. Inference&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-conclusion&#34;&gt;6. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#8-references&#34;&gt;8. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; toxicology, pollution, autonomous systems, surface vehicle, sensors, arduino, water quality, data analysis, environment, big data, ecosystem&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;When it comes to revolutionizing our qualities of life and improving standards, there is not another branch of science and technology that has made more impact than the myriad technological capabilities offered by the areas of Artificial Intelligence (AI) and its sub-fields involving Computer Vision, Robotics, Machine Learning, Deep Learning, Reinforcement Learning, etc. It should be borne in mind that AI was developed to allow machines/computer processors to work in the same way as the human brain works and which could make intelligent decisions at every conscious level. It was meant to help with tasks for rendering scientific applications more smarter and efficient. There are many tasks that can be performed in a far more dexterous fashion by employing smart-machines and algorithms than by involving human beings. But even more importantly, AI has also been designed to perform tasks that cannot be successfully completed by employing human beings. This could either be due to the prolonged boredom of the task itself, or a task that involves hazardous environments that cannot sustain life-forms for a long time. Some examples in this regard would involve exploring deep mines or volcanic trenches for mineral deposits, exploring the vast expanse of the universe and heavenly bodies, etc. And this is where the concept employing AI/Robotics based technology fits in perfectly for aquatic monitoring and oceanographical surveillance based applications.&lt;/p&gt;
&lt;p&gt;Toxicity analysis of ecologically vulnerable water-bodies, or any other marine ecosystem for that matter, could give us a treasure trove of information regarding biodiversity, mineral deposits, unknown biophysical phenomenon, but most importantly, it could also provide meaningful and scientific information related to the biodegradation of the ecosystem itself. In this research project, an attempt will be made to design a simple foundation of an aquatic Autonomous Surface Vehicle (ASV) that will be deployed in marine ecosystems. Such a vehicle would be embedded with different kind of electronic sensors, that are capable of measuring physical quantities such as temperature, pH, conductance, dissolved oxygen level, etc. The data collected by such a system can either be over a period of time (temporal data), or it could cover a vast aquatic geographical region (spatial data). This data will then be compared with existing datasets that are made publicly available by various environmental organizations in the United States, most importantly the Environmental Protection Agency (EPA) and the US Geological Survey (USGS). A comparative data analysis task between the data collected by the ASV and the vast array of environmental data that are made available from these agencies can then give us an indication about the status of the aquatic degradation of the ecosystem in question by measuring the extent to which the current data deviates from relevant historical data trends.&lt;/p&gt;
&lt;h2 id=&#34;2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/h2&gt;
&lt;p&gt;After reviewing the necessary background literture and previous work that has been done in this field, it can be stated that most of such endeavors focussed majorly on continuous environmental data collection with the help of sensors attached to a stationary buoy in a particular location of a water-body. Some of the other endeavors did involve deploying a non-stationary vehicle that collected data from large swaths of geographical areas in various water bodies &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, while some others focussed on niche areas involving migration pattern exhibited by zooplanktons upon natural and aritifical irradiance &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. However, neither did such attempts focus much on the data analysis portion for multiple sensory input(s) nor did it involve an intricate procedure to compare the collected data with historical trends so as to arrive at a suitable conclusion regarding the extent of environmental degradation.&lt;/p&gt;
&lt;p&gt;As mentioned in the previous section, this research project will exhaustively focus not just on the data-collection portion by a non-stationary vehicle, but it will also involve employing deeper study towards the subject of big-data analysis of both the current data of the system in question and the past data obtained for similar aquatic profiles. In this way, it would be possible to learn more about the toxicological aspects of the ecosystem in question.&lt;/p&gt;
&lt;h2 id=&#34;3-choice-of-data-sets&#34;&gt;3. Choice of Data-sets&lt;/h2&gt;
&lt;p&gt;Upon exploring a wide array of available datasets, the following data repositories were chosen to get the required water quality based data over a particular period of time and for a particular geographical region.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;USGS Water Quality Data: &lt;a href=&#34;https://waterdata.usgs.gov/nwis/qw&#34;&gt;https://waterdata.usgs.gov/nwis/qw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;EPA Water Quality Data: &lt;a href=&#34;https://www.epa.gov/waterdata/water-quality-data-download&#34;&gt;https://www.epa.gov/waterdata/water-quality-data-download&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To answer the questions involving existence of multiple data-sets and motivation of using multiple data-sets, we must keep in mind that the very nature of this study is based on historical trends of the nature of water-quality in a particular region from the past and how it relates to the current situation. Because of these reasons, multiple data-sets will be referred to from multiple sources so as to achieve robust data-analytical results. This would ensure that too much focus is not given on outlier cases, that may be relevant to just a particular geographical region or an aberration in the data that may only have arisen due to an unknown underlying phenomenon or some form of cataclysmic event from the past. Using multiple datasets from different sources would help to get a resultant data structure that is more likely to converge towards an approximate level of historical thresholds and which can then be used to find out how the current observed data deviates from such previous patterns.&lt;/p&gt;
&lt;h2 id=&#34;4-methodology&#34;&gt;4. Methodology&lt;/h2&gt;
&lt;h3 id=&#34;41-hardware-component&#34;&gt;4.1 Hardware Component&lt;/h3&gt;
&lt;p&gt;A very rough outline of the autonomous surface vehicle (ASV) in question has been preceived in the Autodesk Fusion 360 software model. A preliminary model has been designed in this software so as to 3D print the system. It will then be interfaced with the appropriate sensors in question. Then system will be driven by an Arduino-Uno based microcontroller, and it will have different types of environmental sensors that will collect and log data. These sensors have been purchased from the vendor, &amp;ldquo;Atlas Scientific&amp;rdquo;. As of now, the sensors that have been chosen for this ASV are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PT-1000 Temperature sensor kit - &lt;a href=&#34;https://atlas-scientific.com/kits/pt-1000-temperature-kit/&#34;&gt;https://atlas-scientific.com/kits/pt-1000-temperature-kit/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Potential of Hydrogen (pH) sensor kit - &lt;a href=&#34;https://atlas-scientific.com/kits/ph-kit/&#34;&gt;https://atlas-scientific.com/kits/ph-kit/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Dissolved Oxygen (DO) sensor kit - &lt;a href=&#34;https://atlas-scientific.com/kits/dissolved-oxygen-kit/&#34;&gt;https://atlas-scientific.com/kits/dissolved-oxygen-kit/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Conductivity K 1.0 sensor kit - &lt;a href=&#34;https://atlas-scientific.com/kits/conductivity-k-1-0-kit/&#34;&gt;https://atlas-scientific.com/kits/conductivity-k-1-0-kit/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;42-software-component&#34;&gt;4.2 Software Component&lt;/h3&gt;
&lt;p&gt;After the data has been collected by the ASV either on a temporal scale (over a period of time) or a spatial scale (over a geographical area), it will then be analyzed to decipher the median convergent values of the water body for the four different parameters that have been measured (i.e. Temperature, pH, DO, and Conductivity). The results of this data analysis task will then be used to find out if such water quality parametric values manifested by the aquatic ecosystem in question deviates by a large proportion from the other result that is obtained after analyzing the historical data from USGS and EPA for a nearby and unpolluted source of water. The USGS and EPA websites make it easier to find data from a nearby geographical region by making it possible to enter the desired location prior to searching for water quality data in their huge databases. In this way, it can be figured out if the water quality parameters of the particular ecological system varies wildly from a neighboring system that has almost the same geographical and ecological attributes.&lt;/p&gt;
&lt;p&gt;The establishment of the degree of variance of the data from the historical data will be carried out by documenting the particular quartile range that the current data lies in with respect to the median data that is obtained from the past/historical datasets. For instance, if the current data resides in the second quartile, it can be demarcated as being more or less consistent with previously established values. However, if it resides in the first or third quartile then it might will that the system has aberrant aspects which might need to be investigated for possible levels of outside pollutants (viz. industrial effluents, agricultural wash-off, etc.), or presence of harmful invasive species that might be altering the delicate natural balance of the ecosystem in question.&lt;/p&gt;
&lt;h2 id=&#34;5-inference&#34;&gt;5. Inference&lt;/h2&gt;
&lt;p&gt;This section will be addressed upon project completion.&lt;/p&gt;
&lt;h2 id=&#34;6-conclusion&#34;&gt;6. Conclusion&lt;/h2&gt;
&lt;p&gt;This section will be addressed upon project completion.&lt;/p&gt;
&lt;h2 id=&#34;7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/h2&gt;
&lt;p&gt;The author would like to thank Dr. Gregor Von Laszewski, Dr. Geoffrey Fox, and the associate instructors in the &lt;em&gt;FA20-BL-ENGR-E534-11530: Big Data Applications&lt;/em&gt; course (offered in the Fall 2020 semester at Indiana University, Bloomington) for their continued assistance and suggestions with regard to exploring this idea and also for their aid with preparing the various drafts of this article.&lt;/p&gt;
&lt;h2 id=&#34;8-references&#34;&gt;8. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Valada A., Velagapudi P., Kannan B., Tomaszewski C., Kantor G., Scerri P. (2014) Development of a Low Cost Multi-Robot Autonomous Marine Surface Platform. In: Yoshida K., Tadokoro S. (eds) Field and Service Robotics. Springer Tracts in Advanced Robotics, vol 92. Springer, Berlin, Heidelberg. &lt;a href=&#34;https://doi.org/10.1007/978-3-642-40686-7_43&#34;&gt;https://doi.org/10.1007/978-3-642-40686-7_43&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;M. Ludvigsen, J. Berge, M. Geoffroy, J. H. Cohen, P. R. De La Torre, S. M. Nornes, H. Singh, A. J. SÃ¸rensen, M. Daase, G. Johnsen, Use of an Autonomous Surface Vehicle reveals small-scale diel vertical migrations of zooplankton and susceptibility to light pollution under low solar irradiance. Sci. Adv. 4, eaap9887 (2018). &lt;a href=&#34;https://advances.sciencemag.org/content/4/1/eaap9887/tab-pdf&#34;&gt;https://advances.sciencemag.org/content/4/1/eaap9887/tab-pdf&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-313/project/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-313/project/test/</guid>
      <description>
        
        
        &lt;h2 id=&#34;this-is-testmd&#34;&gt;This is test.md&lt;/h2&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-313/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-313/test/</guid>
      <description>
        
        
        &lt;h2 id=&#34;this-is-testmd&#34;&gt;This is Test.md&lt;/h2&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-314/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-314/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;residential-power-usage-prediction&#34;&gt;Residential Power Usage Prediction&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please use our trivial template posted in piazza&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Siny P Raphel&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Electricity is an inevitable part of our day today life. Most of the electric service providers like duke, dominion provide customers their consumption data so that customers are aware of their usages. Some providers give predictions on their future usages so that they are prepared.
This project is based on the dataset Residential Power Usage 3 years data in Kaggle datasets. The dataset contains data of hourly power consumption of a 2 storied house in Houston,Texas from 01-06-2016 to August 2020. It includes data during the Covid-19 lockdown and are marked as well. We are planning to build a model to predict future usage from available data.
Data is spread across two csv files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;power_usage_2016_to_2020.csv
This file contains basic details of the data like startdate with hour, value of power consumption in kwh, day of the week and notes. It has 4 features and 35953 instances.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-314/blob/master/fig%201.png&#34; alt=&#34;Figure 1&#34; title=&#34;Figure 1&#34;&gt;&lt;/p&gt;
&lt;p&gt;Day of the week is an integer value with 0 being Monday. Notes gives us details like whether that day is weekend, weekday, covid lockdown or vacation. The Figure 1 shows retrieval and first few rows of the data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-314/blob/master/fig%202.png&#34; alt=&#34;Notes&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;weather_2016_2020_daily.csv
This file contains the weather conditions of that particular day. It has 19 features and 1553 instances. Figure 2 shows retrieval and first few rows and columns of this file.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-314/blob/master/Fig%203.png&#34; alt=&#34;Figure 2&#34; title=&#34;Figure 2&#34;&gt;
Units of features are given as below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Temperature    - F deg&lt;/li&gt;
&lt;li&gt;Dew Point      - F deg&lt;/li&gt;
&lt;li&gt;Humidity       - %age&lt;/li&gt;
&lt;li&gt;Wind           - mph&lt;/li&gt;
&lt;li&gt;Pressure       - Hg&lt;/li&gt;
&lt;li&gt;Precipitation  â€“ inch&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will be using python to develop the model. Since the expected outputs are real numbers(power consumption in kWh) we might be using linear regression or similar ones. We will try using gradient descent for optimization. Since the weather data has 19 features we might use feature selection methods to select best features that increase the accuracy of the model.
The data spread across two files will have to be merged according to date. For that the StartDate feature will have to be first split to date and time. Then the two datasets will have to be merged according to the date only. From the initial inspection of the data, the date feature of datasets have some date format issues which will have to be resolved before starting cleaning.&lt;/p&gt;
&lt;p&gt;In this project we will be planning the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Analyze and clean the data&lt;/li&gt;
&lt;li&gt;Visualize the data- study the relationships between features etc.&lt;/li&gt;
&lt;li&gt;Plan one or two algorithms that can be used to model&lt;/li&gt;
&lt;li&gt;Optimize or feature selection of features&lt;/li&gt;
&lt;li&gt;Calculate accuracy of each model&lt;/li&gt;
&lt;li&gt;Conclusion on which algorithm will be best suited to use and the reason for it.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This dataset is chosen because,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There were datasets similar to this one. But this one has latest power usage data till August this year.&lt;/li&gt;
&lt;li&gt;It has marked covid lockdown, vacations, weekdays and weekends which is a challenge for prediction.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/srinuti/residential-power-usage-3years-data-timeseries&#34;&gt;https://www.kaggle.com/srinuti/residential-power-usage-3years-data-timeseries&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-314/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-314/test/</guid>
      <description>
        
        
        &lt;h1 id=&#34;this-is-to-test-markdown&#34;&gt;This is to test markdown&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;bullet&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-316/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-316/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;sentiment-analysis-and-visualization-using-an-us-election-dataset-for-the-2020-election&#34;&gt;Sentiment Analysis and Visualization using an US-election dataset for the 2020 Election&lt;/h1&gt;
&lt;p&gt;Sudheer Alluri Indiana University fa20-523-316
&lt;a href=&#34;mailto:ngsudheer@gmail.com&#34;&gt;ngsudheer@gmail.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vishwanadham Mandala Indiana University fa20-523-316
&lt;a href=&#34;mailto:vmandal@iu.edu&#34;&gt;vmandal@iu.edu&lt;/a&gt;
(&lt;a href=&#34;mailto:vishwandh.mandala@gmail.com&#34;&gt;vishwandh.mandala@gmail.com&lt;/a&gt;)&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Sentiment analysis is an evaluation of the opinion of the speaker, writer or other subject with regard to some topic.We are going to use US-elections dataset and combining the tweets of people opninon for leading presidential candidates. We have various datasets from kallage and combining tweets and NY times datasets, by combining all data predication will be dervied.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-datasets&#34;&gt;2. DataSets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-methodologyprocess&#34;&gt;3. Methodology/Process&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-technologies-used&#34;&gt;4. Technologies used&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-refernces&#34;&gt;5. Refernces&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; sentiment,  US-election&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;For our final project, we will be focusing on the upcoming U.S. presidential elections. We plan to use a US-elections dataset to predict the votes each contestant will attain, by area. With growing data, the prediction will be changing constantly. We are making the difference by selecting the latest dataset available and previous election data to predict the number of votes each contestant will get to the closest figure. A feature we are introducing to enhance the quality is predicting various area types like counties, towns, and/or big cities.
One might argue that these kinds of predictions will only be helping organizations and not individuals. We assure you that this project will be helping the general public in many ways. The most evident being, an individual knowing which contestant his/her community or the general public around him/her prefer. This project is strictly statistical and does not have a goal to sway the elections in any way or to pressure an individual&lt;/p&gt;
&lt;p&gt;into picking a candidate. Overall, this is just a small step towards a future that might hold an environment where the next president of the United States of America could be accurately guessed based on previous data and innovative Big Data Technologies.&lt;/p&gt;
&lt;h2 id=&#34;2-datasets&#34;&gt;2. DataSets&lt;/h2&gt;
&lt;p&gt;We will be going to use the dataset, &lt;a href=&#34;https://www.kaggle.com/tunguz/us-elections-dataset,&#34;&gt;https://www.kaggle.com/tunguz/us-elections-dataset,&lt;/a&gt; and we will create the filets based on location. If needed, we may download Twitter data from posts on and by Donald Trump, Joe Biden, and their associates. Which leads us to our objective for the project, based on the data we collected, we should be able to predict the winner of the 2020 United States of Americaâ€™s presidential elections.&lt;/p&gt;
&lt;p&gt;All of the data will be location-based and if required we will download realtime campaigning and debate analysis data, giving us a live and updated prediction every time increment. To strengthen the prediction, even more, we may reuse some code from the 2016 electionâ€™s analysis, however, our main focus will be using the latest data we readily acquire during the time leading up to the 2020 election.
In conclusion, to make our predictions as realistic and as strong as we can get, we will be going to choose multiple data sets to integrate between the previous election and twitter data to predict the number of votes each candidate will acquire. Therefore, we will be predicting the winner of the 2020 presidential elections.&lt;/p&gt;
&lt;h2 id=&#34;3-methodologyprocess&#34;&gt;3. Methodology/Process&lt;/h2&gt;
&lt;p&gt;We will collect election data and twitter information and integrate both to predict the results. A lot of twitter or dataset data will be trimmed and parsed to build the model. We will calculate
Our data-gathering and preparation methodology is composed of the following steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use the latest election dataset-2020, we will be creating the model.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Data cleaning and extraction.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;We will try to download the latest data from twitter and campaigning.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4-technologies-used&#34;&gt;4. Technologies used&lt;/h2&gt;
&lt;p&gt;Python, Jupyter notebook or collab, Pandas, Scikit-learn, PyTorch,&lt;/p&gt;
&lt;h2 id=&#34;5-refernces&#34;&gt;5. Refernces&lt;/h2&gt;
&lt;p&gt;TBD&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-326/assignments/assignment_6_gangaprsad_shahapurkar/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-326/assignments/assignment_6_gangaprsad_shahapurkar/</guid>
      <description>
        
        
        &lt;h1 id=&#34;report-on-nursing-robots&#34;&gt;Report on Nursing Robots&lt;/h1&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Robotic technology has gradually penetrated both personal and
professional life of human lives. This is very extensive field. Robotics
is an interdisciplinary branch of engineering and science that includes
mechanical engineering, electrical engineering, and computer science.
Artificial intelligence (AI) is playing fundamental role in robotics as
this technological advanced field is dealing with connecting perception
to action.&lt;/p&gt;
&lt;p&gt;Robots are already being used in industries like manufacturing, places
were dangerous work needs to be carried out not possible by human, or
some places where human cannot survive. Robotics currently has lot of
professional and non-professional applications. They are being used in
non-professional applications like room cleaning, food preservation,
lawn mowing, playing with kids. Professional applications are mainly
public transport systems including the undergrounds, over grounds, and
metro services.&lt;/p&gt;
&lt;p&gt;At present, there are rising incidences of lifestyle diseases and
growing demand for affordable healthcare. There has been increased role
of government in healthcare investment space and emergence of
technologies such as artificial learning (AI), machine learning (ML) and
robotics have been driving healthcare industry across the world. AI &amp;amp; ML
is becoming increasingly sophisticated at doing what humans do, but more
efficiently, quickly and at a lower cost&lt;/p&gt;
&lt;p&gt;Japan is currently leading the world in advanced robotics, where usage
of service robot has been recently growing in nursing or care homes.
Many Japanese corporations are planning to exploit the great potentials
of nursing-care robots manufacturing especially where aimed at taking
care of older adults. There are about 5,000 nursing-care homes testing
robots for use in nursing care due to declining number of human nurses
to care for aged people (above 65 years of age) who are more than a
quarter of the population (the highest in OECD countries).&lt;/p&gt;
&lt;h2 id=&#34;problem-statement&#34;&gt;Problem statement&lt;/h2&gt;
&lt;p&gt;Census bureau estimates that nearly 25 % of population will be aged 65
or older by 2060. According to the World Bank population estimates and
projections, whilst Japan currently has some 126.3 million inhabitants
of which 34.7 million are aged 65 and above, representing 27.38% of the
overall population, in 2050 the total population of Japan will shrink to
108 million with 39 million people that will be aged 65 and above, which
will represent 36% of the overall population. There will be more demand
on care. This could cause a significant shortage of nurses in health
care to care for elderly.&lt;/p&gt;
&lt;p&gt;Nurses spends time in doing multiple every day routine activities which
can be delegated to a different person. Researches around the globe have
observed and are of opinion that certain nursing function such as
ambulation services, patient vital signs measurement, medication
administration, infectious diseases protocols can be delegated to
robots. As robots learn to perform these duties role of nurses in
delivery care will change.&lt;/p&gt;
&lt;p&gt;Research suggests that 8% to 16% nursing time is spent on non-nursing
activities. As robots learns to perform non-nursing activities, nurses
with robot support will have ability to take back the time spent on
non-nursing activities and spend more of it with patients. The robots
are being viewed as assistants to help nurses at bedside or in
community.&lt;/p&gt;
&lt;h2 id=&#34;current-status-of-ai-solution&#34;&gt;Current Status of AI solution&lt;/h2&gt;
&lt;p&gt;Robotics is well on its way in many roles and procedure in health care.
Robotic engineers are advancing what robots can do and how they
emotionally respond to circumstances. Below are some of the AI solutions
used in nursing profession and carries out non-nursing activities&lt;/p&gt;
&lt;h3 id=&#34;1-patients-vital-sign-measurement-and-repetitive-tasks&#34;&gt;1. Patients vital sign measurement and repetitive task(s)&lt;/h3&gt;
&lt;p&gt;While every country is fighting with COVID situation, front line
works are being under tremendous pressure, especially
doctors/nurses. AI solution has come to rescue, with a robot-based
solution that helps to collect samples for testing.&lt;/p&gt;
&lt;h3 id=&#34;2-humanoid-robot&#34;&gt;2. Humanoid Robot&lt;/h3&gt;
&lt;p&gt;PALRO is a humanoid type robot which can communicate with human
&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. It has ability to remember up to 100 faces and communicate
through voice. It has proven effective when applied with some senior
patients with Dementia.&lt;/p&gt;
&lt;h3 id=&#34;3-patient-caretaker&#34;&gt;3. Patient Caretaker&lt;/h3&gt;
&lt;p&gt;Japan introduced an experimental robot in 2015 &amp;ldquo;ROBEAR&amp;rdquo; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. With
its rapidly increasing elderly population, Japan faces an urgent need
for new approaches to assist care-giving personnel. One of the most
strenuous tasks for such personnel, carried out an average of 40 times
every day, is that of lifting a patient from a bed into a wheelchair,
and this is a major cause of lower back pain. Robots are well-suited
to this task, yet none have yet been deployed in care-giving
facilities &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;improvement-opportunities&#34;&gt;Improvement opportunities&lt;/h2&gt;
&lt;h3 id=&#34;communication&#34;&gt;Communication&lt;/h3&gt;
&lt;p&gt;Humans are known to be intelligent creatures and has ability to adapt,
behave, and respond to any situation. Though Robots are developed by
humans they are still far away to mimic these human features. Studies
have shown that communication between human and robot has resulted in
worse outcomes when robots were involved in area like surgery. These are
high stress situation like operation room where we need to improvise
robots in terms of behavior, communication, and response&lt;/p&gt;
&lt;h3 id=&#34;movement&#34;&gt;Movement&lt;/h3&gt;
&lt;p&gt;Technology is moving fast paced where devices have started transitioning
from smart speakers to robots with ability to move. Articulation and
mobility will be the key features to personal/social robots that can
move and face the home user. Adding robotic functions to existing voice
control front-end devices will deliver confirmation of activation and
engagement through physical movement or simulated facial expressions.
Aging-in-place or Ambient Assisted Living (AAL) end-users may be one
consumer segment that would welcome greater robotic capabilities in a
voice control device.&lt;/p&gt;
&lt;h3 id=&#34;human-bot-interaction&#34;&gt;Human-Bot Interaction&lt;/h3&gt;
&lt;p&gt;Today&amp;rsquo;s robots available can perform basic tasks that require no
emotional decision-making or empathy. In addition to ability to perform
basic task, they need to be able to interact with human co-workers
better so that they help to alleviate staff shortages.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Inoue K., Sakuma N., Okada M., Sasaki C., Nakamura M., Wada K.
(2014) Effective Application of PALRO: A Humanoid Type Robot for People
with Dementia. In: Miesenberger K., Fels D., Archambault D., PeÅˆÃ¡z P.,
Zagler W. (eds) Computers Helping People with Special Needs. ICCHP 2014.
Lecture Notes in Computer Science, vol 8547. Springer, Cham.
&lt;a href=&#34;https://doi.org/10.1007/978-3-319-08596-8_70&#34;&gt;https://doi.org/10.1007/978-3-319-08596-8_70&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Ohio University. The Rise of the Robot Nurse.[Online].
&lt;a href=&#34;https://onlinemasters.ohio.edu/blog/the-rise-of-the-robot-nurse/%3E&#34;&gt;https://onlinemasters.ohio.edu/blog/the-rise-of-the-robot-nurse/&amp;gt;&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Jens Wilkinson. (Feb. 23, 2015). The strong robot with the
gentle touch. [Online].
&lt;a href=&#34;https://www.riken.jp/en/news_pubs/research_news/pr/2015/20150223_2/&#34;&gt;https://www.riken.jp/en/news_pubs/research_news/pr/2015/20150223_2/&lt;/a&gt; &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-326/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-326/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;analysis-of-future-of-buffalo-breeds-and-milk-production-growth-in-india&#34;&gt;Analysis of Future of Buffalo Breeds and Milk Production Growth in India&lt;/h1&gt;
&lt;p&gt;Gangaprasad Shahapurkar, fa20-523-326, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-326/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; include a small abstract here. Abstracts can not have references.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-datasets&#34;&gt;2. Datasets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-software-component&#34;&gt;3. Software Component&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-references&#34;&gt;4. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; buffalo, milk production, livestock , argriculture, india&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;Indian Agriculture sector has been playing a vital role in overall
contribution to Indian Economy. Most of the rural community in the
nation still make their livelihood on Dairy Framing or Agriculture
farming. Dairy framing itself has been on its progressive stage from
past few years and it is contributing to almost more than 25% of
agriculture GDP &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Livestock rearing has been integral part of rural community of the
nation. Livestock production plays major role in life of farmers. It
provides food, income, employment. It also does other contributions to
the overall rural development of the nation. The output of livestock
rearing such as milk, egg, meat, and wool provides everyday income to
the farmers on daily basis, it provides nutrition to consumers and
indirectly it helps in contributing to overall national economy and
socio-economic development of the country. Livestock rearing sector is
leveraging the economy in big way considering the growth we can see.&lt;/p&gt;
&lt;p&gt;Livestock population comprises of different species by age, sex and
uses. This project takes a closer look and focus on the Buffalo breed in
India and will attempt to estimate milk production for year 2020 based
on the various features available in the dataset &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. The reason for
focusing on milk production because of various aspect came across based
on the past and current research seen in this area&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The production of milk and meat from buffaloes in Asian countries
over the last decades has shown a varying pattern: in countries such
as India, Sri Lanka, Pakistan and China&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Buffaloes are known to be better at converting poor-quality roughage
into milk and meat. They are reported to have a 5 percent higher
digestibility of crude fibre than high-yielding cows; and a 4-5
percent higher efficiency of utilization of metabolic energy for
milk production (Mudgal, 1988)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;India is the highest buffalo milk producer in the world&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The world buffalo population is estimated at 185.29 million, spread
in some 42 countries, of which 179.75 million (97%) are in Asia
(Source: Fao.org/stat 2008). India has 105.1 million and they
comprise approximately 56.7 percent of the total world buffalo
population. During the last 10 years, the world buffalo population
increased by approximately 1.49% annually, by 1.53% in India, 1.45%
in Asia and 2.67% in the rest of the world.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-datasets&#34;&gt;2. Datasets&lt;/h2&gt;
&lt;p&gt;The Animal Husbandry Statistics Division of the Department of Animal
Husbandry &amp;amp; Dairying division (DAHD) is responsible for generation of
Animal Husbandry Statistics through the schemes of Livestock Census and
Integrated Sample Surveys &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;It is mandate for this division&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Conducting quinquennial livestock census.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Conducting annual sample survey through Integrated Sample Survey.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Publishing of Annual estimates of production of milk, eggs, meat,
wool and other related Animal Husbandry Statistics based on
Integrated Sample Survey conducted through State and Union
Territories.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Survey methodology of Integrated Sample Survey is defined by Indian
Agriculture Statistics Research Institute (IASRI). This is the only
scheme through which considerable data, particularly on the production
estimate of major livestock products, is being generated for policy
formulation in the livestock sector&lt;/p&gt;
&lt;p&gt;Apart from vital census data published by this group no other
competitive data source was found.&lt;/p&gt;
&lt;h2 id=&#34;3-software-component&#34;&gt;3. Software Component&lt;/h2&gt;
&lt;p&gt;Based on features available in survey dataset, supervized machine learning algorithm will be devised and applied to get the predicted out labels being looked at as part of this project&lt;/p&gt;
&lt;h2 id=&#34;4-references&#34;&gt;4. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Department of Animal Husbandry and Dairying.
&lt;a href=&#34;http://dahd.nic.in/about-us/divisions/statistics&#34;&gt;http://dahd.nic.in/about-us/divisions/statistics&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Alessandro, Nardone. (2010). &amp;ldquo;Buffalo Production and Research&amp;rdquo;.
Italian Journal of Animal Science. 5. 10.4081/ijas.2006.203. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;PIB Delhi. (2019). &amp;ldquo;Department of Animal Husbandry &amp;amp; Dairying
releases 20th Livestock Census&amp;rdquo;, 16 (Oct 2019).
&lt;a href=&#34;https://pib.gov.in/PressReleasePage.aspx?PRID=1588304&#34;&gt;https://pib.gov.in/PressReleasePage.aspx?PRID=1588304&lt;/a&gt; &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-326/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-326/test/</guid>
      <description>
        
        
        &lt;p&gt;Test Data 1&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-329/report/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-329/report/</guid>
      <description>
        
        
        &lt;p&gt;Wanru Li&lt;/p&gt;
&lt;p&gt;INFO-I423&lt;/p&gt;
&lt;p&gt;Geoffrey Fox&lt;/p&gt;
&lt;p&gt;Oct 9, 2020&lt;/p&gt;
&lt;p&gt;Get Started in Final Project Plan&lt;/p&gt;
&lt;p&gt;&amp;ndash;Big Data in E-Commerce&lt;/p&gt;
&lt;p&gt;This is an individual project, I plan to accomplish the report by myself. The topic of my report is big data in e-commerce. In my life, e-commerce is a big part of my life. During the shopping online, the recommend commodities are fitter and fitter for my liking and willingness to buy. This is the merit of big data. Big data use my purchase history and browsing history to analyze my liking and recommend the goods for me.&lt;/p&gt;
&lt;p&gt;For the dataset, I will use the source website provided in the project requirements, if there needs more information, I will search for data and information on the web.&lt;/p&gt;
&lt;p&gt;As Artur Olechowski wrote, &amp;quot;According to the IDC, the digital universe of data will grow by 61% to reach a smashing 175 zettabytes worldwide by 2025. There&#39;s no denying that a large chunk of the digital world belongs to e-commerce, which takes advantage of customer social media activity, web browser history, geolocation, and data about abandoned online shopping carts. Most e-commerce businesses are able to collect and process data at scale today. Many of them leverage data analytics to understand their customers&#39; purchasing behaviors, follow the changing market trends, gain insights that allow them to become more proactive, deliver more personalized experiences to customers. The global Big Data in the e-commerce industry is expected to grow at the CAGR of 13.27% between 2019 and 2028. But what exactly is Big Data? And how can e-commerce businesses capture this powerful technology trend to their advantage? In this article, we take a closer look at the key trends in the usage of Big Data technologies by e-commerce companies and offer you some tips to help you get started in this game-changing field (Olechowski, para 1-4)&amp;quot;.&lt;/p&gt;
&lt;p&gt;The most common and widely used application of big data is in e-commerce. Nowadays, the application of big data in e-commerce is relatively mature. As Artur Olechowski wrote, &amp;quot;As businesses scale up, they also collect an increasing amount of data. They need to get interested in data and its processing; this is just inevitable. That&#39;s why a data-driven e-commerce company should regularly measure and improve upon: shopper analysis, customer service personalization, customer experience, the security of online payment processing, targeted advertising ï¼ˆpara11)&amp;quot;.&lt;/p&gt;
&lt;p&gt;There are also some disadvantages of the big data, or to say more need to do after getting the data. Artur Olechowski wrote, &amp;quot;Understand the problem of security â€” Big Data tools gather a lot of data about every single customer who visits your site. This is a lot of sensitive information. If your security is compromised, you could lose your reputation. That&#39;s why before adopting the data technology, make sure to hire a cybersecurity expert to keep all of your data private and secure (para 41)&amp;quot;. Security is always a big problem with big data. This is one of the components I will analyze in my report. He also wrote, &amp;quot;Lack of analytics will become a bigger problem â€” Big Data is all about gathering information, but to make use of it, your system should also be able to process it. High-quality Big Data solutions can do that and then visualize insights in a simple manner. That&#39;s how you can make this valuable information useful to everyone, from managers to customer service reps (para 41)&amp;quot;. The analysis is also an important part of the big data. Only collecting data cannot help e-commerce anything. Security and analytics will be talked in my report.&lt;/p&gt;
&lt;p&gt;For a good report, I will look for some examples of big data in e-commerce and analyze the advantages and disadvantages of the influence of big data in e-commerce. I will do more research on the pros and cons of big data in e-commerce. I will also study in the course to know more about big data.&lt;/p&gt;
&lt;p&gt;Work Cited&lt;/p&gt;
&lt;p&gt;Olechowski, Artur. &amp;quot;Big Data in E-Commerce: Key Trends and Tips for Beginners: Codete Blog.&amp;quot; &lt;em&gt;Codete Blog - We Share Knowledge for IT Professionals&lt;/em&gt;, CODETE, 8 Sept. 2020, codete.com/blog/big-data-in-ecommerce/.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-329/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-329/test/</guid>
      <description>
        
        
        &lt;p&gt;test&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-333/assignment6/assignment6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-333/assignment6/assignment6/</guid>
      <description>
        
        
        &lt;p&gt;Raymond Adams&lt;/p&gt;
&lt;p&gt;Using AI to Efficiently Diagnose and Reduce Error&lt;/p&gt;
&lt;p&gt;Artificial intelligence is taking over the healthcare industry. Although it is known that AI will take many jobs away from workers in many different fields, healthcare is one field where it may be most beneficial. AI has been able to efficiently diagnose and reduce error. An article from Managed Healthcare Executive states, â€œHuman error is the determining factor in 70% to 80% of industrial accidents, as well as in a large percentage of errors and adverse events experienced in healthcare.â€ In fact, according to built-in, misdiagnosing patients and medical error â€œaccounted for 10% of all US deathsâ€ in 2015.&lt;/p&gt;
&lt;p&gt;There are several factors for why human error occurs in healthcare. The first factor is that workers in the industry cannot keep up with the vast amount of new research and recommendations that are regularly being released. According to Managed Healthcare Executive, â€œIn 2010, a new journal article was published to the National Library of Medicine every 40 secondsâ€ and this rate has probably increased since then. The issue here is that no healthcare provider can keep up with the new information that is continuously being written and discovered. Another factor is that humans are prone to cognitive biases that affect the way we solve problems accurately, efficiently, and reliably. Humans also are susceptible to factors such as stress, distraction, and sleep deprivation which all can contribute to human errors.&lt;/p&gt;
&lt;p&gt;Artificial intelligence can reduce all of these issues and can efficiently diagnose patients with diseases at rates that humans could never. For example, built-in states, â€œan AI model using algorithms and deep learning diagnosed breast cancer at a higher rate than 11 pathologists.â€ Many existing and new companies have begun creating AI software to help resolve these issues that humans just arenâ€™t capable of fixing. PathAI is a company that is developing algorithms to help pathologists produce more accurate diagnoses. Buoy Health is another company that is using AI to check peopleâ€™s symptoms and provide cures. Buoy has become so useful and reliable that Harvard Medical School is one of the many hospitals that use the AI-based symptom and cure checker.&lt;/p&gt;
&lt;p&gt;Zebra Medical Vision is an AI-powered radiology assistant that according to Zebra, â€œis empowering radiologists with its revolutionary AI1 offering which helps health providers manage the ever increasing workload without compromising quality.â€ Their goal is to provide radiologists with the tools they need to make the next big improvement in patient care. The need for medical imaging services is constantly growing. Like most fields in healthcare, humans just canâ€™t keep up. The number of radiology reports is out numbering the workers that are able to analyze the reports.&lt;/p&gt;
&lt;p&gt;Zebra Medical Vision is solving this problem by having their imagining analytics engine take-in imaging scans from numerous approaches and automatically analyzes the images for multitude of clinical findings. Zebra-Med works by using a large database that contains millions of imaging scans as well as machine learning and deep learning to develop software that according to Zebra-Med, â€œanalyzes data in real time with human level accuracy.â€&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-333/final_project_plan_invalid/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-333/final_project_plan_invalid/</guid>
      <description>
        
        
        &lt;h1 id=&#34;not-a-valid-md-file-all-md-files-mus-have-ad-least-on-section-heading&#34;&gt;Not a valid md file, all md files mus have ad least on section heading&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please follow markdown template we posted in piazza&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please follow tips we posted in piazza&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; decalring that a report will include 3000-4000 words is not needed.&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please use proper markdown swith sections&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please do not use  : in section titles&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please convert this from &amp;ldquo;I&amp;rdquo; to a formal report.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Raymond Adams&lt;/p&gt;
&lt;p&gt;09 October 2020&lt;/p&gt;
&lt;p&gt;Geoffrey Fox&lt;/p&gt;
&lt;p&gt;Final Project Plan&lt;/p&gt;
&lt;p&gt;Using Spotify Data To Determine If Popular Modern-day Songs Lack Uniqueness Compared To Popular Songs Before The 21st Century&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Topic&lt;/strong&gt; :&lt;/p&gt;
&lt;p&gt;I will be looking at Spotify data, a music streaming service, to answer my research question, &amp;quot;Do popular modern-day songs lack uniqueness compared to popular songs before the year 2000?&amp;quot; Music has always been a way to express oneself. Before the new era of music began most songs seemed to have a unique sound and feel that brought the listener back for more. However, nowadays it seems that most songs that become popular have similar characteristics. The goal of this research is to study whether popular modern-day songs lack the uniqueness that songs had before January 1, 2001.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data&lt;/strong&gt; :&lt;/p&gt;
&lt;p&gt;The dataset that I will be using was created by YamaÃ§ Eren Ay. He is a data scientist at EYU from Ä°stanbul, Ä°stanbul, Turkey. This data set was collected from Spotify&#39;s web API. It contains data on songs from 1921-2019.&lt;/p&gt;
&lt;p&gt;The variables include:&lt;/p&gt;
&lt;p&gt;Numerical values [&lt;strong&gt;acousticness&lt;/strong&gt; (Ranges from 0 to 1), &lt;strong&gt;danceability&lt;/strong&gt; (Ranges from 0 to 1), energy (Ranges from 0 to 1), &lt;strong&gt;duration_ms&lt;/strong&gt; (Integer typically ranging from 200k to 300k), &lt;strong&gt;instrumentalness&lt;/strong&gt; (Ranges from 0 to 1), &lt;strong&gt;valence&lt;/strong&gt; (Ranges from 0 to 1), &lt;strong&gt;popularity&lt;/strong&gt; (Ranges from 0 to 100), &lt;strong&gt;tempo&lt;/strong&gt; (Float typically ranging from 50 to 150), &lt;strong&gt;liveness&lt;/strong&gt; (Ranges from 0 to 1), &lt;strong&gt;loudness&lt;/strong&gt; (Float typically ranging from -60 to 0), &lt;strong&gt;speechiness&lt;/strong&gt; (Ranges from 0 to 1), &lt;strong&gt;year&lt;/strong&gt; (Ranges from 1921 to 2020)]&lt;/p&gt;
&lt;p&gt;Dummy values [&lt;strong&gt;mode&lt;/strong&gt; (0 = Minor, 1 = Major), &lt;strong&gt;explicit&lt;/strong&gt; (0 = No explicit content, 1 = Explicit content)]&lt;/p&gt;
&lt;p&gt;Categorical [&lt;strong&gt;key&lt;/strong&gt; (All keys on octave encoded as values ranging from 0 to 11, starting on C as 0, C# as 1 and so onâ€¦), &lt;strong&gt;artists&lt;/strong&gt; (List of artists mentioned), &lt;strong&gt;release_date&lt;/strong&gt; (Date of release mostly in yyyy-mm-dd format, however precision of date may vary), &lt;strong&gt;name&lt;/strong&gt; (Name of the song)]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What needs to be done to get a great grade&lt;/strong&gt; :&lt;/p&gt;
&lt;p&gt;In order to complete the project and receive a good grade I will need complete a couple steps. First, I will import my data set through Google collab or Jupyter Notebook and create code to visualize and analyze the data. Next I will create markdown cells to explain the code and data used throughout the project. Lastly, I will create a paper report explaining my findings from the software component of my project. This report will be 3000-4000 words long. The most important part of this project is stating my hypothesis and answering my research question. My hypothesis is that songs after 2012 that have a popular score greater than x will have similar features such as, liveliness, loudness, tempo, and key. Whereas I suspect that popular songs before the 21st century are more differentiable.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-333/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-333/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;using-spotify-data-to-determine-if-popular-modern-day-songs-lack-uniqueness-compared-to-popular-songs-before-the-21st-century&#34;&gt;Using Spotify Data To Determine If Popular Modern-day Songs Lack Uniqueness Compared To Popular Songs Before The 21st Century&lt;/h1&gt;
&lt;p&gt;Raymond Adams, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-333/project/project&#34;&gt;fa20-523-333&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please follow our template&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; please remove first person&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt;
&lt;p&gt;For this final project I will be working alone.&lt;/p&gt;
&lt;h2 id=&#34;topic&#34;&gt;Topic&lt;/h2&gt;
&lt;p&gt;I will be looking at Spotify data, a music streaming service, to answer my research question, &amp;ldquo;Do popular modern-day songs lack uniqueness compared to popular songs before the year 2000?&amp;rdquo; Music has always been a way to express oneself. Before the new era of music began most songs seemed to have a unique sound and feel that brought the listener back for more. However, nowadays it seems that most songs that become popular have similar characteristics. The goal of this research is to study whether popular modern-day songs lack the uniqueness that songs had before January 1, 2001.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;The dataset that I will be using was created by YamaÃ§ Eren Ay. He is a data scientist at EYU from Ä°stanbul, Ä°stanbul, Turkey. This data set was collected from Spotify&amp;rsquo;s web API. It contains data on songs from 1921-2019.&lt;/p&gt;
&lt;p&gt;The variables include:&lt;/p&gt;
&lt;p&gt;Numerical values [&lt;strong&gt;acousticness&lt;/strong&gt;  (Ranges from 0 to 1),  &lt;strong&gt;danceability&lt;/strong&gt;  (Ranges from 0 to 1), energy (Ranges from 0 to 1),  &lt;strong&gt;duration_ms&lt;/strong&gt;  (Integer typically ranging from 200k to 300k),  &lt;strong&gt;instrumentalness&lt;/strong&gt;  (Ranges from 0 to 1),  &lt;strong&gt;valence&lt;/strong&gt;  (Ranges from 0 to 1),  &lt;strong&gt;popularity&lt;/strong&gt;  (Ranges from 0 to 100),  &lt;strong&gt;tempo&lt;/strong&gt;  (Float typically ranging from 50 to 150),  &lt;strong&gt;liveness&lt;/strong&gt;  (Ranges from 0 to 1),  &lt;strong&gt;loudness&lt;/strong&gt;  (Float typically ranging from -60 to 0),  &lt;strong&gt;speechiness&lt;/strong&gt;  (Ranges from 0 to 1),  &lt;strong&gt;year&lt;/strong&gt;  (Ranges from 1921 to 2020)]&lt;/p&gt;
&lt;p&gt;Dummy values [&lt;strong&gt;mode&lt;/strong&gt;  (0 = Minor, 1 = Major),  &lt;strong&gt;explicit&lt;/strong&gt;  (0 = No explicit content, 1 = Explicit content)]&lt;/p&gt;
&lt;p&gt;Categorical [&lt;strong&gt;key&lt;/strong&gt;  (All keys on octave encoded as values ranging from 0 to 11, starting on C as 0, C# as 1 and so onâ€¦),  &lt;strong&gt;artists&lt;/strong&gt;  (List of artists mentioned),  &lt;strong&gt;release_date&lt;/strong&gt;  (Date of release mostly in yyyy-mm-dd format, however precision of date may vary),  &lt;strong&gt;name&lt;/strong&gt;  (Name of the song)]&lt;/p&gt;
&lt;h2 id=&#34;what-needs-to-be-done-to-get-a-great-grade&#34;&gt;What needs to be done to get a great grade&lt;/h2&gt;
&lt;p&gt;In order to complete the project and receive a good grade I will need complete a couple steps. First, I will import my data set through Google collab or Jupyter Notebook and create code to visualize and analyze the data. Next I will create markdown cells to explain the code and data used throughout the project. Lastly, I will create a paper report explaining my findings from the software component of my project. The most important part of this project is stating my hypothesis and answering my research question. My hypothesis is that songs after 2012 that have a popular score greater than x will have similar features such as, liveliness, loudness, tempo, and key. Whereas I suspect that popular songs before the 21st century are more differentiable among these features.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-337/project/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-337/project/readme/</guid>
      <description>
        
        
        &lt;p&gt;&lt;strong&gt;Project Title:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Online Store Customer Revenue Prediction&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Project Abstract:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The dataset for this project is obtained from Kaggle. The link to the dataset is provided below:
&lt;a href=&#34;https://www.kaggle.com/c/ga-customer-revenue-prediction&#34;&gt;https://www.kaggle.com/c/ga-customer-revenue-prediction&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Problem Statement:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The 80/20 rule has proven true for many businessesâ€“only a small percentage of customers produce most of the revenue. As such, marketing teams are challenged to make appropriate investments in promotional strategies.&lt;/li&gt;
&lt;li&gt;In this competition, youâ€™re challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. Hopefully, the outcome will be more actionable operational changes and a better use of marketing budgets for those companies who choose to use data analysis on top of GA data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dataset Explanation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Two datasets are provided (train.csv and test.csv)&lt;/li&gt;
&lt;li&gt;Train.csv ïƒ¨ User transactions from August 1st, 2016 to August 1st, 2017&lt;/li&gt;
&lt;li&gt;Test.csv  ïƒ¨ User transactions from August 2nd, 2017 to April 30th, 2018&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Team Members:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Anantha Janakiraman â€“ Machine Learning Engineer&lt;/li&gt;
&lt;li&gt;Balaji Dhamodharan â€“ Data Scientist - Github Repo Owner&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Problem Setting and Model Development&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Our objective is to predict the natural log of total revenue per customer which is a real valued continuous output and linear regression would be an ideal algorithm in such a setting to predict the response variable that is continuous using a set of predictor variables given the basic assumption that there is a linear relationship between the predictor and response variables.&lt;/p&gt;
&lt;p&gt;The training dataset contains 872214 records and considering the size of the training dataset, we will plan to use mini-batch or stochastic gradient descent methods to obtain optimized estimates of the coefficients for our linear function that best describes the input variables. After cleaning and pre-processing the data, we will build a basic linear regression model using basic parameter setting and based on outcome of this initial model, we will perform further experimentation to tune the hyper-parameters including regularization and additional feature engineering to derive more features from the provided input data to improve the parameter estimates for our model and reduce the error.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Metrics&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The metrics we will use for this project is root mean squared error (RMSE). The root mean squared error function forms our objective/cost function which will be minimized to estimate the optimal parameters for our linear function through Gradient Descent. We will conduct multiple experiments to obtain convergence using different â€œnumber of iterationsâ€ value and other hyper-parameters (e.g. learning rate).&lt;/p&gt;
&lt;p&gt;RMSE is defined as:&lt;/p&gt;
&lt;img src=&#34;Images-and-plots/Loss_Func.png&#34;&gt;
&lt;p&gt;where y-hat is the natural log of the predicted revenue for a customer and y is the natural log of the actual summed revenue value plus one as seen below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Model Pipeline Steps&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The  high-level representation of the implementation steps is shown below. The below steps are subject to change as we understand more about the data and various pre-processing, feature engineering or model development steps may vary accordingly.&lt;/p&gt;
&lt;img src=&#34;Images-and-plots/Plot_Part1.png&#34;&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-342/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-342/project/project/</guid>
      <description>
        
        
        &lt;p&gt;Hany Boles, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-342/&#34;&gt;fa20-523-342&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-342/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;By the end of 2019, healthcare across the world started to see a new type of Flu and they called it Coronavirus or Covid-19. This new type of Flu developed across the world and it appeared there is no one treatment could be used to treat it yet, scientists found different treatments that apply to different age ranges. In this project, We will try to work on some analysis on areas that the virus did spread and what factors played big roles in this spread.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-data-sets&#34;&gt;2. Data-Sets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-methodology&#34;&gt;3. Methodology&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-references&#34;&gt;4. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;        While the world is ready to start 2020 we heard about a new type of the Flu that it appears to be started in China and from there it went to the entire world. It appeared to affect all ages but its severity did depend on other factors that related to age, health conditions if the patient is a smoker or not?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This new disease attacked aggressively the respiratory system for the patient and then all the human body causing death. The recovery from this disease appeared to vary from area to area across the globe, Also the death percentage as well was and still vary from area to area.&lt;/p&gt;
&lt;h2 id=&#34;2-data-sets&#34;&gt;2. Data-Sets&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;We will use http://datatopics.worldbank.org/universal-health-coverage/coronavirus/  also https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge as data sets, we will try to observe more data sets so we can get a better understanding of what relates between the coronavirus spread and the most affected areas. Currently looks like we are getting a second wave of coronavirus and so we will try to get the most recent data.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will collect the data and extract it from its sources and datasets, Also we will look for the most recent data as well and we will compare and do analysis on the founding and get the best conclusion accordingly.&lt;/p&gt;
&lt;h2 id=&#34;3-methodology&#34;&gt;3. Methodology&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;We will be utilizing the Indiana University system to process the collected data as it will need a strong system to process it. Also, we will utilize Python, Collab, and Jupyter notebook as programming software.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;4-references&#34;&gt;4. References&lt;/h2&gt;
&lt;p&gt;TBD&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-343/project/homework_5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-343/project/homework_5/</guid>
      <description>
        
        
        &lt;h1 id=&#34;team&#34;&gt;Team&lt;/h1&gt;
&lt;h3 id=&#34;bryce-wieczorek&#34;&gt;Bryce Wieczorek&lt;/h3&gt;
&lt;h1 id=&#34;topic&#34;&gt;Topic&lt;/h1&gt;
&lt;h3 id=&#34;predictive-model-for-pitches-thrown-by-major-league-baseball-pitchers&#34;&gt;Predictive Model For Pitches Thrown By Major League Baseball Pitchers&lt;/h3&gt;
&lt;h1 id=&#34;dataset&#34;&gt;Dataset&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/weslayton/2019-statcast-pitching-summary?select=2019_statcast_summary_2.csv&#34;&gt;https://www.kaggle.com/weslayton/2019-statcast-pitching-summary?select=2019_statcast_summary_2.csv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We plan to use the â€œ2019 Statcast Pitching Summaryâ€ dataset from Kaggle.com. After finding a few different datasets, we decided that this one was the best for this project. The dataset contains every pitcher who had pitched in the 2019 season, along with all their different pitch types, plus their speed and spin effect on the baseball. We are using the 2019 dataset for two reasons. The first being because of COVID19. Due to this virus, multiple players have opted to sit out like star pitcher David Price of the Los Angeles Dodgers. The second being because the 2020 dataset is not complete, due to the season not being over.&lt;/p&gt;
&lt;h1 id=&#34;what-needs-to-be-done-to-get-a-great-grade&#34;&gt;What Needs To Be Done To Get A Great Grade&lt;/h1&gt;
&lt;p&gt;To get a great grade we believe that we will have to create my own prediction model by analyzing the different pitch types, their speeds, and the spin rate of the baseball according to the pitch type. When comparing this data to pitches thrown in game, we believe that we would be able to find what type of pitch was thrown. we will also have to find and compare my own prediction model to any others that are in existence. We believe that this will be good to compare to see if these other prediction models to gain insight to other methods for this research process. Along with this, we will have to evaluate for efficiency and account for limitations. For efficiency, this will let me know how accurate my prediction model is. we must account for limitations in my prediction model, for instance, the pitcher may not always throw the baseball at a consistent velocity. We need to also account for new pitchers who have not pitched in the MLB, or pitchers who have â€œnewâ€ pitches. The last thing we could do and perhaps the most important thing we should do is work on this project in increments. We should plan my project out accordingly and not cram it all together last second.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Report: </title>
      <link>/report/fa20-523-348/project/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-348/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;benchmarking-multi-cloud-auto-generated-ai-services&#34;&gt;Benchmarking Multi-Cloud Auto Generated AI Services&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;NOTE:&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The location of this paper is a temporary location. These notes will be at one point integrated into&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/paper/_index.md&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/master/paper/_index.md&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The branch in which the documentation is done is going to be the master. During the development the code is
managed in a branch &lt;code&gt;benchmark&lt;/code&gt;. However, the team members must frequently stay in sync with &lt;code&gt;master&lt;/code&gt; as new
developments are integrated there frequently. We want to make sure that a merge with master is
any time possible.&lt;/p&gt;
&lt;p&gt;At this time a draft with additional information is available at&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi/blob/benchmark/paper/_index.md&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi/blob/benchmark/paper/_index.md&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The team has yet to merge the main document into a single document to avoid that 3 documents are used.&lt;/p&gt;
&lt;p&gt;At this time the plan is to have the document always in the master branch&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://laszewski.github.io&#34;&gt;Gregor von Laszewski&lt;/a&gt;,
Richard Otten,
Anthony Orlowski, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-310/&#34;&gt;fa20-523-310&lt;/a&gt;,
Caleb Wilson, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-348/&#34;&gt;fa20-523-348&lt;/a&gt;,
Vishwanadham Mandala, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-325/&#34;&gt;fa20-523-325&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-348/blob/master/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;In this wor we are benchmarking auto generated cloud REST services on various clouds. In todays application scientist want to share their services with a wide number of collegues while not only offereing the services as bare metal programs, but exposing the functionality as a software as a service. For this reason a tool has been debveloped that takes a regular python function and converts it automatically into a secure REST service. We will create a number of AI REST services while using examples from ScikitLearn and benchmark the execution of the resulting REST services on various clouds. The code will be accompanied by benchmark enhanced unit tests as to allow replication of the test on the users computer. A comparative study of the results is included in our evaluation.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#cloudmesh&#34;&gt;Cloudmesh&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#algorithms-and-datasets&#34;&gt;Algorithms and Datasets&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#deployment&#34;&gt;Deployment&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#pipiline-anova-svm&#34;&gt;Pipiline ANOVA SVM&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#using-unit-tests-for-benchmarking&#34;&gt;Using unit tests for Benchmarking&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#limitations&#34;&gt;Limitations&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; cloudmesh, AI service, REST, multi-cloud&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;We will develop benchmark tests that are pytest replications of Sklearn artificial intelligent alogrithms. These pytests will then be ran on different cloud services to benchmark different statistics on how they run and how the cloud performs. The team will obtain cloud service accounts from AWS, Azure, Google, and OpenStack. To deploy the pytests, the team will use Cloudmesh and its Openapi based REST services to benchmark the performance on different cloud services. Benchmarks will include components like data transfer time, model train time, model prediction time, and more. The final project will include scripts and code for others to use and replicate our tests. The team will also make a report consisting of research and findings. So far, we have installed the Cloudmesh OpenAPI Service Generator on our local machines. We have tested some microservices, and even replicated a Pipeline Anova SVM example on our local machines. We will repeat these processes, but with pytests that we build and with cloud accounts.&lt;/p&gt;
&lt;h2 id=&#34;cloudmesh&#34;&gt;Cloudmesh&lt;/h2&gt;
&lt;p&gt;Cloudmesh is a service that enables users to access multi-cloud environments easily. Cloudmesh is an evolution of previous tools that have been used by thousands of users. Cloudmesh makes interacting with clouds easy by creating a service mashup to access common cloud services across numerous cloud platforms. Documentation for Cloudmesh can be found at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/&#34;&gt;https://cloudmesh.github.io/cloudmesh-manual/&lt;/a&gt; &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Code for cloud mesh can be found at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudmesh/&#34;&gt;https://github.com/cloudmesh/&lt;/a&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples in this paper came from the cloudmesh openapi manual which is located here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi&lt;/a&gt; &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Information about cloudmesh can be found here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/preface/about.html&#34;&gt;https://cloudmesh.github.io/cloudmesh-manual/preface/about.html&lt;/a&gt; &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Various cloudmesh installations for various needs can be found here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/installation/install.html&#34;&gt;https://cloudmesh.github.io/cloudmesh-manual/installation/install.html&lt;/a&gt; &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;algorithms-and-datasets&#34;&gt;Algorithms and Datasets&lt;/h2&gt;
&lt;p&gt;This project uses a number of simple example algorithms and datasets. We have chosen to use the once included in Scikit Learn as they are widel known and can be used by others to replicate our benchmarks easily. Nevertheless, it will be possible to integrate easily other data sources, as well as algorithms due to the generative nature of our base code for creating REST services.&lt;/p&gt;
&lt;p&gt;Within Skikit Learn we have chosen the following examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pipelined ANOVA SVM&lt;/strong&gt;: A code thet shows a pipeline running successively a univariate feature selection with anova and then a SVM of the selected features &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;aSklearn algorithms replicated and pytests. How the pytests perform on various cloud environments.&lt;/p&gt;
&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;
&lt;p&gt;The project is easy to replicate with our detailed instructions. First you must install Cloudmesh OpenAPI whihch can be done by the follwoing steps:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python -m venv ~/ENV3
source ~/ENV3/bin/activate 
mkdir cm
cd cm
pip install cloudmesh-installer
cloudmesh-installer get openapi 
cms help
cms gui quick
#fill out mongo variables
#make sure autinstall is True
cms config set cloudmesh.data.mongo.MONGO_AUTOINSTALL=True
cms admin mongo install --force
#Restart a new terminal to make sure mongod is in your path
cms init
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As a first example we like to test if the deployment works by using a number of simple commands we execute in a terminal.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd ~/cm/cloudmesh-openapi

cms openapi generate get_processor_name \
    --filename=./tests/server-cpu/cpu.py

cms openapi server start ./tests/server-cpu/cpu.yaml

curl -X GET &amp;quot;http://localhost:8080/cloudmesh/get_processor_name&amp;quot; \
     -H &amp;quot;accept: text/plain&amp;quot;
cms openapi server list

cms openapi server stop cpu
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The output will be a string containing your computer.&lt;/p&gt;
&lt;p&gt;TODO: how does the string look like&lt;/p&gt;
&lt;p&gt;Next you can test a more sophiticated example. Here we generate from a python function a rest servive. We consider the following function definition in which a float is returned as a simple integer&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def add(x: float, y: float) -&amp;gt; float:
    &amp;quot;&amp;quot;&amp;quot;
    adding float and float.
    :param x: x value
    :type x: float
    :param y: y value
    :type y: float
    :return: result
    :return type: float
    &amp;quot;&amp;quot;&amp;quot;
    result = x + y

    return result
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once we execute the following lines in a terminal, the result of the addition will be calculated in the REST service and it is returned as a string.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate add --filename=./tests/add-float/add.py
cms openapi server start ./tests/add-float/add.yaml 
curl -X GET &amp;quot;http://localhost:8080/cloudmesh/add?x=1&amp;amp;y=2&amp;quot; -H  &amp;quot;accept: text/plain&amp;quot;
#This command returns
&amp;gt; 3.0
cms openapi server stop add
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;As we often also need the information as a REST service, we provide in our next example a jsonified object specification.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from flask import jsonify

def add(x: float, y: float) -&amp;gt; str:
    &amp;quot;&amp;quot;&amp;quot;
    adding float and float.
    :param x: x value
    :type x: float
    :param y: y value
    :type y: float
    :return: result
    :return type: float
    &amp;quot;&amp;quot;&amp;quot;
    result = {&amp;quot;result&amp;quot;: x + y}

    return jsonify(result)

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The result will include a json string returned by the service.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms openapi generate add --filename=./tests/add-json/add.py
cms openapi server start ./tests/add-json/add.yaml 
curl -X GET &amp;quot;http://localhost:8080/cloudmesh/add?x=1&amp;amp;y=2&amp;quot; -H  &amp;quot;accept: text/plain&amp;quot;
#This command returns
&amp;gt; {&amp;quot;result&amp;quot;:3.0}
cms openapi server stop add
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These examples are used to demonstrate the ease of use as well as the functionality for those that want to replicate our work.&lt;/p&gt;
&lt;h2 id=&#34;pipiline-anova-svm&#34;&gt;Pipiline ANOVA SVM&lt;/h2&gt;
&lt;p&gt;Next we demonstrate how oto run the Pipeline ANOVA example.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ pwd
~/cm/cloudmesh-openapi

$ cms openapi generate PipelineAnovaSVM \
      --filename=./tests/Scikitlearn-experimental/sklearn_svm.py \
      --import_class --enable_upload

$ cms openapi server start ./tests/Scikitlearn-experimental/sklearn_svm.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After running these commands, we opened a web user interface. In the user interface, we uploaded the file iris data located in ~/cm/cloudmesh-openapi/tests/ Scikitlearn-experimental/iris.data&lt;/p&gt;
&lt;p&gt;We then trained the model on this data set by inserting the name of the file we uploaded &lt;code&gt;iris.data&lt;/code&gt;. Next, we tested the model by clicking on make_prediction and giving it the name of the file iris.data and the parameters &lt;code&gt;5.1&lt;/code&gt;, &lt;code&gt;3.5&lt;/code&gt;, &lt;code&gt;1.4&lt;/code&gt;, &lt;code&gt;0.2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The response we received was &lt;code&gt;Classification: [&#39;Iris-setosa&#39;]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Lastly, we close the server:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cms openapi server stop sklearn_svm
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This process can easily be replicated when we create more service examples that we derive from existing sklearn examples. We benchmark these tests while wrapping them into pytests and run them on various cloud services.&lt;/p&gt;
&lt;h2 id=&#34;using-unit-tests-for-benchmarking&#34;&gt;Using unit tests for Benchmarking&lt;/h2&gt;
&lt;p&gt;TODO: This section will be expanded upon&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Describe why we can unit tests&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Describe how we access multiple clouds&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cms set cloud=aws
# run test
cms set cloud=azure
# run test
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Describe the Benchmark class from cloudmesh in one sentence and how we use it&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;p&gt;Azure has updated their libraries and discontinued the version 4.0 Azure libraries. We have not yet identified if code changes in Azure need to be conducted to execute our  code on Azure&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;â€ƒ&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Cloudmesh Manual, &lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/&#34;&gt;https://cloudmesh.github.io/cloudmesh-manual/&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Cloudmesh Repositories, &lt;a href=&#34;https://github.com/cloudmesh/&#34;&gt;https://github.com/cloudmesh/&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Cloudmesh OpenAPI Repository for automatically generated REST services from Python functions &lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-openapi&#34;&gt;https://github.com/cloudmesh/cloudmesh-openapi&lt;/a&gt;. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Cloudmesh Manaual Preface for cloudmesh,  &lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/preface/about.html&#34;&gt;https://cloudmesh.github.io/cloudmesh-manual/preface/about.html&lt;/a&gt; &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Cloudmesh Manual, Instalation instryctions for cloudmesh &lt;a href=&#34;https://cloudmesh.github.io/cloudmesh-manual/installation/install.html&#34;&gt;https://cloudmesh.github.io/cloudmesh-manual/installation/install.html&lt;/a&gt; &lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit Learn, Pipeline Anova SVM, &lt;a href=&#34;https://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection_pipeline.html&#34;&gt;https://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection_pipeline.html&lt;/a&gt; &lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
  </channel>
</rss>
